---
date: "2019-04-29T06:42:08-07:00"
draft: true
title: "Distri-Design"
tags: [Distributed]
#series: []
categories: []
toc: true
---
# 分布式系统设计
分布式系统设计主要有关于四个重点两个小点。

# 四个重点

## 容错能力（服务隔离、异步调用、请求幂等性、分布式锁）
何为容错能力：
系统在不健康、不顺，甚至出错的情况下有能力 hold 得住，挺得住，还有能在这种逆境下力挽狂澜的能力；我们都知道，故障是必然会发生的，是正常的，是常见的，我们应该把处理故障的代码当成正常的功能做在架构里写在代码里。

请求幂等：幂等并不是每次请求的结果都一样，而是一次和多次请求某一个资源应该具有同样的副作用，f(x) = f(f(x))，要做到幂等性的交易接口，需要有一个唯一的标识，来标志交易是同一笔交易，这个标识要能做到全局唯一。幂等还是比较容易实现的，比如对于转账交易（支付系统一定要保证幂等），最简单的就是每次请求都带有一个唯一标识id，比如一个请求（id,money），此id标识在数据库中能唯一确定一条记录；若因为网络故障客户端多次请求同一个转账交易（id,money），服务端必须保证只能有一次记录成功，对于其他重复请求应该给客户端明确的解析语义。我们一般保证幂等的判断是从数据库查询有没有相同id的记录，但是在分布式系统环境下，可能有问题，主从问题：两个相同的请求request1、request2时间间隔很短，request1请求过来的时候，查询从库发现没有对应记录，则request1开始操作插入主库record1，但是还没有同步到从库；此时request2查询从库（主从还未同步）也发现没有相同id的记录，准备插入有相同id的记录record2，这个时候request1成功插入record1，request2开始插入record2，数据库报错：唯一约束被破坏相关的异常日志；解决这个问题有两种方法：1、读写都强制走主库；2、采用分布式锁，考虑性能问题，一般都选2
分布式锁：分布式系统一般都有多台机器，常规的多线程锁已经无法解决问题；最简单用redis实现：思路很简单，主要用到的redis函数是setnx()。首先是将某一任务标识名UniqueKey（能唯一识别一个请求的标识）作为键存到redis里，并为其设个过期时间，如果是同样的请求过来，先是通过setnx()看看是否能将UniqueKey插入到redis里，可以的话就返回true，不可以就返回false。
>分布式锁设计原则：
>   互斥性，同一时间只有一个线程持有锁
>   容错性，即使某一个持有锁的线程，异常退出，其他线程仍可获得锁
>   隔离性，线程只能解自己的锁，不能解其他线程的锁

服务隔离：是为了在系统发生故障时能限定传播范围和影响范围，即发生故障后不会出现滚雪球效应，从而保证只有出问题的服务不可用，其他服务还是可用的。

异步调用：发送方发送请求后，接收方直接返回正在处理，通过轮询或者回调的方式返回结果；异步调用相比于同步调用的最大好处是可以快速相应客户端的请求，至于具体的请求结果，通过异步回调的方式发送给客户端，这种方式在服务端平均处理请求时间过长的业务场景下很好用，避免在高请求流量下的超时、阻塞等问题；

## 可伸缩性（有 / 无状态的服务）

无状态服务在程序 Bug 上和水平扩展上有非常优秀的表现，但是在一致性上却有劣势，事物总是相对的（个人此点能力不足，不足以论述）

## 可伸缩性（有 / 无状态的服务）

ACID :大家在买同一本书的过程中，每个用户的购买请求都需要把库存锁住，等减完库存后，把锁释放出来，后续的人才能进行购买。同一时间不可能有多个用户下单，订单流程需要有排队的情况，这样一来，我们就不可能做出性能比较高的系统来。

BASE :大家都可以同时下单，这个时候不需要去真正地分配库存，然后系统异步地处理订单，而且是批量的处理。因为下单的时候没有真正去扣减库存，所以，有可能会有超卖的情况。而后台的系统会异步地处理订单时，发现库存没有了，于是才会告诉用户你没有购买成功。

强一致性（ACID）和高可用性（BASE）是对立，顾此失彼；因此，为了可用性，我们要讲业务中需要强一致性的动作和不需要强一致性的动作剥离开，对于非强一致性需求的动作，可以做补偿事务；我们应尽量设计更多非强一致性的业务
由于网络等问题，一些请求无法确定是否成功，这个时候需要重试，即在此发送请求给服务端，希望服务端能确定的交易结果，重试一般通过定时任务扫表，将不是终态的记录查询出在此发请求。

## 应对大流量的能力（熔断、降级）
熔断（慎用）：如果系统中，某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用；熔断主要是应对流量引起的问题，弃卒保车，使服务处于关闭、半关闭状态，以保证部分业务成功，或者舍弃次要业务使主业务运行通畅；
	
限流：熔断的一种，半开状态，只允许少部分的请求，其他的都拒绝，如果设计得当，被拒绝的请求，客户端会通过重试、补偿操作来完成；
	

降级：暂时牺牲掉一些服务，保障整个系统的服务。比如：如果服务器已经高负载，这个时候可以将一些不重要的操作给关闭，比如重试操作，因为服务器已经承受不住，这个时候再重试也没有多大效果，反而更加重服务端的压力，这个时候可以设置一个开关，将重试功能关闭；

# 两个小点
## 解耦（MQ）
在软件工程中，对象之间的耦合度就是对象之间的依赖性。对象之间的耦合越高，维护成本越高，因此对象的设计应使模块之间的耦合度尽量小。在软件架构设计中，模块之间的解耦或者说松耦合有两种，假设有两个模块A、B，A依赖B：

第一种是，模块A和模块B只通过接口交互，只要接口设计不变，那么模块B内部细节的变化不影响模块A对模块B服务能力的消费。 
面向接口设计下真正实现了将接口契约的定义和接口的实现彻底分离，实现变化不影响到接口契约，自然不影响到基于接口的交互。
模块A和B之间的松耦合，主要通过合理的模块划分、接口设计来完成。如果出现循环依赖，可以将模块A、B共同依赖的部分移除到另一个模块C中，将A、B之间的相互依赖，转换为A、B同时对C的依赖。
	
第二种是，将同步调用转换成异步消息交互。 
比如在买机票系统中，机票支付完成后需要通知出票系统出票、代金券系统发券。如果使用同步调用，那么出票系统、代金券系统宕机是会影响到机票支付系统，如果另一个系统比如专车系统也想要在机票支付完成后向用户推荐专车服务，那么同步调用模式下机票支付系统就需要为此而改动，容易影响核心支付业务的可靠性。
如果我们将同步调用替换成异步消息，机票支付系统发送机票支付成功的消息到消息中间件，出票系统、代金券系统从消息中间件订阅消息。这样一来，出票系统、代金券系统的宕机也就不会对机票支付系统造成任何影响了。专车系统想要知道机票支付完成这一事件，也只需要从消息中间件订阅消息即可，机票支付系统完全不需要做任何改动。
异步消息解耦，适合那些信息流单向流动（类似发布-订阅这样的），实时性要求不高的系统。常见的开源消息队列框架有：Kafka、RabbitMQ、RocketMQ。

## 线程池

线程池：如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间，且创建过多的线程会耗费系统资源，频繁的上下文切换也影响系统的性能。


# 实战分析

分析项目一：三个系统，A、B、C；A负责下单菜品:aaa，B负责接受A的下单请求，比根据A传递过来的aaa查询C得到菜品的详情，然后在继续下单；我们可以看出如果C系统挂了，整个下单流程就挂了，无法下单了；如何降级？B将C的菜品数据也存一份，正常情况下用C的菜品查询（C的菜品数据实时性更好一点），如果C挂了，B就用自己存的菜品，作为一种临时方案，达到可继续下单的目的，毕竟不能因为一个查询系统挂了导致整个下单功能不能用，这就是一种降级处理～

分析项目二：关闭重试机制；很多项目都有超时重试的机制，这种机制在服务已经负载过大、无法及时处理时，应当将重试逻辑关闭，避免因重试导致更严重的服务负担。

分析项目三：控制入口访问权限，白名单可用，当服务负载过大，可以通过在入口(比如拦截器中进行控制)控制流量，比如只允许vip客户访问，通过添加白名单方式来实现。

---
高可用设计注意事项
分析项目一：缓存，不要放在业务侧，要在数据源头设置，业务方只负责增删改；否则可能造成多个业务方的数据不一致；


# 云平台架构
当当架构部总监史海峰在其为架构师杂志写的开卷语中列举的架构师自我修养工整且字字在理，这里摘抄如下，也算是对自己的鼓励和激励：

- 以工程思维全面理解业务需求
- 基于模型和基础模式抽象简化
- 提出恰当可行的整体解决方案
- 在限定资源范围完成明确目标
- 满足业务需求且保证系统质量
- 在可预见的周期内具备扩展性
- 并在系统生命周期内持续演进

架构能力的成长没有捷径，也不可能成为所谓的理论家，一定要在项目实践中不断思考积累经验，了解技术和业务发展趋势，用强大的自学能力补足各种短板，严格要求自己，用最大的动力朝抵抗力最大的路径走。当然，最重要的，有责任心，要对自己交付的每一行代码，每一张图片，每一句文字都负责。

《分布式系统本质论》中把架构问题做了一个很好的总结：
- 互联网海量承载问题
    - 提高吞吐量：分层调用、异步并发
    - 降低延迟：缓存、NoSQL
- 大量服务器管理问题
    - 故障恢复和可扩展性：分布式目录服务、消息队列服务、分布式事务系统
    - 运维便利性：自动部署工具、统一日志系统
- 开发效率问题
    - 复杂的通信编程：微服务框架、异步编程工具
    - 大量功能模块需要分工：搭建 IaaS/PaaS/SaaS 云服务

## 负载均衡

负载均衡会和几乎所有的服务器主机连接，具体如何保证网络安全就是一个大问题，一个解决方案是利用 VPC。把主机和系统资源放置在 VPC(虚拟私有云) 网络中并指定内网网段，这样经负载均衡隔离，主机间与资源间只通过内网地址进行通信，就不至于暴露在公网。

负载均衡一般来说有一台服务器负责扮演负载均衡器的角色，是一个单点问题，我们可以为其做冗余备份，一旦出现问题，立刻进行替换。具体涉及的技术一般是七层(Nginx, HAProxy)/四层(LVS)负载均衡，可以根据分发需求与性能需求进行选择；用来监控后端服务器可以使用简单的心跳检查。

## 缓存系统
因为涉及到共享数据，就不得不面对数据完整性与一致性的问题。目前在设计的系统的业务场景和滴滴出行的需求类似，即大部分请求是大部分请求是对数据进行修改，少部分请求对数据进行读取。比方说司机地理位置的即时变化是大量写入，而用户查看周围车辆的情况是少量读取。

比方说可以保存一个 Map 的缓存，其中的键值对是司机的编号和司机当前的信息，在并发读写时这个 Map 是临界资源，用户量一上来，就不得不在处理锁的问题上耗费大量的时间，因为一锁就只能锁整个 Map，出现的问题和内存系统中 false sharing 有些类似。优化方法有两种，一种是类似于 **MySQL 分库**，把一个 Map 拆成多个 Map；另一种是把 **Map 转换为数组**，这样就可以针对每个数组元素加锁。后一种的精细度非常高，只不过锁本身的开销就会太大需要权衡。

滴滴的解决办法很巧妙，直接去掉了锁，利用数据签名技术，在每次读取前都进行校验，一旦校验失败，则认为是 cache miss，这样就在性能成本较低的条件下保证了数据完整性。

## 业务层
业务层最关键的问题其实就是服务质量。在版本稳定之后，可以考虑制作镜像，需要时开启并挂载到负载均衡即可，具体判断是否需要也可以通过 AutoScaling 来自动化这个过程，唯一需要注意的就是需要在实际环境中测试并设置好触发条件，前期肯定要投入不少人力。

而如果是开发中，服务器环境和程序快速变化迭代的时候，最好依赖自动化部署工具，按照我一贯的思路，选择简单的，所以 Ansible 是不错的选择。

还有一些需要注意的地方：

- 服务器连接无状态，因为负载均衡分发使得上下文不可靠，每次请求都需要带上所有信息，是在需要上下文，保存到缓存或数据库中
- 根据业务需求拆分服务，降低耦合性，即使子服务故障也不会影响系统的可用性，进行扩容时也更加灵活
- 不同子服务的调用异步化，利用消息队列来实现，好处在于消息队列可以把数据进行多向发送，满足业务需求的同时，还能导入数据分析平台，更加灵活

## 数据层
业务相关的场景大多都是对数据库的增删查改，如果单机数据库已经无法满足需求，可以利用缓存配合一致性哈希来处理热点数据的访问，或者增加节点。对于大的，用于后期分析或存档的文件，可以考虑直接通过消息队列保存到 AWS S3 中。

我个人是比较倾向于使用 NoSQL 数据库的，但是 NoSQL 没有所谓的万能钥匙，真正落地有太多可以优化的地方。主要有键值存储、文档数据库、列族存储、图数据库这么几类：列族重写入，文档更灵活，键值高性能，图处理关系。就目前的需求来说，图数据库配合文档数据库可能是比较好的选择，不过具体还需要进一步测试。

数据库的性能优化就是个大问题了，虽然 NoSQL 在一定程度上摆脱了传统迂腐的 SQL 设计，不过一个设计精良的存储方式，能减轻很大的性能压力。

## 后端框架
单来说就是 DRY 原则 - Don’t Repeat Yourself。代码中有重复和相似地方不可避免，把这部分抽取出来，只写必须要写的代码，也就是所谓的业务逻辑。

至于设计模式什么的，实话说我觉得有些过时，框架等于是在设计模式的基础上更上一层，极大提高了开发效率，但是却让开发者真正成为了搬砖的角色，个人觉得是非常痛苦的。

为什么痛苦？我觉得最不能忍受的就是『我』成为了『框架』的一部分，就好比『我』要用『框架』，最后却发现是『框架』在用『我』，类似的，和『我以为自己在玩游戏其实却是在被游戏玩』一个感觉。

# 数据平台设计
## 缘起
市场、运营、研发还是内部管理每天都会产生各种各样的数据及报表，一是用于监控各项事宜的运作情况，二是给决策提供更多有价值的信息。随着公司的快速发展与业务的不断扩大，产生和消费的数据也越来越多，传统手工以及简单的电子化统计已经不能满足各个部门的需求。我们来看看下面这三个问题：

- 从前收集数据和制作报表只需要半天，但是现在随着需要统计的内容增多，可能需要三天，也就是说数据最重要的时效性大打折扣
- 很多时候依靠单一部门的数据无法完成复杂的分析，但由于不同部门间天生较高的沟通成本，除了需要专人对接外，还需要走一定的流程，就把原本简单的工作变得复杂了，甚至因为各种推诿最终不了了之
- 不同部门的业务统计很多需求是一致或者类似的，只是统计的数据维度不同，这也意味着很多没有意义的重复劳动

为了解决上面提到的三个问题，一个统一的内部数据平台便应运而生。在此基础上，我们还从另外两个维度扩展了数据平台，一是更基础的服务监控，二是更高级的智能分析。更让我骄傲的是，整个项目的核心开发者只有三人，其中前端一人，后台及服务器两人（在此感谢曾为此项目付出过的其他同事）。

从白手起家到接入来自公司不同部门的十多项业务，从最初简单的原型到现在初具规模的系统，每次重构与架构调整，都是大家一起摸着石头过河淌出来的。虽然还有许多堆积的需求（缺人力呀），但只要地基打得好，就不怕盖高楼。

## 方向
第一步：**取代**。深入各个部门的业务流程与实践，了解第一手的需求。这里的取代，指的是利用数据平台自动化处理数据生成报表，把他们从繁重的人工统计中解放出来（用 Excel 仍然需要大量需要人工参与的中间过程）。只要各个部门把数据接入并打通数据流，我们就可以根据需求制作相应的页面（这里主要指长期且能够流程化处理的需求）。当他们需要具体数据与报表时，只需要登录网站查看即可。如果需要做一些临时分析，也可以把数据导出为 Excel 表格自行处理。

第二步：**超越**。在接入了不同部门的数据后，数据平台实际上拥有了综合不同数据源进行协同统计的可能，相当于把原先部门范围的数据辐射到了公司范围，各个部门都可以方便地利用更加全面的信息进行业务判断。所谓超越，指数据平台应该能完成原先 Excel 不能做（或者是难以做好）的深入分析。通过挖掘隐藏在数据背后的规律，给各个部门提供更加简单轻松的数据服务。

**重构**
在重构一开始，我给自己的设计定下的目标是：

- 尽量小的改动（影响面越小，可能出的问题就越少）
- 尽量就近服务（因为要提供全球范围内的服务，需要尽量优化线路）
- 减少跨机房数据同步量（尤其是跨海传输，带宽和稳定性所带来的额外成本很令人头疼）

在经历了一系列技术测试之后（详情见最后的链接），由我确定了日志部分的架构，而数据平台部分的架构由我的同事确定，后台部分最终选择的技术是：
**ELK Stack + Kafka + Spring MVC**
细节与原因如下：

- ELK Stack 在业界的实践中已被证明是比较靠谱的日志解决方案，加上原来的日志系统就已经采用了 ELK 方案，改动的成本较低
- 用 Logstash 取代了原先采用的系统级的 Rsyslog 用来传输日志，方便管理和配置（Logstash 的配置还是非常好写的）
- 加入了 Kafka 用作消息队列，把 Logstash 与 Elasticsearch 解耦，所有日志会先经过 Kafka，再由 Kafka 导入 Elasticsearch
- 出于性能考虑和其他一些因素的考虑，用基于 Java 的 Spring MVC 取代 Ruby on Rails，虽然 RoR 的开发效率很高，但是我和另一个核心开发人员都不熟悉 Ruby，所以转为 Java（至少好招人）



## 流程

### 采集与预处理
数据采集也许是最被低估的一个步骤。做过数据挖掘和模型分析的朋友应该都知道『Garbage in, Garbage out』这个简单的道理，数据模型可谓是数据平台的灵魂，而数据采集的方法和策略是数据模型的基础，一定要谨慎。如果要用一句话总结数据收集的思路，那就是：

>从用数据的角度出发收集数据，而不是反过来

具体的思路就有很多的扩展了，主要三点：**细粒度**、**围绕业务**、**概念层级一致**。

实现：

>日志的收集要跟不同团队的开发人员对接，了解真正有价值的参数，减少带宽与存储的消耗（毕竟日志中会有大量的冗余）
>提取日志中真正有价值的东西
>分词问题，string 字段要在 logstash 阶段就要设置为 not_index
>数据上报系统采用 ID 与密钥配对方式进行有效性校验，并且利用另外的数据库做权限控制，具体需要做到的粒度可以根据需求进行控制
>做多机房同步的时候尽量利用云服务本身提供的服务，自己做数据同步很辛苦，得不偿失
>不同的服务要有流量和数据量控制，保证不因为单个系统的不稳定而拖挂整个系统
>不同数据源如何对齐，公共字段需要仔细设置
>写日志的时候就要考虑未来的处理和应用，尤其是和已有数据源的对齐
>字段同名但类型不同导致的索引冲突问题
>设计埋点及统计字段时一定要基于具体的统计需求，不能为了打点而打点，字段是什么，后面要如何使用，不同的字段如何联系与互动，都需要事先想好
>专注于核心指标，不同指标的优先级是什么
>界面、事件和事件参数独立，但必须有公共的统计参数（最好两个一上，冗余保证后续数据清洗及验证的准确性）
>维护埋点，增加上报的信息量（同样大小的前提下），减少上报压力
>整个 ETL 过程需要建立固定的流程，为开发者准备好对应的接口、文档及测试系统。对于老数据的导入也需要有自动化可重复的工具链。而对于需要内网才能访问的系统，可以考虑在内网假设服务，然后走数据上报的流程进行数据汇总。

### 清洗与分类

这部分的内容需要大量的跨部门沟通，比如不同业务系统的日志信息筛选过滤，一是能够有效减少无意义的存储（日志中会有大量重复信息），二是为后续的存储与查询打下良好的基础。

我们目前是按照业务来进行划分的，不同的业务有不同的工作流，优点在于比较灵活，缺点在于没有把通用的部分抽出来（主要问题是目前公共的部分并不多）。

在这一步我们需要进行概念统一，比方说外部代号与内部代号的映射，这样在之后的统计分析中，我们能够以比较简洁的代码和模型去处理，而不用再去纠结格式与编号问题（与网络分层模型的思路一致）

实现：

这一层主要是进行分发与过滤，利用 Logstash 和 Kafka 的诸多特性，不需要写很多代码就可以完成。一些考虑有：

>根据服务区分 Kafka 中不同的 topic，来进行隔离，虽然是同一管道，但是也要尽量避免相互影响
>日志中可能有的非法字符以及过长的日志需要进行过滤，不然进入 ES 可能会导致问题
>需要有定期任务机制，清理不需要的数据，保存到 S3 这种比较便宜的存储中
>贯彻二八原则，20% 最有价值的数据进行结构化存储，剩下的以文本形式保存在云存储中，除非必要时，一般不需要动
>因为不需要跟外部系统交互，这部分其实需要做的东西不算太多，但是作为最重要的中转站，需要保证高可用性，这就需要对各个组件有一定深入了解了。

### 存储与查询
这一步唯一需要统一的就是『存储是为了查询』。存的时候随意存，查的时候肯定就没办法随意。我见过很多把 NoSQL 数据库当做 MySQL 来用的做法，那不就是自找苦吃嘛。

提一下『数据自治自洽』这个概念，自治指的是数据流的通畅以及自动根据多个系统的信息综合验证补全修复非正常数据，自洽指的是通过不同数据源得出的结论是说得通可以互相验证的。

实现：
>基于 Luence 的 ES 集群在处理中文的时候可能有坑，不过目前 IK 分词基本可以满足需求。其他需要注意的有
>ES 集群的监控一定要做，要好好做，可以采用业界流行的方案，也需要了解 ES 的基本 API 和相关设置。 
>如果可能的话，尽量多配几台机器，可以由专门的机器做不负责存储只负责调度的主节点以及只负责存储及查询的数据节点，具体需要根据需求进行调整
>很多暴露出来的问题，回归到最初都是因为存的时候太随意导致的，还是那句话，即使是类似 NoSQL 的存储，好的设计仍然无比重要
>监控部分需要和运维密切配合，以达到快速反应，保证服务质量的目的
>安全是非常重要的话题，内部系统的好处在于可以用白名单与二次验证的机制保证数据安全，具体的备份策略也需要仔细斟酌，找到一个平衡

### 展示与应用
展示与应用是数据平台价值的外现，也是各个部门实际能够体验感知的部分。根据前面提出的『取代-超越』两步走思路，注定是一个比较耗费人力且业务导向的工作。

>数据可视化的核心在于目标明确，而这个目标怎么找到，一定是和相关业务部门沟通出来的，不能是开发人员拍脑袋
>需要结合不同部门之前的业务实践，走之前提到了『取代-超越』两步战略
>随着数据量的增大，可以结合 Spark/Hadoop 等分布式计算框架来进行数据挖掘，当然，这是比较后面的工作了，可能需要专门找人来负责





## 版本控制

| Version | Action                   | Time       |
| ------- | ------------------------ | ---------- |
| 1.0     | Init                     | 2019-04-29T06:42:08-07:00|
