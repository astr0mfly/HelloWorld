---
date: "2019-04-29T06:19:10-07:00"
draft: ture
title: "Server-Interview"
tags: ["cpp", "golang", "mysql"]
#series: []
categories: [“编码人生”]
toc: true
---
# 如何找工作
## 重点细节
1. 准备好自我介绍，因为面试官往往没时间看你简历，或者一边听你自我介绍一边看简历，要让他们感到对 CS 的热爱，对工作的向往和对自己以往经历的自豪。要提的点应该包括： 
- 为什么是这个公司
- 为什么是这个职位
- 为什么是我
2. 交流非常非常重要，锻炼自己边说边写的能力，一面理清思路，一面让面试官了解自己在干什么
3. 放轻松，保持自信，说话大声点流利点
4. 在函数之前写几句文档
5. 一开始 validate input
6. 在合适的地方加注释
7. 面试完之后立即发 Thank you letter

## 技术面试的流程模板
- 明确题意：通过与面试官交流明确需要解答的问题。这部分主要为了让自己放松心态，并且给面试官留下你具有良好团队意识和交流能力的印象。
- 描述大体思路：描述你打算用什么算法，什么数据结构。主要是为了让面试官了解你的思维过程，如果你给出的解答与他想要的答案偏差太多，可以及时纠正。同时，描述思路也给了你自己思考的机会。
- 实现算法：先处理边界条件。对于重要的算法模块，加一些注释或者与面试官进行交流。目的是让面试官始终了解你在做什么，算法框架是什么。
- 跑一个测试：用一个测试用例(test case)走一遍你写的程序。目的在于和面试官一起确保你的算法是有效的，可以在过程中及时发现并纠正自己的错误。同时，给面试官留下你有写单元测试习惯的良好印象。
描述算法复杂度，回答面试官的问题

## 总体策略

越好的公司越要放到最后面试。因为你每面试一次，尤其是 onsite，基本上会都有新的感悟，都会发现自己之前准备上的不足，而这个过程本身就是一种提高，所以说基本上是越面越强的。

投简历也要抓住时机不要错过机会：许多大公司招new grad都是在某一特定时间内，过了这段招满了就不招了。今年的例子比如微软思科雅虎。这三家公司我都没拿到面试。不过好在flg都是全年招人的。

## 简历怎么投
推荐顺序是内推 > 直接找recruiter > 网申，非常不建议网申（小公司除外，初期我们还是需要投一些小公司练手的，海投的途径我主要用过以下几个，indeed，Linkedin，jobvite），虽然不是所有网申都石沉大海，但是网申的效率远比内推或者直接找recruiter联系低得多，直接找recruiter是个很不错的途径。

如何找内推或者recruiter的联系方式？内推基本有两种途径找，一是找自己的学长学姐，无论是之前就认识还是在LinkedIn上现加的，一般客气一点人家还是愿意内推的，毕竟大家出来混都不容易。二是去各大论坛找内推帖，绝大多数的内推帖都还是很靠谱的，至于如何搜，“site:论坛域名 公司名+内推”屡试不爽。

recruiter的联系方式也有两种途径，一是一般来说周围会有一些正在面或者已经面过这一公司的同学，面试过程中会有一些recruiter联系过他们，把这些recruiter的邮箱要过来就好。二是去LinkedIn上搜。

## Interview Preparation Grid
针对每个 project，列出以下几个方面的相关总结关键词，一定要是特别精炼的短语，不要长篇大论的句子：
- Challenges
- Mistakes/Failures
- Enjoyed
- Leadership
- Conflicts
- What You'd Do Differently

## 细致准备重点项目
两三个 project 要重点准备，除了上面提到的方面，还需要能够细致介绍：
- Technical decisions
- Choices of technologies(tradeoff)

## 常见面试问题
**Tell me about yourself**
可以按照如下的方式组织准备
- Current Role [Headline Only]: I'm a graduate student in Carnegie Mellon University majored in Electrical and Computer Engineering.
- College: I majored in Software Engineering for my undergraduate and had a 6-month internship in Microsoft.
- Current Role [Details]: Learning both the software and the hardware, I know how to write great code on different platforms, especially computer vision and machine learning.
- Outside of Work: Outside of work, I've been working on mobile app development. One of my app named League of Legends Wiki has over 700K downloads with an average rating of 4.5 out of 5.
- Wrap Up: I'm looking for a full time job as I'll get my master degree next year and your company caught my eye. I've always been interested in creating something new so I'd like to talk more with you about the xxx position in your company.

注意见缝插针描述自己的闪光点，让人感兴趣和印象深刻。

**What are your weaknesses**

回答技巧：实话实话，不要装逼。点明缺点之后重点强调自己是如何克服的。

个人参考答案：Sometimes, I may lose focus on the whole project while plunge into very detailed problems. It's not bad to spend more time finding the best solution. But it may be better to finish the most critical part first. As it is, I'll draw the whole design on paper and put it just in front of the monitor so that I can easily find out what I should focus on.

## 问面试官的问题
**Genuine Questions**
跟公司，工作有关的问题，例如
1. What brought you to this company? //公司给你带来了什么？
2. What has been most challenging for you? //你最大的挑战如何？
3. Do you have program managers? If there is a conflicts between developer and managers, how do you solve it? //技术路线与管理路线的抉择

**Insightful Questions**
这类问题通常需要对公司有比较深入的研究，例如
1. I noticed that you use technology X. How do you handle problem Y? //对于X技术，怎么处理Y问题
2. Why did this product choose to use technology X over technology Y? //X技术与Y技术怎么选择

**Passion Questions**
展现激情和学习兴趣
I'm very interested in machine learning, and I'd love to learn more about it. What opportunities are there at this company to learn about this? //技术发展路线
I'm not familiar with technology X, but it sounds like a very interesting solution. Could you tell me a bit more about how it works? //技术领域的工作详情

## 回答问题技巧

不要过多涉及细节，而是用数据对比或者面试官能听懂的内容来介绍

多说 I 而不是 We，说自己扮演的角色和所做的工作

结构式问题回答

- S.A.R. (Situation, Action, Result)
- outline the situation
- explain the actions you took
- describe the result

Action 部分是最需要着力的地方，逻辑清晰，分点叙述，主要不要涉及过多细节。

精雕细琢故事部分，字里行间体现出自己的一些特质，如：

Initiative/Leadership, Empathy, 

Compassion, Humility, Teamwork/Helpfulness




# 面试经验总结
## 编程语法相关

## 计算机网络
- Q：epoll/select 模型的底层实现 区别 epoll的lt和et模式及对缓冲区的理解 错误处理 
    >1
- Q：网络字节序 大小端 
    >A：ntohl ntohs htonl htons  可以用这四个函数进行字节序转换,网络字节序 为大端  主机字节序为小端(一般) 

- Q:进程池与线程池 实现一个线程池（写代码） 
  >用posix条件变量和信号量实现
- Q:生产者消费者模型问题 实现一个什么问题记不清了 涉及了pv操作 同步与互斥 
  >1
- Q:用文件实现进程之间的通信 (写伪代码) 
  >1
- Q:一个机器最大能连接的并发数目
  >通过通信的四元组去回答 ip1 ip2 port1 port2 分别去匹配 具体能并非链接多少与机器的内存有关 1G大约10万条 2G大约20万条 
- Q:利用信号实现 异步的i/o模型 主要不让进程阻塞
  >1
- Q:信号 信号量 条件变量 hashmap
  >1
- Q:http的一些问题 memched 问题 具体记不清了
  >1
- Q:数据传输时间 buf满了怎么处理 
  >1
- Q:断电续传 用lseek() sendfile() 
  >1
- Q:实现一个多线程代码 交叉打印出AB 
  >1
- Q:influxDB是什么 大致操作指令 cjson lib_curb这些开源的源代码看过没有
  >1
- Q:apache的底层实现 主要是i/o模型和异步 异步的实现 
  >1
- Q:UDP的应用场景，UDP怎么实现可靠传输
  >1
- Q:LRU Cache的实现，LeetCode原题
  >1
- Q:操作系统中有哪些你觉得有意思的东西 
  >1
- Q:三个房间，只有一个房间里面有车，你选一个，然后上帝打开另一个没车的，问你改不改主意。经典问题，答案是要改
  >1
- Q:画TCP三次握手、四次挥手 
  >1
- Q:分段分页机制 
  >1
- Q:C++垃圾回收，shared_ptr的引用计数出现循环引用怎么办，
  >1
- Q:实现稀疏矩阵相乘 
  >1
- Q:C中的malloc和free做了哪些事情，free怎么知道free多长，C++中的delete又怎么知道delete多长
  >malloc/free是C/C++语言的标准库函数，new/delete是C++的运算符
  >new能够自动分配空间大小，malloc传入参数
  >new/delete能进行对对象进行构造和析构函数的调用进而对内存进行更加详细的工作，而malloc/free不能。
  >既然new/delete的功能完全覆盖了malloc/free，为什么C++还保留malloc/free呢？因为C++程序经常要调用C函数，而C程序只能用malloc/free管理动态内存。
  >分配内存块的时候，内存块首尾有额外的辅助空间表示内存长度。

- Q:c++的static关键字的作用(我从elf结构,链接过程来回答) 
  >在函数体，一个被声明为静态的变量在这一函数被调用过程中维持其值不变。
  >在模块内（但在函数体外），一个被声明为静态的变量可以被模块内所用函数访问，但不能被模块外其它函数访问。它是一个本地的全局变量。
  >在模块内，一个被声明为静态的函数只可被这一模块内的其它函数调用。那就是，这个函数被限制在声明它的模块的本地范围内使用
  >类内的static成员变量属于整个类所拥有，不能在类内进行定义，只能在类的作用域内进行定义
  >类内的static成员函数属于整个类所拥有，不能包含this指针，只能调用static成员函数

- Q:static全局变量与普通的全局变量有什么区别?static局部变量和普通局部变量有什么区别?static函数与普通函数有什么区别?
  >static全局变量与普通的全局变量有什么区别：static全局变量只初使化一次，防止在其他文件单元中被引用;
  >static局部变量和普通局部变量有什么区别：static局部变量只被初始化一次，下一次依据上一次结果值；
  >static函数与普通函数有什么区别：static函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝

- Q:内联函数跟普通函数区别(从反汇编角度来回答) 
  > 内联函数是用来消除函数调用时的时间开销。频繁被调用的短小函数非常受益。
  > 宏定义不检查函数参数，返回值什么的，只是展开，相对来说，内联函数会检查参数类型，所以更安全。
  > 宏是由预处理器对宏进行替代，而内联函数是通过编译器控制来实现的
  > 内联函数属于编译优化，直接在代码段展开。
  > 普通函数有jump，即指针跳转，上下文切换。

- Q:STL中的迭代器失效问题 
  >1
- Q:指针,引用区别(反汇编分析,其实汇编指令实现都一样,可以把引用看做编译器管理的指针,语法糖) 
  >引用是直接访问，指针是间接访问
  >引用是变量的别名，本身不单独分配自己的内存空间，而指针有自己的内存空间
  >引用绑定内存空间（必须赋初值），是一个变量别名不能更改绑定，可以改变对象的值。
  >总的来说：引用既具有指针的效率，又具有变量使用的方便性和直观性

- Q:父子进程fork时,打开的文件的偏移量是否是相同的(从内核角度看,父子进程fork会将file文件复制一份,所以肯定会的) 
  >1
- Q:作者：赛罗奥特曼~
链接：https://www.nowcoder.com/discuss/26045?type=2&order=3&pos=135&page=2
来源：牛客网

Linux虚拟地址空间(3G以上内核,因为进程创建时,内核的页表全部拷贝到进程第768页目录项以上的,3G以下则是代码段(.init节,.text节,.rodata节),数据段(.data节,.bss节),堆(brk指针),栈从3G往下)
  >1
- Q:找20个最大数，内存够与不够该怎么办
  >1
- Q:多线程一个线程往一个数据中输入一些数字，另一个线程取出最大的两个数，用什么算法。
  >1
- Q:堆的创建过程，怎么将无序的数组转换成一个堆 
  >1
- Q:iptables的实现原理
  >1
- Q:怎么统计出现次数最多的数据（hash，前缀树）
  >1
- Q:对于迭代器和其他模板对象使用前缀形式 (++i) 的自增, 自减运算符.
  >不考虑返回值的话, 前置自增 (++i) 通常要比后置自增 (i++) 效率更高. 因为后置自增 (或自减) 需要对表达式的值 i 进行一次拷贝. 如果 i 是迭代器或其他非数值类型, 拷贝的代价是比较大的. 

- Q:我们强烈建议你在任何可能的情况下都要使用 const
  >大家更容易理解如何使用变量. 编译器可以更好地进行类型检测, 相应地, 也能生成更好的代码. 人们对编写正确的代码更加自信, 因为他们知道所调用的函数被限定了能或不能修改变量值. 即使是在无锁的多线程编程中, 人们也知道什么样的函数是安全的.const 是入侵性的: 如果你向一个函数传入 const 变量, 函数原型声明中也必须对应 const 参数 (否则变量需要 const_cast 类型转换), 在调用库函数时显得尤其麻烦.
  >1）在定义的时候必须进行初始化
  >2）指针可以是const  指针，也可以是指向const对象的指针
  >3）定义为const的形参，即在函数内部是不能被修改的
  >4）类的成员函数可以被声明为常成员函数，不能修改类的成员变量
  >5）类的成员函数可以返回的是常对象，即被const声明的对象
  >6）类的成员变量是常成员变量不能在声明时初始化，必须在构造函数的列表里进行初始化

- Q:在 C++11 里，用 constexpr 来定义真正的常量，或实现常量初始化。
  >如今 constexpr 就可以定义浮点式的真・常量，不用再依赖字面值了；也可以定义用户自定义类型上的常量；甚至也可以定义函数调用所返回的常量。若过早把变量优化成 constexpr 变量，将来又要把它改为常规变量时，挺麻烦的；当前对 constexpr 函数和构造函数中允许的限制可能会导致这些定义中解决的方法模糊。
- Q:整数用 0, 实数用 0.0, 指针用 nullptr 或 NULL, 字符 (串) 用 '\0'.
  >实际上，一些 C++ 编译器对 NULL 的定义比较特殊，可以输出有用的警告，特别是 sizeof(NULL) 就和 sizeof(0) 不一样。

- Q:尽可能用 sizeof(varname) 代替 sizeof(type)
  >使用 sizeof(varname) 是因为当代码中变量类型改变时会自动更新. 您或许会用 sizeof(type) 处理不涉及任何变量的代码，比如处理来自外部或内部的数据格式，这时用变量就不合适了。

- Q:程序员必须会区分 auto 和 const auto& 的不同之处，否则会复制错东西。
  >用 auto 绕过烦琐的类型名，只要可读性好就继续用，别用在局部变量之外的地方。

- Q:基类的析构函数写成virtual虚析构函数
  >派生类中有资源需要回收，而在编程中采用多态，由基类的指针指向派生类，则在释放的时候，如果基类的析构函数不是virtual，则派生类的析构函数得不到释放
  >C++中基类采用virtual虚析构函数是为了防止内存泄漏。具体地说，如果派生类中申请了内存空间，并在其析构函数中对这些内存空间进行释放。假设基类中采用的是非虚析构函数，当删除基类指针指向的派生类对象时就不会触发动态绑定，因而只会调用基类的析构函数，而不会调用派生类的析构函数。那么在这种情况下，派生类中申请的空间就得不到释放从而产生内存泄漏。所以，为了防止这种情况的发生，C++中基类的析构函数应采用virtual虚析构函数。
  >如果静态类型绑定的指针，即指针的静态类型就是“派生类”本身，则析构的时候回先调用派生来析构，然后调用基类析构。

```cpp
//动态绑定
int main() {  
  Base* base[2] = {  
    new Derived1(),  
    new Derived2("Bob")        
  };  

  for (int i = 0; i != 2; ++i) {  
    delete base[i];      //直接主动析构基类
  }  
  return 0;  
}
```

- Q:volatile是干啥用的，（必须将cpu的寄存器缓存机制回答的很透彻）
  >访问寄存器比访问内存单元要快,编译器会优化减少内存的读取，可能会读脏数据。声明变量为volatile，编译器不再对访问该变量的代码优化，仍然从内存读取，使访问稳定。
  >使用实例如下(并行设备的硬件寄存器（如：状态寄存器）, 一个中断服务子程序中会访问到的非自动变量(Non-automatic variables), 多线程应用中被几个任务共享的变量)

- Q:一个参数既可以是const还可以是volatile吗？
  >可以。一个例子是只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。

- Q:一个指针可以是volatile 吗？
  >一个例子当中断服务子程序修该一个指向一个buffer的指针时

下面的函数有什么错误：
int square(volatile int *ptr) {
return *ptr * *ptr;
}
下面是答案：
这段代码有点变态。这段代码的目的是用来返指针*ptr指向值的平方，但是，由于*ptr指向一个volatile型参数，编译器将产生类似下面的代码：
int square(volatile int *ptr){
int a,b;
a = *ptr;
b = *ptr;
return a * b;
}
由于*ptr的值可能被意想不到地该变，因此a和b可能是不同的。结果，这段代码可能返不是你所期望的平方值！正确的代码如下：
long square(volatile int *ptr){
int a;
a = *ptr;
return a * a;
}

- Q:关于静态内存分配和动态内存分配的区别及过程
  >静态内存分配是在编译时完成的，不占用CPU资源；动态分配内存运行时完成，分配与释放需要占用CPU资源；
  >静态内存分配是在栈上分配的，动态内存是堆上分配的；
  >动态内存分配需要指针或引用数据类型的支持，而静态内存分配不需要；
  >静态内存分配是按计划分配，在编译前确定内存块的大小，动态内存分配运行时按需分配。
  >静态分配内存是把内存的控制权交给了编译器，动态内存把内存的控制权交给了程序员；
  >静态分配内存的运行效率要比动态分配内存的效率要高，因为动态内存分配与释放需要额外的开销；动态内存管理水平严重依赖于程序员的水平，处理不当容易造成内存泄漏。

- Q:头文件中的 ifndef/define/endif 干什么用？
  >预处理，防止头文件被重复使用，包括#pragma once都是这样的
  >前者对语言兼容性好，后者依靠编译器实现。

- Q:宏定义求两个元素的最小值
  >#define MIN(A,B) ((A) <= (B) ? (A) : (B))

- Q:分别设置和清除一个整数的第三位？
  >```cpp
    #define BIT(n) (0x1 << n)
    #difine SET_BIT(a, n) (a |= BIT(3))
    #difine CLR_BIT(a, n) (a &= ~BIT(3))
   ```
- Q:用预处理指令#define 声明一个常数，用以表明1年中有多少秒
  >`#define SECONDS_PER_YEAR (60 * 60 * 24 * 365)UL`

- Q: 预处理器标识#error的目的是什么？
  >抛出错误提示，标识外部宏是否被定义!

- Q:嵌入式系统中经常要用到无限循环，你怎么样用C编写死循环呢？
  >```cpp
    while(1){}

    for(;;){}

    Loop:
    ...
    goto Loop;
  
   ```
- Q:一个有10个指针的数组，该指针指向一个函数，该函数有一个整型参数并返回一个整型数
  >int (*afunc[10])(int);

- Q:strcmp函数实现
  >```cpp
    int strcmp(const char *str1,const char *str2){
      /*不可用while(*str1++==*str2++)来比较，当不相等时仍会执行一次++，
      return返回的比较值实际上是下一个字符。应将++放到循环体中进行。*/
      while(*str1 == *str2){
          if(*str1 == '\0')
              return0;
          
          ++str1;
          ++str2;
      }
      return *str1 - *str2;
    }
   ```

- Q:strlen
  >```cpp
    int strlen(const char *str){
      assert(str != NULL);
      int len = 0;
      while (*str ++ != ‘\0′)
          ++ len;
      return len;
    }
  
   ```

- Q:string实现
  >```cpp
    class String{
    public:
      String(const char *str = NULL);
      String(const String &other);//拷贝构造函数

      Strign& operator=(String &other);//赋值函数
      ~String(void);

    private:
    char* m_str; 
    };

    String::String(const char* str){
      if(str==NULL) { //如果str为NULL，存空字符串
          m_str = new char[1]; //分配一个字节
          *m_str = ‘\0′; //赋一个’\0′
      }else{
        str = new char[strlen(str) + 1];//分配空间容纳str内容
        strcpy(m_str, str); //复制str到私有成员m_str中
      }
    }
    String::~String(){
      if(m_str!=NULL) {    //如果m_str不为NULL，释放堆内存
          delete [] m_str;
          m_str = NULL;
      }
    }

    String::String(const String &other){
      m_str = new char[strlen(other.m_str)+1]; //分配空间容纳str内容
      strcpy(m_str, other.m_str); //复制other.m_str到私有成员m_str中 
    }

    String & String::operator=(String &other){
    if(this == &other){ //若对象与other是同一个对象，直接返回
        return *this
    }
    delete [] m_str; //否则，先释放当前对象堆内存
    m_str = new char[strlen(other.m_str)+1]; //分配空间容纳str内容
    strcpy(m_str, other.m_str); //复制other.m_str到私有成员m_str中
    return *this；
   ```

- Q:用struct关键字与class关键定义类以及继承的区别
  >默认的访问级别和默认的继承级别 class都是private, struct是public

- Q: 虚函数与纯虚函数区别
  >虚函数在子类里面也可以不重载的；但纯虚必须在子类去实现
  >带纯虚函数的类叫虚基类也叫抽象类，这种基类不能直接生成对象，只能被继承，重写虚函数后才能使用，运行时动态动态绑定！

- Q:深拷贝与浅拷贝
  >浅拷贝：`char ori[]=“hello”；char *copy=ori；`
  >深拷贝：`char ori[]="hello";  char *copy=new char[];  copy=ori;`
  >浅拷贝可能出现的问题：调用函数析构的时，会造成同一份资源析构2次,任何一方的变动都会影响到另一方。同一个空间，第二次释放失败，导致无法操作该空间，造成内存泄漏。

- Q: stl各容器的实现原理
  >Vector顺序容器，是一个动态数组，支持随机插入、删除、查找等操作，在内存中是一块连续的空间。在原有空间不够情况下自动分配空间，增加为原来的两倍。vector随机存取效率高，但是在vector插入元素，需要移动的数目多，效率低下。对vector空间重新配置，指向原vector的所有迭代器就都失效了。
  >Map关联容器，以键值对的形式进行存储，方便进行查找。关键词起到索引的作用，值则表示与索引相关联的数据。红黑树的结构实现，插入删除等操作都在O(logn)时间内完成。
  >Set是关联容器，set每个元素只包含一个关键字。set支持高效的关键字检查是否在set中。set也是以红黑树的结构实现，支持高效插入、删除等操作。

- Q:C++特点是什么，多态实现机制？（面试问过）多态作用？两个必要条件？
  >C++中多态机制主要体现在两个方面，一个是函数的重载，一个是接口的重写。
  >每一个对象内部都有一个虚表指针，该虚表指针被初始化为本类的虚表。所以在程序中，不管你的对象类型如何转换，但该对象内部的虚表指针是固定的，所以呢，才能实现动态的对象函数调用，这就是C++多态性实现的原理。
  >多态的基础是继承，需要虚函数的支持，简单的多态是很简单的。子类继承父类大部分的资源，不能继承的有构造函数，析构函数，拷贝构造函数，operator=函数，友元函数等等
  >隐藏实现细节，代码能够模块化；2. 接口重用：为了类在继承和派生的时候正确调用。
  >1. 一个基类的指针或者引用指向派生类的对象；2.虚函数

- Q:多重继承有什么问题? 怎样消除多重继承中的二义性?
  >增加程序的复杂度，使程序的编写和维护比较困难，容易出错；
  >继承类和基类的同名函数产生了二义性，同名函数不知道调用基类还是继承类，C++中使用虚函数解决这个问题,虚继承解决菱形继承问题。
  >继承过程中可能会继承一些不必要的数据，对于多级继承，可能会产生数据很长

- Q:什么叫静态关联，什么叫动态关联
  >多态中，静态关联是程序在编译阶段就能确定实际执行动作，程序运行才能确定叫动态关联

- Q:什么叫智能指针?常用的智能指针有哪些？智能指针的实现？
  >智能指针是一个存储指向动态分配（堆）对象指针的类，构造函数传入普通指针，析构函数释放指针。栈上分配，函数或程序结束自动释放，防止内存泄露。使用引用计数器，类与指向的对象相关联，引用计数跟踪该类有多少个对象共享同一指针。创建类的新对象时，初始化指针并将引用计数置为1；当对象作为另一对象的副本而创建，增加引用计数；对一个对象进行赋值时，减少引用计数，并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数，当引用计数减至0，则删除基础对象。
  >C++11或boost的shared_ptr，基于引用计数的智能指针。可随意赋值，直到内存的引用计数为0的时候这个内存会被释放。还有Weak_ptr

- Q:介绍一下函数的重载
  >重载是在不同类型上作不同运算而又用同样的名字的函数。重载函数至少在参数个数，参数类型， 或参数顺序上有所不同。

- Q:.派生新类的过程要经历三个步骤
  >1.吸收基类成员    2.改造基类成员    3.添加新成员

- Q:多态性体现都有哪些？动态绑定怎么实现？
  >多态性是一个接口,多种实现，是面向对象的核心。 编译时多态性：通过重载函数实现。运行时多态性：通过虚函数实现,结合动态绑定。

- Q:C++中哪些不能是虚函数？
  >普通函数只能重载，不能被重写，因此编译器会在编译时绑定函数。
  >构造函数是知道全部信息才能创建对象，然而虚函数允许只知道部分信息
  >内联函数在编译时被展开，虚函数在运行时才能动态绑定函数。
  >友元函数 因为不可以被继承。
  >静态成员函数 只有一个实体，不能被继承。父类和子类共有。

- Q:类型转换有哪些？各适用什么环境？dynamic_cast转换失败时，会出现什么情况(对指针，返回NULL.对引用，抛出bad_cast异常)？
  > 静态类型转换，static_cast，基本类型之间和具有继承关系的类型。
  > 常量类型转换，const_cast, 去除指针变量的常量属性。
  > 无法将非指针的常量转换为普通变量。
  > 动态类型转换，dynamic_cast，运行时进行转换分析的，并非在编译时进行。dynamic_cast转换符只能用于含有虚函数的类。dynamic_cast用于类层次间的向上转换和向下转换，还可以用于类间的交叉转换。在类层次间进行向上转换，即子类转换为父类，此时完成的功能和static_cast是相同的，因为编译器默认向上转换总是安全的。向下转换时，dynamic_cast具有类型检查的功能，更加安全。类间的交叉转换指的是子类的多个父类之间指针或引用的转换。该函数只能在继承类对象的指针之间或引用之间进行类型转换，或者有虚函数的类。


- Q:为什么要用static_cast转换而不用c语言中的转换？
  >Static_cast转换，它会检查类型看是否能转换，有类型安全检查。

- Q: 操作符重载（+操作符），具体如何去定义？
  >除了类属关系运算符”.”、成员指针运算符”.*”、作用域运算符”::”、sizeof运算符和三目运算符”?:”以外，C++中的所有运算符都可以重载。
  >重载为类的成员函数和重载为类的非成员函数。参数个数会不同，因为this指针。


- Q: explicit是干什么用的 ?
  >构造器 ，可以阻止不应该允许的经过转换构造函数进行的隐式转换的发生。explicit是用来防止外部非正规的拷贝构造的，要想不存在传值的隐式转换问题。

- Q:内存溢出有那些因素？
  > 使用非类型安全(non-type-safe)的语言如 C/C++ 等。
  > 以不可靠的方式存取或者复制内存缓冲区
  > 编译器设置的内存缓冲区太靠近关键数据结构

- Q:必须使用初始化列表初始化数据成员的情况
  >1.是对象的情况；2.const修饰的类成员；3.引用成员数据；类成员变量的初始化不是按照初始化表顺序被初始化，是按照在类中声明的顺序被初始化的。

- Q:深入谈谈内存，堆和栈
  >分配和管理方式不同 ：堆是动态分配的，其空间的分配和释放都由程序员控制。栈由编译器自动管理。栈有两种分配方式：静态分配和动态分配。静态分配由编译器完成，比如局部变量的分配。动态分配由alloca()函数进行分配，但是栈的动态分配和堆是不同的，它的动态分配是由编译器进行释放，无须手工控制。
  >产生碎片不同 :对堆来说，频繁的new/delete或者malloc/free势必会造成内存空间的不连续，造成大量的碎片，使程序效率降低。对栈而言，则不存在碎片问题，因为栈是先进后出的队列，永远不可能有一个内存块从栈中间弹出。
  >生长方向不同 : 堆是向着内存地址增加的方向增长的，从内存的低地址向高地址方向增长。 栈是向着内存地址减小的方向增长，由内存的高地址向低地址方向增长。

- Q:内存的静态分配和动态分配的区别？
  >时间不同。静态分配发生在程序编译和连接时。动态分配则发生在程序调入和执行时。
  >空间不同。堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。alloca，可以从栈里动态分配内存，不用担心内存泄露问题，当函数返回时，通过alloca申请的内存就会被自动释放掉。


- Q: 静态成员函数和数据成员有什么意义？
  >非静态数据成员，每个对象都有自己的拷贝。而静态数据成员被当作是类的成员，是该类的所有对象所共有的，在程序中只分配一次内存只有一份拷贝，所以对象都共享，值对每个对象都是一样的，它的值可以更新。
  >静态数据成员存储在全局数据区，所以不能在类声明中定义，应该在类外定义。由于它不属于特定的类对象，在没有产生类对象时作用域就可见，即在没有产生类的实例时，我们就可以操作它。
  >静态成员函数与静态数据成员一样，都是在类的内部实现，属于类定义的一部分。因为普通成员函数总是具体的属于具体对象的，每个有this指针。静态成员函数没有this指针，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数。静态成员之间可以互相访问，包括静态成员函数访问静态数据成员和访问静态成员函数；
  >非静态成员函数可以任意地访问静态成员函数和静态数据成员；
  >没有this指针的额外开销，静态成员函数与类的全局函数相比，速度上会有少许的增长；
  >调用静态成员函数，可以用成员访问操作符(.)和(->)为一个类的对象或指向类对象的指调用静态成员函数。

- Q:析构函数可以抛出异常吗？为什么不能抛出异常？除了资源泄露，还有其他需考虑的因素吗？
  >C++标准指明析构函数不能、也不应该抛出异常。C++异常处理模型最大的特点和优势就是对C++中的面向对象提供了最强大的无缝支持。那么如果对象在运行期间出现了异常，C++异常处理模型有责任清除那些由于出现异常所导致的已经失效了的对象(也即对象超出了它原来的作用域)，并释放对象原来所分配的资源， 这就是调用这些对象的析构函数来完成释放资源的任务，所以从这个意义上说，析构函数已经变成了异常处理的一部分。
  >如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。
  >通常异常发生时，c++的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。

- Q:拷贝构造函数作用及用途？什么时候需要自定义拷贝构造函数？
  >一般如果构造函数中存在动态内存分配，则必须定义拷贝构造函数。否则，可能会导致两个对象成员指向同一地址，出现“指针悬挂问题”。

- Q:100万个32位整数，如何最快找到中位数。能保证每个数是唯一的，如何实现O(N)算法？
  >内存足够时：快排 
  >内存不足时：分桶法

- Q:OFFSETOF(s, m)的宏定义，s是结构类型，m是s的成员，求m在s中的偏移量
  >`#define OFFSETOF（s, m） size_t（&((s*)0)->m）`

## 服务器编程
- Q:.多线程和多进程的区别（重点 必须从cpu调度，上下文切换，数据共享，多核cup利用率，资源占用，等等各方面回答，然后有一个问题必须会被问到：哪些东西是一个线程私有的？答案中必须包含寄存器，否则悲催）！
  >进程数据是分开的:共享复杂，需要用IPC，同步简单；多线程共享进程数据：共享简单，同步复杂
  >进程创建销毁、切换复杂，速度慢 ；线程创建销毁、切换简单，速度快 ,30倍差距
  >进程占用内存多， CPU利用率低；线程占用内存少， CPU利用率高
  >进程编程简单，调试简单；线程 编程复杂，调试复杂
  >进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉
  >进程适应于多核、多机分布；线程适用于多核
  >线程所私有的：线程id、寄存器的值、栈、线程的优先级和调度策略、线程的私有数据、信号屏蔽字、errno变量


- Q:自旋锁和互斥锁的区别？
  >当锁被其他线程占用时，其他线程并不是睡眠状态，而是不停的消耗CPU，获取锁；互斥锁则不然，保持睡眠，直到互斥锁被释放激活
  >自旋锁，递归调用容易造成死锁，对长时间才能获得到锁的情况，使用自旋锁容易造成CPU效率低，只有内核可抢占式或SMP情况下才真正需要自旋锁。

- Q:进程间通信和线程间通信
  >1）管道 2）消息队列 3)共享内存 4)信号量 5)套接字 6)条件变量

- Q:多线程程序架构，线程数量应该如何设置？
  > 应尽量和CPU核数相等或者为CPU核数+1的个数

- Q:网络编程设计模式，reactor/proactor/半同步半异步模式？
  >eactor模式：同步阻塞I/O模式，注册对应读写事件处理器，等待事件发生进而调用事件处理器处理事件。 proactor模式：异步I/O模式。Reactor和Proactor模式的主要区别就是真正的读取和写入操作是有谁来完成的，Reactor中需要应用程序自己读取或者写入数据，Proactor模式中，应用程序不需要进行实际读写过程。
  >Reactor是：主线程往epoll内核上注册socket读事件，主线程调用epoll_wait等待socket上有数据可读，当socket上有数据可读的时候，主线程把socket可读事件放入请求队列。睡眠在请求队列上的某个工作线程被唤醒，处理客户请求，然后往epoll内核上注册socket写请求事件。主线程调用epoll_wait等待写请求事件，当有事件可写的时候，主线程把socket可写事件放入请求队列。睡眠在请求队列上的工作线程被唤醒，处理客户请求。
  >Proactor:主线程调用aio_read函数向内核注册socket上的读完成事件，并告诉内核用户读缓冲区的位置，以及读完成后如何通知应用程序，主线程继续处理其他逻辑，当socket上的数据被读入用户缓冲区后，通过信号告知应用程序数据已经可以使用。应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求之后调用aio_write函数向内核注册socket写完成事件，并告诉内核写缓冲区的位置，以及写完成时如何通知应用程序。主线程处理其他逻辑。当用户缓存区的数据被写入socket之后内核向应用程序发送一个信号，以通知应用程序数据已经发送完毕。应用程序预先定义的数据处理函数就会完成工作。
  >半同步半异步模式：上层的任务（如：数据库查询，文件传输）使用同步I/O模型，简化了编写并行程序的难度。而底层的任务（如网络控制器的中断处理）使用异步I/O模型，提供了执行效率。


- Q:有一个计数器，多个线程都需要更新，会遇到什么问题，原因是什么，应该如何做？如何优化？
  >有可能一个线程更新的数据已经被另外一个线程更新了，更新的数据就会出现异常，可以加锁，保证数据更新只会被一个线程完成。

- Q:如果select返回可读，结果只读到0字节，什么情况？
  >某个套接字集合中没有准备好，可能会select内存用FD_CLR清为0.

- Q:connect可能会长时间阻塞，怎么解决?
  >1.使用定时器；（最常用也最有效的一种方法）
  >2.采用非阻塞模式：设置非阻塞，返回之后用select检测状态。

- Q:keepalive 是什么东西？如何使用？
  >keepalive，是在TCP中一个可以检测死连接的机制。
  >如果主机可达，对方就会响应ACK应答，就认为是存活的
  >如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。
  >如果可达，但应用程序崩溃，对方就发FIN消息。
  >如果对方主机不响应ack, rst，继续发送直到超时，就撤消连接。默认二个小时。

- Q:socket什么情况下可读？
  > 1.socket接收缓冲区中已经接收的数据的字节数大于等于socket接收缓冲区低潮限度的当前值;对这样的socket的读操作不会阻塞,并返回一个大于0的值(准备好读入的数据的字节数).
  >2.连接的读一半关闭(即:接收到对方发过来的FIN的TCP连接),并且返回0; 
  >3.socket收到了对方的connect请求已经完成的连接数为非0.这样的soocket处于可读状态； 
  >4.异常的情况下socket的读操作将不会阻塞,并且返回一个错误(-1)。

- Q:udp调用connect有什么作用？
  >因为UDP可以是一对一，多对一，一对多，或者多对多的通信，所以每次调用sendto()/recvfrom()时都必须指定目标IP和端口号。通过调用connect()建立一个端到端的连接，就可以和TCP一样使用send()/recv()传递数据，而不需要每次都指定目标IP和端口号。但是它和TCP不同的是它没有三次握手的过程。
  >可以通过在已建立连接的UDP套接字上，调用connect()实现指定新的IP地址和端口号以及断开连接。

- Q: socket编程，如果client断电了，服务器如何快速知道？
  >使用定时器（适合有数据流动的情况）；
  >使用socket选项SO_KEEPALIVE（适合没有数据流动的情况）; 
  >自己编写心跳包程序,
  >使用TCP的keepalive机制,UNIX网络编程不推荐使用SO_KEEPALIVE来做心跳检测。
  >keepalive原理:TCP内嵌有心跳包,以服务端为例,当server检测到超过一定时间(/proc/sys/net/ipv4/tcp_keepalive_time 7200 即2小时)没有数据传输,那么会向client端发送一个keepalive packet。

### liunx操作系统
- Q:熟练netstat tcpdump ipcs ipcrm
  >netstat:检查网络状态，tcpdump:截获数据包，ipcs:检查共享内存，ipcrm:解除共享内存

- Q:共享内存段被映射进进程空间之后，存在于进程空间的什么位置？共享内存段最大限制是多少？
  >将一块内存映射到两个或者多个进程地址空间。通过指针访问该共享内存区。一般通过mmap将文件映射到进程地址共享区。存在于进程数据段，最大限制是0x2GByte

- Q:ELF是什么？其大小与程序中全局变量的是否初始化有什么关系（注意未初始化的数据放在bss段）
  >可执行连接格式。可以减少重新编程重新编译的代码。

- Q:32位系统一个进程最多有多少堆内存
  >32位意味着4G的寻址空间，Linux把它分为两部分：最高的1G(虚拟地址从0xC0000000到0xffffffff)用做内核本身，成为“系统空间”，而较低的3G字节（从0x00000000到0xbffffff）用作各进程的“用户空间”。每个进程可以使用的用户空间是3G。虽然各个进程拥有其自己的3G用户空间，系统空间却由所有的进程共享。从具体进程的角度看，则每个进程都拥有4G的虚拟空间，较低的3G为自己的用户空间，最高的1G为所有进程以及内核共享的系统空间。实际上有人做过测试也就2G左右。

- Q:写一个c程序辨别系统是64位 or 32位
  >查看指针长度可知 `void* number =  0;      printf("%d\n",sizeof(&number));  `

- Q:写一个c程序辨别系统是大端or小端字节序
  >使用联合体
  >```cpp
    union{ short value; char a[sizeof(short)];}test;
    test.value= 0x0102;
    if((test.a[0] == 1) && (test.a[1] == 2)) cout << "big"<<endl; else cout << "little"  << endl;
   ```

- Q:信号：列出常见的信号，信号怎么处理？
  >1).进程终止的信号 2).跟踪进程的信号 3).与进程例外事件相关的信号等
  >对于信号的处理或者执行相关的操作进行处理(自定义signal函数)或者直接忽略

- Q:i++ 是否原子操作?并解释为什么?
  >i++主要看三个步骤：
  >首先把数据从内存放到寄存器上，在寄存器上进行自增处理，放回到寄存器上，每个步骤都可能会被中断分离开！

- Q:说出你所知道的各类linux系统的各类同步机制（重点），什么是死锁？如何避免死锁（每个技术面试官必问）
  >1).原子操作 2).信号量（其实就是互斥锁也就是锁的机制）3).读写信号量（就是读写锁） 4）.自旋锁  5.内核锁 6）.顺序锁
  >死锁就是几个进程申请资源，出现了循环等待的情况！
  >避免死锁的方法：1）.资源是互斥的 2）.不可抢占 3）占有且申请 4）.循环等待

- Q:如何实现守护进程？
  >创建子进程，父进程退出->在子进程中创建新会话->改变当前目录为根目->重设文件权限掩码->关闭文件描述符->守护进程退出处理
  >当用户需要外部停止守护进程运行时，往往会使用 kill命令停止该守护进程。所以，守护进程中需要编码来实现kill发出的signal信号处理，达到进程的正常退出。

- Q:linux的任务调度机制是什么？
  >Linux 分实时进程和普通进程，实时进程应该先于普通进程而运行
  >实时进程：FIFO(先来先服务调度),  RR（时间片轮转调度）。
  >每个进程有两个优先级（动态优先级和实时优先级），实时优先级就是用来衡量实时进程是否值得运行的。 非实时进程有两种优先级，一种是静态优先级，另一种是动态优先级。实时进程又增加了第三种优先级，实时优先级。优先级越高，得到CPU时间的机会也就越大。

- Q:标准库函数和系统调用的区别？
  >系统调用：是操作系统为用户态运行的进程和硬件设备(如CPU、磁盘、打印机等)进行交互提供的一组接口，即就是设置在应用程序和硬件设备之间的一个接口层。inux内核是单内核，结构紧凑，执行速度快，各个模块之间是直接调用的关系。linux系统上到下依次是用户进程->linux内核->硬件。其中系统调用接口是位于Linux内核中的，整个linux系统从上到下可以是：用户进程->系统调用接口->linux内核子系统->硬件，也就是说Linux内核包括了系统调用接口和内核子系统两部分；或者从下到上可以是：物理硬件->OS内核->OS服务->应用程序，操作系统起到“承上启下”作用，向下管理物理硬件，向上为操作系服务和应用程序提供接口，这里的接口就是系统调用了。
  >库函数：把函数放到库里。是把一些常用到的函数编完放到一个lib文件里，供别人用。别人用的时候把它所在的文件名用#include<>加到里面就可以了。一类是c语言标准规定的库函数，一类是编译器特定的库函数。
  >系统调用是为了方便使用操作系统的接口，而库函数则是为了人们编程的方便。

- Q:系统如何将一个信号通知到进程？
  >内核给进程发送信号，是在进程所在的进程表项的信号域设置对应的信号的位。执行用户自定义的信号处理函数的方法很巧妙, 把该函数的地址放在用户栈栈顶，进程从内核返回到用户态的时候，先弹出信号处理函数地址，于是就去执行信号处理函数了，然后再弹出，才是返回进入内核时的状态。

- Q:fork()一子进程程后父进程的全局变量能不能使用？
  >fork后子进程将会拥有父进程的几乎一切资源，父子进程的都各自有自己的全局变量。不能通用，不同于线程。对于线程，各个线程共享全局变量。

### 网络编程

- Q:TCP头大小，包含字段？三次握手，四次断开描述过程，都有些什么状态。状态变迁图。TCP/IP收发缓冲区（2次）
  >1

- Q: 使用udp和tcp进程网络传输，为什么tcp能保证包是发送顺序，而 udp无法保证？
  >因为TCP发送的数据包是按序号发送，有确认机制和丢失重传机制，而udp是不可靠的发送机制，发送的对应端口的数据包不是按顺序发送的。

- Q:epoll哪些触发模式，有啥区别？
  >epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值。
  >也就是说在LT模式的情况下一定要确认收发的数据包的buffer是不是足够大如果收发数据包大小大于buffer的大小的时候就可能会出现数据丢失的情况。

- Q: tcp与udp的区别（必问）为什么TCP要叫做数据流？
  >TCP提供的是面向连接、可靠的字节流服务。当客户和服务器彼此交换数据前，必须先在双方之间建立一个TCP连接，之后才能传输数据。TCP提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。
  >UDP是一个简单的面向数据报的运输层协议。UDP不提供可靠性，它只是把应用程序传给IP层的数据报发送出去，但是并不能保证它们能到达目的地。由于UDP在传输数据报前不用在客户和服务器之间建立一个连接，且没有超时重发等机制，故而传输速度很快

- Q:流量控制和拥塞控制的实现机制
  >网络拥塞现象是指到达通信子网中某一部分的分组数量过多,使得该部分网络来不及处理,以致引起这部分乃至整个网络性能下降的现象,严重时甚至会导致网络通信业务陷入停顿,即出现死锁现象。拥塞控制是处理网络拥塞现象的一种机制。数据的传送与接收过程当中很可能出现收方来不及接收的情况,这时就需要对发方进行控制,以免数据丢失。

- Q:滑动窗口的实现机制
  >滑动窗口机制，窗口的大小并不是固定的而是根据我们之间的链路的带宽的大小，这个时候链路是否拥护塞。接受方是否能处理这么多数据了。  滑动窗口协议，是TCP使用的一种流量控制方法。该协议允许发送方在停止并等待确认前可以连续发送多个分组。由于发送方不必每发一个分组就停下来等待确认，因此该协议可以加速数据的传输。 

- Q:epoll和select的区别？
  >select在一个进程中打开的最大fd是有限制的，由FD_SETSIZE设置，默认值是2048。不过 epoll则没有这个限制，内存越大，fd上限越大，1G内存都能达到大约10w左右。
  >select的轮询机制是系统会去查找每个fd是否数据已准备好，当fd很多的时候，效率当然就直线下降了，epoll采用基于事件的通知方式，一旦某个fd数据就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，高效。 
  >select还是epoll都需要内核把FD消息通知给用户空间，epoll是通过内核于用户空间mmap同一块内存实现的，而select则做了不必要的拷贝


- Q:网络中，如果客户端突然掉线或者重启，服务器端怎么样才能立刻知道？
  >若客户端掉线或者重新启动，服务器端会收到复位信号(RST)，每一种tcp/ip得实现不一样，控制机制也不一样。

- Q:TTL是什么？有什么用处，通常那些工具会用到它？ping? traceroute? ifconfig? netstat?
  >TTL是Time To Live，每经过一个路由就会被减去一，如果它变成0，包会被丢掉。它的主要目的是防止包在有回路的网络上死转，浪费网络资源。ping和traceroute用到它。

- Q:linux的五种IO模式/异步模式.
  >1）同步阻塞I/O
  >2）同步非阻塞I/O
  >3）同步I/O复用模型
  >4） 同步信号驱动I/O
  >5） 异步I/O模型

- Q:请说出http协议的优缺点.
  >1.支持客户/服务器模式。
  >2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径，通信速度很快。
  >3.灵活：HTTP允许传输任意类型的数据对象。
  >4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
  >5.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，导致每次连接传送的数据量增大。缺点就是不够安全，可以使用https完成使用

- Q:NAT类型，UDP穿透原理。
  >Full cone NAT （全克隆nat）:一对一NAT一旦一个内部地址（iAddr:port1）映射到外部地址（eAddr:port2）。
  >Address-Restricted cone NAT（地址受限克隆nat）:任意外部主机（hostAddr:any）都能通过给eAddr:port2发包到达iAddr:port1的前提是：iAddr:port1之前发送过包到hostAddr:any. "any"也就是说端口不受限制
  > Port-Restricted cone NAT:内部地址（iAddr:port1）映射到外部地址（eAddr:port2），所有发自iAddr:port1的包都经eAddr:port2向外发送。一个外部主机（hostAddr:port3）能够发包到达iAddr:port1的前提是：iAddr:port1之前发送过包到hostAddr:port3.
  > Symmetric NAT（对称NAT）:同内部IP与port的请求到一个特定目的地的IP地址和端口，映射到一个独特的外部来源的IP地址和端口。同一个内部主机发出一个信息包到不同的目的端，不同的映射使用外部主机收到了一封包从一个内部主机可以送一封包回来

- Q:大规模连接上来，并发模型怎么设计
  >Epoll+线程池（epoll可以采用libevent处理）

- Q:流量控制与拥塞控制的区别，节点计算机怎样感知网络拥塞了？
  >拥塞控制是把整体看成一个处理对象的，流量控制是对单个的节点。
  >感知的手段应该不少，比如在TCP协议里，TCP报文的重传本身就可以作为拥塞的依据。

### 算法和数据结构

**数组和字符串**

**解题思路**

- 一般来说，一旦出现“unique”，就落入使用哈希表或者bitset来判断元素出现与否的范畴。
- 一旦需要统计一个元素集中元素出现的次数，我们就应该想到哈希表。
- 访问数组时要注意越界问题。

在C／C++中，标准的数组可以通过在栈(Stack)上分配空间，或者通过先声明指针，然后用new关键字(或者C中的malloc函数)，在堆(Heap)上动态的分配空间。举例如下：
```cpp
// 在栈上定义长度为arraySize的整型数组
int array[arraySize];    
// 在堆上定义长度为arraySize的整型数组
int *array ＝ new int[arraySize];    

//释放内存
delete[] array;

```

数组可以通过下标随机访问元素，所以在修改、读取某个元素的时候效率很高，具有O(1)的时间复杂度。在插入、删除的时候需要移动后面的元素，所以平均时间复杂度O(n)。通常，数组这个数据结构不是很适合增减元素。如果你想要的操作需要大量在随机位置增减元素，可以考虑其他的数据结构。在C++中，标准库提供vector容器，其本质上相当于一个长度可变的动态数组。

**哈希表**

哈希表(Hash Table)几乎是最为重要的数据结构，主要用于基于“键(key)”的查找，存储的基本元素是键-值对(key-value pair)。逻辑上，数组可以作为哈希表 的一个特例：键是一个非负整数。注意，通常哈希表会假设键是数据的唯一标识，相同的键默认表示同一个基本存储元素。

哈希表的本质是当使用者提供一个键，根据哈希表自身定义的哈希函数(hash function)，映射出一个下标，根据这个下标决定需要把当前的元素存储在什么位置。在一些合理的假设情况下，查找一个元素的平均时间复杂度是O(1)，插入一个元素的平摊(amortized)时间复杂度是O(1)。

当对于不同的键，哈希函数提供相同的存储地址时，哈希表就遇到了所谓的冲突(collision)。解决冲突的方式有链接法(chaining)和开放地址法(open addressing)两种。简单来说，链接法相当于利用辅助数据结构(比如链表)，将哈希函数映射出相同地址的那些元素链接起来。而开放地址法是指以某种持续的哈希方式继续哈希，直到产生的下标对应尚未被使用的存储地址，然后把当前元素存储在这个地址里。

通常而言，链接法实现相对简便，但是可能需要附加空间，并且利用当前空间的效率不如开放地址法高。开放地址法更需要合理设计的连续哈希函数，但是可以获得更好的空间使用效率。需要注意的是，过于频繁的冲突会降低哈希表的搜索效率，此时需要哈希表的扩张。

C++标准库中提供map容器，可以插入、删除、查找键-值对，底层以平衡二叉搜索树的方式实现，根据键进行了排序。严格来说，map并不是一个哈希表，原因是查找时间从O(1)变为了O(log n)，但是好处在于能够根据键值，顺序地输出元素，对于某些应用场景可能更为合适。在C++11中，标准库添加了unordered_map，更符合哈希表的传统定义，平均查找时间O(1)。

**字符串**
在C语言中，字符串(string)指的是一个以‘\0’结尾的char数组。关于字符串的函数通常需要传入一个字符型指针。然而，在C++中，String是一个类，并且可以通过调用类函数实现判断字符串长度，字串等等操作。

**栈和堆**
栈主要是指由操作系统自动管理的内存空间。当进入一个函数，操作系统会为该函数中的局部变量分配存储空间。事实上，系统会分配一个内存块，叠加在当前的栈上，并且利用指针指向前一个内存块的地址。函数的局部变量就存储在当前的内存块上。当该函数返回时，系统“弹出”内存块，并且根据指针回到前一个内存块。所以，栈总是以后进先出(LIFO)的方式工作。通常，在栈上分配的空间不需要用户操心。

堆是用来存储动态分配变量的空间。对于堆而言，并没有像栈那样后进先出的规则，程序员可以选择随时分配或回收内存。这就意味着需要程序员自己用命令回收内存，否则会产生内存泄漏(memory leak)。在C/C++中，程序员需要调用free/delete来释放动态分配的内存。在Java，Objective-C (with Automatic Reference Count)中，语言本身引入垃圾回收和计数规则帮助用户决定在什么时候自动释放内存。

需要了解的常见容器及方法

- Vector / ArrayList
- HashSet, HashTable
- Map / Dictionary

**String Matching 的常见算法**

Brute-Force算法： 顺序遍历母串，将每个字符作为匹配的起始字符，判断是否匹配子串。时间复杂度 O(mn)。

Rabin-Karp算法：将每一个匹配子串映射为一个哈希值。例如，将子串看做一个多进制数，比较它的值与母串中相同长度子串的哈希值，如果相同，再细致地按字符确认字符串是否确实相同。顺序计算母串哈希值的过程中，使用增量计算的方法：扣除最高位的哈希值，增加最低位的哈希值。因此能在平均情况下做到O(m+n)。

- Q:给定一个单向链表（长度未知），请设计一个既节省时间又节省空间的算法来找出该链表中的倒数第m个元素。实现这个算法，并为可能出现的特例情况安排好处理措施。“倒数第m个元素”是这样规定的：当m=0时，链表的最后一个元素将被返回。
```cpp

/*
方法一、如果我们知道链表的长度n，查找倒数第m个元素，也就是查找正序的第（n -  m）个元素（这里的序号只是为了分析，可能跟题目不一定正确的符合）。那么这样来说就简单很多。首先遍历链表得到链表长度，然后重新遍历一次，查找正数第（n-m）个元素。时间复杂度大约是O(2n)。
方法二、我们是不是可以提供一个辅助存储空间，是的我们在遍历到链表结束的时候可以回溯到倒数第m个元素。比如用一个支持随机访问的容器记录链表每一个节点的地址。那么这样的就可以只遍历一次链表就能得到结果。时间复杂度大约是O(n)，但是我们是用空间换取时间的，辅助存储空间的大小由m决定，如果m过大也是不可取的。
方法三、头结点指针为当前指针，尾节点指针为拖后指针。开始的时候当前指针和拖后指针初始化为链表的头结点，首先我们让当前指针遍历到第m个元素，拖后指针不变；然后同步更新当前指针和拖后指针；直到当前指针为链表结尾。这样我们就能保证当前指针和拖尾指针之间的距离是m。
*/
Node* FindMToLastNode(Node* pHead, int m) {  
    // 查找到第m个元素  
    Node* pCurrent = pHead;  
    for (int i = 0; i < m; ++i) {  
        if (pCurrent) {  
            pCurrent = pCurrent->next;  
        } else {  
            return NULL;  
        }  
    }  
  
    Node* pFind = pHead;  
    while (pCurrent) {  
        pFind     = pFind->next;  
        pCurrent  = pCurrent->next;  
    }   
    return pFind;  
} 

```

- Q:给定一个单向链表（长度未知），请遍历一次就找到中间的指针，假设该链表存储在只读存储器，不能被修改
```cpp
/*
设置两个指针，一个每次移动两个位置，一个每次移动一个位置，当第一个指针到达尾节点时，第二个指针就达到了中间节点的位置
处理链表问题时，”快行指针“是一种很常见的技巧，快行指针指的是同时用两个指针来迭代访问链表，只不过其中一个比另一个超前一些。快指针往往先行几步，或与慢指针相差固定的步数。
*/

node *create()  {  
    node *p1, *p2, *head;  
    int cycle = 1, x;  
    head = (node*)malloc(sizeof(node));  
    p1 = head;  
    while (cycle) {         
        cout << "please input an integer: ";  
        cin >> x;  
        if (x != 0) {  
            p2 = (node*)malloc(sizeof(node));  
            p2->data = x;  
            p1->next = p2;  
            p1 = p2;  
        } else {  
            cycle = 0;  
        }  
    }  
    head = head->next;  
    p1->next = NULL;  
    return head;  
}  
void findmid(node* head)  {  
    node *p1, *p2, *mid;  
    p1 = head;  
    p2 = head;  
  
    while (p1->next->next != NULL)  
    {     
        p1 = p1->next->next;  
        p2 = p2->next;  
        mid = p2;  
    }     
}

```

**堆栈和队列**
**解题策略**
考虑到栈具有LIFO的特性，那么与之匹配地，最大值追踪方式也需要具有相同特性：不妨用另一个栈追踪最大值。
遍历子树的过程是一个自上而下结构：从顶层出发，逐渐向下扩散。所以考虑递归或者栈。
从最基本的情况出发，根据题意推倒整个计算流程。这样做的好处是：1) 确保自己正确地理解了题目 2) 从简单的情况出发，找找解题思路。该方法特别适用于递归，动态编程等题目类型。
由于栈具有LIFO的特性，如需实现任何特定顺序的读取操作，往往可以借助两个栈互相“倾倒”来实现特定顺序。事实上，在很多情况下，栈并不是实现这种读取顺序的最佳数据结构。但作为面试问题，往往面试官会很明确的说明用栈实现。此时，我们就应该立刻想到利用另一个栈作为辅助。
有一类问题有这样的特性：当前节点的解依赖后驱节点。也就是说，对于某个当前节点，如果不能获知后驱节点，就无法得到有意义的解。这类问题可以通过栈(或等同于栈的若干个临时变量)解决：先将当前节点入栈，然后看其后继节点的值，直到其依赖的所有节点都完备时，再从栈中弹出该节点求解。某些时候，甚至需要反复这个过程：将当前节点的计算结果再次入栈，直到其依赖的后继节点完备。
所谓的自上而下(Top-Down)结构，从逻辑理解的角度来看，实际上就是一种树形结构，从顶层出发，逐渐向下扩散，例如二叉树的遍历问题。 在实际运算的时候，我们先解决子问题，再利用子问题的结果解决当前问题。从算法角度而言，就是利用递归。用递归解决自上而下结构的问题，详见第7章。
由于栈的LIFO特性，可以利用栈数据结构消除递归。递归通常用函数调用自身实现，在调用的时候系统会分配额外的空间，并且需要用栈指针记录函数返回的位置，故额外开销(overhead)比较大。但在实际工作或面试中，往往用栈或者用递归的区别不大，按照自己擅长的方式做就可以。在使用栈的时候， 每个子问题应当被看成是同样类型的对象(object)，将该对象按照自上而下“的方向入栈。然后通过while循环，调用栈的pop()函数弹出栈顶元素并访问，直至栈清空。这样，后入栈的子问题会优先被弹出，相当于实现了递归。

**栈**
栈(stack)是一种数据结构，可以实现后进先出(Last in first out, LIFO)。通常情况下，我们可以用栈作为辅助，实现深度优先算法(Depth first search, DFS)，或者将递归转为while循环。在本书第4章中，可以看到这样的实例。
事实上，递归本身就是相当于把函数本身一层一层地加到操作系统的内存栈上，所以利用栈数据结构去实现递归也是非常自然的：入栈操作相当于递归调用自身，出栈操作相当于递归返回。入栈操作的对象相当于需要被解决的问题，出栈对象相当于已经解决的子问题，通过共享的状态变量或返回值把子问题的结果传递出来。
最基本的栈至少包括入栈(push)和出栈(pop)，前者将一个元素放入栈内，后者将最后放入栈的元素弹出。

**队列**
与栈对称，队列(Queue)帮助实现先进先出(First in first out, FIFO)，我们可以用Queue作为辅助，实现广度优先算法(Breadth first search, BFS)。在第5章可以看到这样的实例。队列还可以作为buffer，构建一个生产者－消费者模型：生产者把新的元素加到队尾，消费者从队头读取元素。在有两个线程同时读取同一个队列时，需要考虑同步(synchronization)，具体问题在第11章中讨论。
事实上，栈 与队列可以视作封装好的链表，只是限制了访问和插入的自由。因此适用栈或队列的情境，也可以考虑使用更为强大的链表。

**链表**
链表(linked list)是一种常见的线性数据结构。对于单向链表(singly linked list)，每个节点有一个next指针指向后一个节点，还有一个成员变量用以存储数值；对于双向链表(doubly Linked List)，还有一个prev指针指向前一个节点。与数组类似，搜索链表需要O(n)的时间复杂度，但是链表不能通过常数时间(O(1))读取第k个数据。链表的优势在于能够以较高的效率在任意位置插入或删除一个节点。

**解题策略**
当涉及对头节点的操作，我们不妨考虑创建哑节点。
由于题目涉及在链表中寻找特定位置，我们用两个指针变量以不同的速度遍历该链表。
循环遍历链表, 每次只处理当前指针的next 变量，由此实现链表的逆转。

注：操作链表时务必注意边界条件：curr == head, curr == tail 或者 curr == NULL
两种存储方式 
顺序存储结构：随机读取，访问时是 O(1)
链式存储结构：插入和删除 O(1)，访问时最坏是 O(n)
分类（根据指针域） 
单向链表
双向链表
循环链表

反转链表
访问某个节点 curt.next 时，要检验 curt 是否为 null
要把反转后的最后一个节点（即第一个节点）指向 null

删除某个节点
由于需要知道前继节点的信息，而前继节点可能会导致表头产生变化，所以需要一些技巧 Dummy Node
链表指针的鲁棒性 
访问某个节点 curt.next 时，要检验 curt 是否为 null
全部操作结束后，判断是否有环；若有，则置其中一端为 null

Dummy Node
是一个虚拟节点 dummy.next = head
针对单向链表没有前向指针的问题，保证链表的 head 不会在删除操作中丢失
也可以用来进行 head 节点（但比较少见）
当链表的 head 可能有变化时，使用 dummy node 可以简化代码，最后返回 dummy.next 即可

快慢指针
快慢指的是指针向前移动的步长，一般来说，快指针每次移动 2，慢指针每次移动 1
主要有两个应用 
快速找出未知长度单链表的中间节点 
设置两个指针 *fast 和 *slow 都指向头节点
*fast 移动速度是 *slow 的两倍
*fast 指向末尾节点时，*slow 正好就在中间
判断单链表是否有环 
设置两个指针 *fast 和 *slow 都指向头节点
*fast 移动速度是 *slow 的两倍
如果 *fast == null 说明该单链表不是循环链表
如果 *fast == *slow 说明该链表是循环链表
其他应用 
找倒数第 N 个节点 
设置两个指针 *fast 和 *slow 都指向头节点
*fast 先移动 N 步，然后两个指针一起前进
*fast 到达末尾时，*slow 即为倒数第 N 个节点

**递归和动态规划**
递归和动态编程(Dynamic Programming, DP)是算法类问题中的难点所在。算法的核心在于找到状态转移方程，即如何通过子问题解决原问题。在“The Rules”部分，我们先介绍递规和DP的普适特性；再通过“模式识别”，从题目的关键字出发，判断什么样的题目适合用递归和DP，并且总结算法模版

**解题策略**
用动态编程(自底向上)解决收敛结构问题

用动态编程(自底向上)解决收敛结构问题
具有强收敛性/Aggregate属性的问题(承前所述，是指关于特解，或最值，或总和，或数量的问题)，都可以用整数坐标映射所有节点，且当前节点的解只依赖于前驱节点(无论是顺序还是倒序)。那么，这类问题往往可以用DP解决。解决的关键是建立子问题的解之间的递推关系：
f(n) = G[f(n-1), f(n-2), … , f(1)] 或
f(i, j) = G[f(i-1, j-1), f(i, j -1), f(i-1,j)]
其中G[ ]表示子问题到原问题的映射关系，例如对于斐波那契数列，有递推式：
f(n) = G[f(n-1), f(n-2)] = f(n-1) + f(n-2)
解决这类问题的时候，可以把上述递推关系写在手边，这样做非常有利于理清算法实现的思路。实际实现算法时，往往以问题的一端为循环开端，另一端为循环终止条件， 将当前节点的解(或往往是，以当前节点为末节点的问题的解，抑或是以当前两个坐标为输入的问题的解)用DP table(即数组)记录下来(如果当前节点只由之前紧接的若干个节点决定，那么用若干个变量也够了)，数组的下标即为子问题的输入变量，也就是递推关系中的函数参数，只是把f(i,j)表示成array[i][j]而已。
如果问题除了要计算动归终点的数值以外，还需要记录具体的到达路径，则可记录每个节点的前驱节点(prev[n])或前驱路径(vector<vector<int>> prev)，然后用终点出发通过backtracking处理成path。这时候记录的前驱们都是经过了DP的剪枝，每一条路径都是符合条件的正确路径。
注意，如果出现类似于“所有解”，“所有路径”等关键词，则用自上而下方法更为直接。之后我们也会给出例子。
最长子序列类型的问题
对于“最长子序列”问题(即有限空间内，满足一定条件的最长顺序子序列)，本身具有很强的聚合性，可以以如下方式解答：用DP Table来记录以当前节点为末节点的序列的解(至少固定问题的一端，因此不是以“当前节点或之前节点”为末节点)的解，并根据递推关系，由问题空间的起点到达问题空间的终点。
用Memorization (Top-Down)解决收敛结构问题
Memorization是自顶向下形式的动态编程，并且受到的制约更少 ，自然也可以用来解决前述的问题(但空间上可能效率不及自底向上形式的DP)。
Memorization的核心在于，在原有递归框架下，存储子问题的计算结果，在重复计算子问题时返回已经计算的值。
值得注意的是，这里所谓的“重复计算子问题”，在自顶向下结构下必须与前驱节点无关，因为子问题并不知道原问题是如何到达当前节点的。举例来说，求二叉树从根节点到叶节点的权值最大路径，对于当前节点到叶节点的路径与之前如何到达当前节点没有关系，只要计算当前节点到叶节点的路径，就一定是重复的计算，可以直接返回结果。作为反例，在一个字母矩阵当中寻找词典中的单词，当前路径能否构成单词，不仅与之后走的过程有关，也与之前的过程有关。因此，从当前节点出发，哪怕走过相同的路径，也不能看成是重复计算的子问题。在回溯部分我们会进一步讲解。
用回溯法( 自上而下 )解决发散结构问题
对于发散性问题(例如“所有组合”，“全部解”)，可以选取其问题空间“收敛”的一端作为起点，沿着节点发散的方向(或者说，当前节点的多种选择)进行递归，直到
当前节点“不合法” 或 
当前节点发散方向搜索完毕，才会return
举例来说，考虑树的遍历：根节点方向就是“收敛”的一端，节点发散的方向就是子节点。对于某个树的节点，其孩子就是当前决策的多种选择。当达到叶节点是，其孩子为NULL，即达到“不合法”的边界条件。回溯法的核心在于选择哪些方向/决策，才是最合理，不重复的。所谓“剪枝”(pruning)，就是指：只选择尽可能少的、可能到达“胜利条件”的方向，而不是搜索当前节点的所有发散方向。这样，可能将幂指数级的复杂度降低到阶乘级。
值得注意的是，invalid前的最末节点未必意味着胜利(不是所有的问题走通就算满足条件)，胜利的节点也未必代表不需要继续走下去(比如寻找到一个单词之后，继续走下去可能能找到以这个单词为前缀的另一个单词)。因此我们强烈推荐将invalid的判定与胜利条件的判定总是分开，即使在某些题目中它们是一致的。当然，如果经过充分剪枝之后，所有搜索只会沿着“正确”的方向行进，那么当前节点“不合法”往往也就意味着胜利条件。
如果需要记录决策的路径，可以用vector<int> &path沿着搜索的方向记录，在满足胜利条件时记录当前path(通常是将path存入vector<vector<int>> &paths)。
注意，我们传入的path是引用形式，属于全局变量。Backtracking(回溯)本身隐含的含义是，在访问完这个节点返回时，需要恢复原本的状态(即回到该节点)，以访问其他路径。具体实现时，意味着需要:
在return前，删除path中的当前节点。
如果搜索的方向有出现环路的可能，那么可以使用bool []或unordered_map来记录该节点是否已被使用，在访问时以及return前维护。
如果以传值形式传入path，由于path成了局部变量，故在某些情况下不需要显式回溯，相当于把状态复制给了子问题。可能有人觉得这样做比较直观，但其缺点是需要额外的空间。
回溯法的典型模板如下所示： 

```cpp
void backtracking( P node, vector<P> &path, vector<vector<P> >&paths ){
        if(!node )  // invalid node
            return;

        path.push_back(node);

        bool success =  ;  // condition for success
        if( success )  
            paths.push_back( vector<P>(path.begin(),path.end()) ); 
            // don't return here
        
        for( P next: all directions )
            backtracking( next, path, paths );
        path.pop_back();
        return;
}


```
用Divide and Conquer 解决独立子问题
如果能将问题由几个孤立但类似的部分组成，则可以优先选择使用D&C策略：将问题分割解决，再合并结果。特别地，如果期望将问题的复杂度由O(n)进一步降低到O(logn)，一般总是可以联想到使用D&C策略，将问题分割而治。

从子问题得到最终解
递归和动态编程能解决的问题都有一个特性：原问题(problem)可以分解成若干个子问题(sub-problem)，只有先解决了子问题才能进一步解决原问题。子问题的解决方式形式上与原问题一致。从题目描述来看，可以提示我们尝试用递归、DP解决的关键词有：compute nth element (value, sum, max, etc.), return all the paths, return all the combinations, return all the solutions…
既然动规与递归都能解决相同类型的问题，那么DP和递归有什么不同？最大的区别在于，DP存储子问题的结果，当子问题已经被计算过，直接返回结果。因此，当需要重复计算子问题时，DP的时间效率高很多，但需要额外的空间。
特别地，具有聚合属性的问题(Aggregate)，例如在所有组合中寻找符合特定条件的特解(比如二叉树求一条从根节点到叶节点和为定值的路径，或第n个元素)，或最优解(包括最值)，或总和，或数量的问题(其实看一下SQL里的聚合函数(aggregate function)就明白了)。因为这些问题它们只需要一个聚合的或者特殊的结果，而不是所有满足条件的集合，所以它们具有很强的收敛性质。这类问题往往也可以用DP来解决。
本章节将问题处理的每一个最小的元素/步骤，称为节点，就好比一维/二维/三维数组中的一个element，或者每一次递归中独立解决的那个元操作。 我们把节点空间“两端收敛”的问题，归结为收敛结构；将节点空间“发散”的问题，归结为发散结构。形象地说，收敛问题是由若干个子问题共同决定当前状态，即状态的总数逐渐“收敛”，例如斐波那契数列问题(前两个节点决定当前节点)；发散问题是当前状态会衍生出多个下一状态，例如遍历已知根节点的二叉树(下一层的状态以指数形式增加)。抽象地说，能够在多项式时间内解决的问题，是收敛问题(P类问题)，不能在多项式内解决的问题(如阶乘级或指数级)，是发散问题(NP类问题)。定义“收敛”和“发散”是为了方便本章节描述和区分这两类问题，并非是公认的准则。
递归的空间与时间成本
对系统层面上说，操作系统是利用函数栈来实现递归，每次操作可视为栈里的一个对象。递归的时间成本随递归深度n(单条路径中递归调用的次数)成指数增长；空间复杂度为O(n)。

自底向上与自顶向下
从子问题解决原问题, 无非是两种方法，自底向上(Bottom-Up)与自顶向下(Top-Down)，形式上前者对应iteration，利用循环将结果存在数组里，从数组起始位置向后计算；后者对应recursion，即利用函数调用自身实现，如果不存储上一个状态的解，则为递归，否则就是DP。

我们再次强调：动态编程的核心在于，如果在一个问题的解决方案中，子问题被重复计算，那么就可以利用记录中间结果，达到用空间换取时间的目的。

以下回顾一些利用到DP思想的经典算法策略：
分而治之(Divide and Conquer) 
这里只谈狭义的D&C，即将问题分成几个部分，每一部分相互独立，互不重叠，假定每个部分都可以得到解决来进行递归调用，合并每一部分的结果。
例如Merge Sort， Quick Sort (Merge Sort的divide容易，但Conquer/Merge复杂，Quick Sort的divide复杂，但Conquer/Merge容易)
动态编程(Dynamic Programming) 
尽可能不重复计算每个子问题，而是将计算结果存储下来，以确定后驱问题的解。
与贪心算法的区别是，会记录下所有可能通向全局最优解的局部解，以便在计算后驱问题时综合考虑多个前驱问题的解。
贪婪算法(Greedy Algorithm) 
只做出当下最优的判断，并且以此为基础进行下一步计算。当前判断最优时，不考虑对全局/未来的影响，所以所以从全局来说并不能保证总是最优。
贪心算法每次更新当前的最优解。如Dijkstra算法就是贪心算法的实例之一。
回溯 (Backtracking) 
一种暴力(穷举)的深度优先搜索法：搜索，直到节点空间的尽头，然后再返回到上次的节点，再往其他方向深度搜索。
树或图的DFS是回溯的实例之一。


**树和图**
**解题策略**
对于树和图的性质，一般全局解依赖于局部解。通常可以用DFS来判断子问题的解，然后综合得到当前的全局结论。
值得注意的是，当我们在传递节点指针的时候，其实其代表的不只是这个节点本身，而是指对整个子树、子图进行操作。只要每次递归的操作对象的结构一致，我们就可以选择Divide and Conquer(事实上对于树和图总是如此，因为subgraph和subtree仍然是graph和tree结构)。实现函数递归的步骤是：首先设置函数出口，就此类问题而言，递归出口往往是node == NULL。其次，在构造递归的时候，不妨将递归调用自身的部分视为黑盒，并想象它能够完整解决子问题。以二叉树的中序遍历为例，函数的实现为：
```cpp
void InOrderTraversal(TreeNode *root) {
    if (root == NULL) {
        return;
    }
    InOrderTraversal(root->left);
    root->print();
    InOrderTraversal(root->right);
}
```
DFS 处理树的问题
有一类关于树的问题是， 要求找出一条满足特定条件的路径 。对于这类问题，通常都是传入一个vector记录当前走过的路径(为尽可能模版化，统一记为path)，传入path的时候可以是引用，可以是值，具体见下面的分析。还需要传入另一个vector引用记录所有符合条件的path(为尽可能模版化，统一记为result)。注意， result可以用引用或指针形式，相当于一个全局变量，或者就开辟一个独立于函数的成员变量。由于path通常是vector ，那么result就是vector>。当然，那个特定条件，也是函数的一个输入变量。
在解答此类问题的时候，通常都采用DFS来访问，利用回溯思想，直到无法继续访问再返回。值得注意的是，如果path本身是以引用(reference)的形式传入，那么需要在返回之前消除之前所做的影响(回溯)。因为传引用(Pass by reference)相当于把path也看作全局变量，对path的任何操作都会影响其他递归状态，而传值(pass by value)则不会。传引用的好处是可以减小空间开销。
树和其他数据结构的相互转换
这类题目要求将树的结构转化成其他数据结构，例如链表、数组等，或者反之，从数组等结构构成一棵树。前者通常是通过树的遍历，合并局部解来得到全局解，而后者则可以利用D&C的策略，递归将数据结构的两部分分别转换成子树，再合并。
寻找特定节点
此类题目通常会传入一个当前节点，要求找到与此节点具有一定关系的特定节点：例如前驱、后继、左／右兄弟等。
对于这类题目，首先可以了解一下常见特定节点的定义及性质。在存在指向父节点指针的情况下，通常可以由当前节点出发，向上倒推解决。如果节点没有父节点指针，一般需要从根节点出发向下搜索，搜索的过程就是DFS。
图的访问
关于图的问题一般有两类。一类是前面提到的关于图的基本问题，例如图的遍历、最短路径、可达性等；另一类是将问题转化成图，再通过图的遍历解决问题。第二类问题有一定的难度，但也有一些规律可循：如果题目有一个起始点和一个终止点，可以考虑看成图的最短路径问题。
树
树的概念
树(tree)是一种能够分层存储数据的重要数据结构，树中的每个元素被称为树的节点，每个节点有若干个指针指向子节点。从节点的角度来看，树是由唯一的起始节点引出的节点集合。这个起始结点称为根(root)。树中节点的子树数目称为节点的度(degree)。在面试中，关于树的面试问题非常常见，尤其是关于二叉树(binary tree)，二叉搜索树(Binary Search Tree, BST)的问题。
所谓的二叉树，是指对于树中的每个节点而言，至多有左右两个子节点，即任意节点的度小于等于2。而广义的树则没有如上限制。二叉树是最常见的树形结构。二分查找树是二叉树的一种特例，对于二分查找树的任意节点，该节点存储的数值一定比左子树的所有节点的值大比右子树的所有节点的值小“(与之完全对称的情况也是有效的：即该节点存储的数值一定比左子树的所有节点的值小比右子树的所有节点的值大)。
基于这个特性，二分查找树通常被用于维护有序数据。二分查找树查找、删除、插入的效率都会于一般的线性数据结构。事实上，对于二分查找树的操作相当于执行二分搜索，其执行效率与树的高度(depth)有关，检索任意数据的比较次数不会多于树的高度。这里需要引入高度的概念：对一棵树而言，从根节点到某个节点的路径长度称为该节点的层数(level)，根节点为第0层，非根节点的层数是其父节点的层数加1。树的高度定义为该树中层数最大的叶节点的层数加1，即相当于于从根节点到叶节点的最长路径加1。由此，对于n个数据，二分查找树应该以“尽可能小的高度存储所有数据。由于二叉树第L层至多可以存储 2L 个节点，故树的高度应在logn量级，因此，二分查找树的搜索效率为O(logn)。
直观上看，尽可能地把二分查找树的每一层“塞满”数据可以使得搜索效率最高，但考虑到每次插入删除都需要维护二分查找树的性质，要实现这点并不容易。特别地，当二分查找树退化为一个由小到大排列的单链表(每个节点只有右孩子)，其搜索效率变为O(n)。为了解决这样的问题，人们引入平衡二叉树的概念。所谓平衡二叉树，是指一棵树的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。通过恰当的构造与调整，平衡二叉树能够保证每次插入删除之后都保持平衡性。平衡二叉树的具体实现算法包括AVL算法和红黑算法等。由于平衡二叉树的实现比较复杂，故一般面试官只会问些概念性的问题。
树型的概念
满二叉树(full binary tree)：如果一棵二叉树的任何结点，或者是叶节点，或者左右子树都存在，则这棵二叉树称作满二叉树。
完全二叉树(complete binary tree)：如果一棵二叉树最多只有最下面的两层节点度数可以小于2，并且最下面一层的节点都集中在该层最左边的连续位置上，则此二叉树称作完全二叉树。
二叉树的遍历
二叉树的常见操作包括树的遍历，即以一种特定的规律访问树中的所有节点。常见的遍历方式包括：
前序遍历(Pre-order traversal)：访问根结点；按前序遍历左子树；按前序遍历右子树。
中序遍历(In-order traversal)：按中序遍历左子树；访问根结点；按中序遍历右子树。特别地，对于二分查找树而言，中序遍历可以获得一个由小到大或者由大到小的有序序列。
后续遍历(Post-order traversal)：按后序遍历左子树；按后序遍历右子树；访问根结点。
以上三种遍历方式都是深度优先搜索算法(depth-first search)。深度优先算法最自然的实现方式是通过递归实现，事实上，大部分树相关的面试问题都可以优先考虑递归。此外，另一个值得注意的要点是：深度优先的算法往往都可以通过使用栈数据结构将递归化为非递归实现。这里利用了栈先进后出的特性，其数据的进出顺序与递归顺序一致(请见 Stack and Queue) 。
层次遍历(Level traversal)：首先访问第0层，也就是根结点所在的层；当第i层的所有结点访问完之后，再从左至右依次访问第i+1层的各个结点。层次遍历属于广度优先搜索算法(breadth-first search)。广度优先算法往往通过队列数据结构实现。

Trie
字典树(trie or prefix tree)是一个26叉树，用于在一个集合中检索一个字符串，或者字符串前缀。字典树的每个节点有一个指针数组代表其所有子树，其本质上是一个哈希表，因为子树所在的位置(index)本身，就代表了节点对应的字母。节点与每个兄弟具有相同的前缀，这就是trie也被称为prefix tree的原因。

字典树以及字典树节点的原型：
```cpp

class TrieNode {
    private:
        T mContent;
        vector<TrieNode*> mChildren;
    public:
        Node();
        ~Node();
        friend class Trie;
};
class Trie {
public:
    Trie();
    ~Trie();
    void addWord(string s);
    bool searchWord(string s);
    void deleteWord(string s);
private:
    TrieNode* root;
};

```
字典树的基本功能如下：
1) void addWord(string key, int value);
添加一个键:值对。添加时从根节点出发，如果在第i层找到了字符串的第i个字母，则沿该节点方向下降一层(注意，如果下一层存储的是数据，则视为没有找到)。否则，将第i个字母作为新的兄弟插入到第i层。将键插入完成后插入值节点。
2) bool searchWord(string key, int &value);
查找某个键是否存在，并返回值。从根节点出发，在第i层寻找字符串中第i个字母是否存在。如果是，沿着该节点方向下降一层；否则，返回false。
3) void deleteWord(string key)
删除一个键:值对。删除时从底层向上删除节点，“直到遇到第一个有兄弟的节点(说明该节点向上都是与其他节点共享的前缀)，删除该节点。
堆与优先队列
通常所说的堆(Heap)是指二叉堆，从结构上说是完全二叉树，从实现上说一般用数组。以数组的下标建立父子节点关系：对于下标为i的节点，其父节点为(int)i/2，其左子节点为2i，右子节点为2i+1。堆最重要的性质是，它满足部分有序(partial order)：最大(小)堆的父节点一定大于等于(小于等于)当前节点，且堆顶元素一定是当前所有元素的最大(小)值。
堆算法的核心在于插入，删除算法如何保持堆的性质(以下讨论均以最大堆为例):
下移(shift-down)操作：下移是堆算法的核心。对于最大值堆而言，对于某个节点的下移操作相当于比较当前节点与其左右子节点的相对大小。如果当前节点小于其子节点，则将当前节点与其左右子节点中较大的子节点对换，直至操作无法进行(即当前节点大于其左右子节点)。
建堆：假设堆数组长度为n，建堆过程如下，注意这里数组的下标是从 1 开始的：
for i, n/2 downto 1
    do shift-down(A,i)
插入：将新元素插入堆的末尾，并且与父节点进行比较，如果新节点的值大于父节点，则与之交换，即上移(shift-up)，直至操作无法进行。
弹出堆顶元素：弹出堆顶元素(假设记为A[1]，堆尾元素记为A[n])并维护堆性质的过程如下：
output = A[1]
exchange A[1] <-> A[n]
heap size -= 1
shift-down(A,1)
return output
值得注意的是，堆的插入操作逐层上移，耗时O(log(n))，与二叉搜索树的插入相同。但建堆通过下移所有非叶子节点(下标n/2至1)实现，耗时O(n)，小于BST的O(nlog(n))。
通过上述描述，不难发现堆其实就是一个优先队列。对于C++，标准模版库中的priority_queue是堆的一种具体实现。
图
图(Graph)是节点集合的一个拓扑结构，节点之间通过边相连。图分为有向图和无向图。有向图的边具有指向性，即AB仅表示由A到B的路径，但并不意味着B可以连到A。与之对应地，无向图的每条边都表示一条双向路径。
图的数据表示方式也分为两种，即邻接表(adjacency list)和邻接矩阵(adjacency matrix)。对于节点A，A的邻接表将与A之间相连的所有节点以链表的形势存储起来，节点A为链表的头节点。这样，对于有V个节点的图而言，邻接表表示法包含V个链表。因此，链接表需要的空间复杂度为O(V+E)。邻接表适用于边数不多的稀疏图。但是，如果要确定图中边(u, v)是否存在，则只能在节点u对应的邻接表中以O(E)复杂度线性搜索。
对于有V个节点的图而言，邻接矩阵用V*V的二维矩阵形式表示一个图。矩阵中的元素Aij表示节点i到节点j之间是否直接有边相连。若有，则Aij数值为该边的权值，否则Aij数值为0。特别地，对于无向图，由于边的双向性，其邻接矩阵的转置矩阵为其本身。邻接矩阵的空间复杂度为O(V2 )，适用于边较为密集的图。邻接矩阵在检索两个节点之间是否有边相连这样一个需求上，具有优势。
图的遍历
对于图的遍历(Graph Transversal)类似于树的遍历(事实上，树可以看成是图的一个特例)，也分为广度优先搜索和深度优先搜索。算法描述如下：
广度优先
对于某个节点，广度优先会先访问其所有邻近节点，再访问其他节点。即，对于任意节点，算法首先发现距离为d的节点，当所有距离为d的节点都被访问后，算法才会访问距离为d+1的节点。广度优先算法将每个节点着色为白，灰或黑，白色表示未被发现，灰色表示被发现，黑色表示已访问。算法利用先进先出队列来管理所有灰色节点。一句话总结，广度优先算法先访问当前节点，一旦发现未被访问的邻近节点，推入队列，以待访问。

深度优先
深度优先算法尽可能“深”地搜索一个图。对于某个节点v，如果它有未搜索的边，则沿着这条边继续搜索下去，直到该路径无法发现新的节点，回溯回节点v，继续搜索它的下一条边。深度优先算法也通过着色标记节点，白色表示未被发现，灰色表示被发现，黑色表示已访问。算法通过递归实现先进后出。一句话总结，深度优先算法一旦发现没被访问过的邻近节点，则立刻递归访问它，直到所有邻近节点都被访问过了，最后访问自己。

单源最短路径问题
对于每条边都有一个权值的图来说，单源最短路径问题是指从某个节点出发，到其他节点的最短距离。该问题的常见算法有Bellman-Ford和Dijkstra算法。前者适用于一般情况(包括存在负权值的情况，但不存在从源点可达的负权值回路)，后者仅适用于均为非负权值边的情况。Dijkstra的运行时间可以小于Bellman-Ford。本小节重点介绍Dijkstra算法。
特别地，如果每条边权值相同(无权图)，由于从源开始访问图遇到节点的最小深度 就等于到该节点的最短路径，因此 Priority Queue就退化成Queue，Dijkstra算法就退化成BFS。
Dijkstra的核心在于，构造一个节点集合S，对于S中的每一个节点，源点到该节点的最短距离已经确定。进一步地，对于不在S中的节点，“我们总是选择其中到源点最近的节点，将它加入S，并且更新其邻近节点到源点的距离。算法实现时需要依赖优先队列。一句话总结，Dijkstra算法利用贪心的思想，在剩下的节点中选取离源点最近的那个加入集合，并且更新其邻近节点到源点的距离，直至所有节点都被加入集合。关于Dijkstra算法的正确性分析，可以使用数学归纳法证明，

任意两点之间的最短距离
另一个关于图常见的算法是，如何获得任意两点之间的最短距离(All-pairs shortest paths)。直观的想法是，可以对于每个节点运行Dijkstra算法，该方法可行，但更适合的算法是Floyd-Warshall算法。
Floyd算法的核心是动态编程，利用二维矩阵存储i，j之间的最短距离，矩阵的初始值为i，j之间的权值，如果i，j不直接相连，则值为正无穷。动态编程的递归式为：d(k)ij = min(d(k-1)ij, d(k-1)ik+ d(k-1)kj) (1<= k <= n)。直观上理解，对于第k次更新，我们比较从i到j只经过节点编号小于k的中间节点(d(k-1)ij)，和从i到k，从k到j的距离之和(d(k-1)ik+ d(k-1)kj)。Floyd算法的复杂度是O(n3)。

二叉树的遍历
```cpp
class TreeNode {
public:
    TreeNode *left;
    TreeNode *right;
    TreeNode *parent;
    int val;
};

class BinaryTree {
public:
    BinaryTree(int rootValue);
    ~BinaryTree();
    bool insertNodeWithValue(int value);
    bool deleteNodeWithValue(int value);
    void printTree();

private:
    TreeNode *root;
};

void preOrderTraversal(TreeNode *root) {
    if (!root) {
        return;
    }
    visit(root);
    preOrderTraversal(root->left);
    preOrderTraversal(root->right);
}

void inOrderTraversal(TreeNode *root) {
    if (!root) {
        return;
    }
    inOrderTraversal(root->right);
    visit(root);
    inOrderTraversal(root->left);
}

void postOrderTraversal(TreeNode *root) {
    if (!root) {
        return;
    }
    postOrderTraversal(root->left);
    postOrderTraversal(root->right);
    visit(root);
}

void levelTraversal(TreeNode *root)
{
    queue<TreeNode *> nodeQueue;
    TreeNode *currentNode;
    if (!root) {
        return;
    }
    nodeQueue.push(root);
    while (!nodeQueue.empty()) {
        currentNode = nodeQueue.front();
        processNode(currentNode);
        if (currentNode->left) {
            nodeQueue.push(currentNode->left);
        }
        if (currentNode->right) {
            nodeQueue.push(currentNode->right);
        }
        nodeQueue.pop();
    }
}

```

**排序和搜索**
Bubble Sort 冒泡排序

比较相邻的元素。如果第一个比第二个大，就交换他们两个。
对第0个到第n-1个数据做同样的工作。这时，最大的数就“浮”到了数组最后的位置上。
针对所有的元素重复以上的步骤，除了最后一个。
持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。

```python

def bubble_sort(arry):
    n = len(arry)                   #获得数组的长度
    for i in range(n):
        for j in range(1,n-i):
            if  arry[j-1] > arry[j] :       #如果前者比后者大
                arry[j-1],arry[j] = arry[j],arry[j-1]      #则交换两者
    return arry
```
优化1：某一趟遍历如果没有数据交换，则说明已经排好序了，因此不用再进行迭代了。用一个标记记录这个状态即可。
优化2：记录某次遍历时最后发生数据交换的位置，这个位置之后的数据显然已经有序，不用再排序了。因此通过记录最后发生数据交换的位置就可以确定下次循环的范围了。

Selection Sort 选择排序

在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。
再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。
以此类推，直到所有元素均排序完毕。

```python
def select_sort(ary):
    n = len(ary)
    for i in range(0,n):
        min = i                             #最小元素下标标记
        for j in range(i+1,n):
            if ary[j] < ary[min] :
                min = j                     #找到最小值的下标
        ary[min],ary[i] = ary[i],ary[min]   #交换两者
    return ary

```

Insertion Sort 插入排序
插入排序的工作原理是，对于每个未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。
步骤：
从第一个元素开始，该元素可以认为已经被排序
取出下一个元素，在已经排序的元素序列中从后向前扫描
如果被扫描的元素（已排序）大于新元素，将该元素后移一位
重复步骤3，直到找到已排序的元素小于或者等于新元素的位置
将新元素插入到该位置后
重复步骤2~5

```python
def insert_sort(ary):
    n = len(ary)
    for i in range(1,n):
        if ary[i] < ary[i-1]:
            temp = ary[i]
            index = i           #待插入的下标
            for j in range(i-1,-1,-1):  #从i-1 循环到 0 (包括0)
                if ary[j] > temp :
                    ary[j+1] = ary[j]
                    index = j   #记录待插入下标
                else :
                    break
            ary[index] = temp
    return ary
```

Shell Sort 希尔排序

希尔排序，也称递减增量排序算法，实质是分组插入排序。由 Donald Shell 于1959年提出。希尔排序是非稳定排序算法。

希尔排序的基本思想是：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。

```python
def shell_sort(ary):
    n = len(ary)
    gap = round(n/2)       #初始步长 , 用round四舍五入取整
    while gap > 0 :
        for i in range(gap,n):        #每一列进行插入排序 , 从gap 到 n-1
            temp = ary[i]
            j = i
            while ( j >= gap and ary[j-gap] > temp ):    #插入排序
                ary[j] = ary[j-gap]
                j = j - gap
            ary[j] = temp
        gap = round(gap/2)                     #重新设置步长
    return ary
'''
上面源码的步长的选择是从n/2开始，每次再减半，直至为0。步长的选择直接决定了希尔排序的复杂度,一般是3
'''
```

Merge Sort 归并排序

归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。
先考虑合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。
再考虑递归分解，基本思路是将数组分解成left和right，如果这两个数组内部数据是有序的，那么就可以用上面合并数组的方法将这两个数组合并排序。如何让这两个数组内部是有序的？可以再二分，直至分解出的小组只含有一个元素时为止，此时认为该小组内部已有序。然后合并排序相邻二个小组即可。

```python
def merge_sort(ary):
    if len(ary) <= 1 : return ary
    num = int(len(ary)/2)       #二分分解
    left = merge_sort(ary[:num])
    right = merge_sort(ary[num:])
    return merge(left,right)    #合并数组

def merge(left,right):
    '''合并操作，
    将两个有序数组left[]和right[]合并成一个大的有序数组'''
    l,r = 0,0           #left与right数组的下标指针
    result = []
    while l < len(left) and r < len(right):
        if left[l] < right[r]:
            result.append(left[l])
            l += 1
        else:
            result.append(right[r])
            r += 1
    result += left[l:]
    result += right[r:]
    return result

```

Quick Sort 快速排序
快速排序通常明显比同为Ο(n log n)的其他算法更快，因此常被采用，而且快排采用了分治法的思想，所以在很多笔试面试中能经常看到快排的影子。可见掌握快排的重要性。
步骤：
从数列中挑出一个元素作为基准数。
分区过程，将比基准数大的放到右边，小于或等于它的数都放到左边。
再对左右区间递归执行第二步，直至各区间只有一个数。

```python
def quick_sort(ary):
    return qsort(ary,0,len(ary)-1)

def qsort(ary,left,right):
    #快排函数，ary为待排序数组，left为待排序的左边界，right为右边界
    if left >= right : return ary
    key = ary[left]     #取最左边的为基准数
    lp = left           #左指针
    rp = right          #右指针
    while lp < rp :
        while ary[rp] >= key and lp < rp :
            rp -= 1
        while ary[lp] <= key and lp < rp :
            lp += 1
        ary[lp],ary[rp] = ary[rp],ary[lp]
    ary[left],ary[lp] = ary[lp],ary[left]
    qsort(ary,left,lp-1)
    qsort(ary,rp+1,right)
    return ary

```

Heap Sort 堆排序
堆排序在 top K 问题中使用比较频繁。堆排序是采用二叉堆的数据结构来实现的，虽然实质上还是一维数组。二叉堆是一个近似完全二叉树 。
二叉堆具有以下性质：
父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值。
每个节点的左右子树都是一个二叉堆（都是最大堆或最小堆）。
步骤：
构造最大堆（Build_Max_Heap）：若数组下标范围为0~n，考虑到单独一个元素是大根堆，则从下标n/2开始的元素均为大根堆。于是只要从n/2-1开始，向前依次构造大根堆，这样就能保证，构造到某个节点时，它的左右子树都已经是大根堆。
堆排序（HeapSort）：由于堆是用数组模拟的。得到一个大根堆后，数组内部并不是有序的。因此需要将堆化数组有序化。思想是移除根节点，并做最大堆调整的递归运算。第一次将heap[0]与heap[n-1]交换，再对heap[0...n-2]做最大堆调整。第二次将heap[0]与heap[n-2]交换，再对heap[0...n-3]做最大堆调整。重复该操作直至heap[0]和heap[1]交换。由于每次都是将最大的数并入到后面的有序区间，故操作完后整个数组就是有序的了。
最大堆调整（Max_Heapify）：该方法是提供给上述两个过程调用的。目的是将堆的末端子节点作调整，使得子节点永远小于父节点。

```python
def heap_sort(ary) :
    n = len(ary)
    first = int(n/2-1)       #最后一个非叶子节点
    for start in range(first,-1,-1) :     #构造大根堆
        max_heapify(ary,start,n-1)
    for end in range(n-1,0,-1):           #堆排，将大根堆转换成有序数组
        ary[end],ary[0] = ary[0],ary[end]
        max_heapify(ary,0,end-1)
    return ary

#最大堆调整：将堆的末端子节点作调整，使得子节点永远小于父节点
#start为当前需要调整最大堆的位置，end为调整边界
def max_heapify(ary,start,end):
    root = start
    while True :
        child = root*2 +1               #调整节点的子节点
        if child > end : break
        if child+1 <= end and ary[child] < ary[child+1] :
            child = child+1             #取较大的子节点
        if ary[root] < ary[child] :     #较大的子节点成为父节点
            ary[root],ary[child] = ary[child],ary[root]     #交换
            root = child
        else :
            break


```
Bucket Sort 桶排序
桶排序和归并排序有那么点点类似，也使用了归并的思想。大致步骤如下：
设置一个定量的数组当作空桶。
Divide - 从待排序数组中取出元素，将元素按照一定的规则塞进对应的桶子去。
对每个非空桶进行排序，通常可在塞元素入桶时进行插入排序。
Conquer - 从非空桶把元素再放回原来的数组中。

Counting Sort 计数排序
计数排序，顾名思义，就是对待排序数组按元素进行计数。使用前提是需要先知道待排序数组的元素范围，将这些一定范围的元素置于新数组中，新数组的大小为待排序数组中最大元素与最小元素的差值。
维基上总结的四个步骤如下：
定新数组大小——找出待排序的数组中最大和最小的元素
统计次数——统计数组中每个值为i的元素出现的次数，存入新数组C的第i项
对统计次数逐个累加——对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）
反向填充目标数组——将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1
其中反向填充主要是为了避免重复元素落入新数组的同一索引处。

Merge Sort
合并排序(Merge Sort)是一种典型的排序算法，应用“分而治之(divide and conquer)”的算法思路：将线性数据结构(如array、vector或list )分为两个部分，对两部分分别进行排序，排序完成后，再将各自排序好的两个部分合并还原成一个有序结构。由于合并排序不依赖于随机读写，因此具有很强的普适性，适用于链表等数据结构。算法的时间复杂度O(nlogn)，如果是处理数组需要额外O(n)空间，处理链表只需要O(1)空间。算法实现如下：

```cpp
void mergesort(int[] array){
    int[] helper = new int[array.length];
    mergesort(array, helper, 0, array.length - 1)
}

void merge(int[] array, int[] helper, int low, int middle, int high){
    for (int i = low; i <= high; i++){
        helper[i] = array[i];
    }

    int helperLeft = low;
    int helperRight = middle + 1;
    int current = low;

    while (helperLeft <= middle && helperRight <= high){
        if (helper[helperLeft] <= helper[helperRight]){
            array[current] = helper[helperLeft];
            helperLefting;
        }
        else {
            array[current] = helper[helperRight];
            helperRight++;
        }
        current++;
    }

    int remaining = middle - helperLeft;
    for (int i = 0; i <= remaining; i++){
        array[current + i] = helper[helperLeft + i];
    }
}

```
指标对比

排序方法
平均情况
最好情况
最坏情况
辅助空间
稳定性

冒泡排序
O(n2)
O(n)
O(n2)
O(1)
稳定
选择排序
O(n2)
O(n2)
O(n2)
O(1)
不稳定
插入排序
O(n2)
O(n)
O(n2)
O(1)
稳定
希尔排序
O(nlogn)~O(n2)
O(n1.3)
O(n2)
O(1)
不稳定
堆排序
O(nlogn)
O(nlogn)
O(nlogn)
O(1)
不稳定
归并排序
O(nlogn)
O(nlogn)
O(nlogn)
O(n)
稳定
快速排序
O(nlogn)
O(nlogn)
O(n2)
O(logn)~O(n)
不稳定


```cpp

void quickSort(int arr[], int left, int right){
    int index = partition(arr, left, right);
    if (left < index - 1){
        quickSort(arr, left, index - 1);
    }
    if (index < right){
        quickSort(arr, index, right);
    }
}

int partition(int arr[], int left, int right){
    int pivot = arr[(left + right) / 2];
    while (left <= right){
        while (arr[left] < pivot) left++;
        while (arr[right] > pivot) right--;

        // Swap elements, and move left and right indices
        if (left <= right){
            swap(arr, left, right);
            left++;
            right--;
        }
    }
    return left;
}

int binarySearch(int[] a, int x){
    int low = 0;
    int high = a.length - 1;
    int mid;

    while (low <= high){
        mid = (low + high) / 2;
        if (a[mid] < x){
            low = mid + 1;
        }
        else if (a[mid] > x){
            high = mid - 1;
        }
        else {
            return mid;
        }
    }
    return -1;
}

int binarySearchRecursive(int[] a, int x, int low, int high){
    if (low > high) return -1;

    int mid = (low + high) / 2;
    if (a[mid] < x){
        return binarySearchRecursive(a, x, mid + 1, high);
    }
    else if (a[mid] > x){
        return binarySearchRecursive(a, x, low, mid - 1);
    }
    else{
        return mid;
    }
}

```

常见的外排序算法
外排序算法的核心思路在于把文件分块读到内存，在内存中对每块文件依次进行排序，最后合并排序后的各块数据，依次按顺序写回文件。相比于内排序，外排序需要进行多次磁盘读写，因此执行效率往往低于内排序，时间主要花费于磁盘读写上。我们给出外排序的算法步骤如下：
假设文件需要分成k块读入，需要从小到大进行排序
依次读入每个文件块，在内存中对当前文件块进行排序(应用恰当的内排序算法)。此时，每块文件相当于一个由小到大排列的有序队列
在内存中建立一个最小值堆，读入每块文件的队列头
弹出堆顶元素，如果元素来自第i块，则从第i块文件中补充一个元素到最小值堆。弹出的元素暂存至临时数组
当临时数组存满时，将数组写至磁盘，并清空数组内容。
重复过程3)，4)，直至所有文件块读取完毕

所谓外排序，顾名思义，即是在内存外面的排序，因为当要处理的数据量很大，而不能一次装入内存时，此时只能放在读写较慢的外存储器（通常是硬盘）上。
外排序通常采用的是一种“排序-归并”的策略。
在排序阶段，先读入能放在内存中的数据量，将其排序输出到一个临时文件，依此进行，将待排序数据组织为多个有序的临时文件；
尔后在归并阶段将这些临时文件组合为一个大的有序文件，也即排序结果。

参考编程珠玑一书上的位图方案，针对我们的10^7个数据量的磁盘文件排序问题，我们可以这么考虑，由于每个7位十进制整数表示一个小于1000万的整数。我们可以使用一个具有1000万个位的字符串来表示这个文件，其中，当且仅当整数i在文件中存在时，第i位为1。采取这个位图的方案是因为我们面对的这个问题的特殊性：
输入数据限制在相对较小的范围内，
数据没有重复，
其中的每条记录都是单一的整数，没有任何其它与之关联的数据。
所以，此问题用位图的方案分为以下三步进行解决：
第一步，将所有的位都置为0，从而将集合初始化为空。
第二步，通过读入文件中的每个整数来建立集合，将每个对应的位都置为1。
第三步，检验每一位，如果该位为1，就输出对应的整数。
经过以上三步后，产生有序的输出文件



快速选择算法 (quick selection algorithm)
快速选择算法能够在平均O(n)时间内从一个无序数组中返回第k大的元素。算法实际上利用了快速排序的思想，将数组依照一个轴值分割成两个部分，左边元素都比轴值小，右边元素都比轴值大。由于轴值下标已知，则可以判断所求元素落在数组的哪一部分，并在那一部分继续进行上述操作，直至找到该元素。与快排不同，由于快速选择算法只在乎所求元素所在的那一部分，所以时间复杂度是O(n)。关于算法复杂度的理论分析请见“工具箱”给出的参考资料。我们给出算法实现如下：

```cpp
int partition( int array[], int left, int right ) {
    int pivot = array[right];
    while( left != right ){
        while( array[left] < pivot && left < right)
            left++;
            left++;
        if (left < right) {
            swap( array[left], array[right--]);
        }
        while( array[right] > pivot && left < right)
            right--;
        if( left < right )
            swap( array[left++], array[right]);
    }
    return left;
}

int quick_select(int array[], int left, int right, int k)
{
    if ( left >= right )
        return array[left];
    int index = partition(array, left, right);
    int size = index - left + 1;
    if ( size == k )
        return array[left + k - 1]; // the pivot is the kth largest element
    else if ( size > k )
        return quick_select(array, left, index - 1, k);
    else
        return quick_select(array, index + 1, right , k - size);
}

```


操作符
功能
用法
~
位求反
~var
<<
左移(乘法)
var << position
>>
右移(除法)
var >> position
&
位与
var1 & var2
^
位异或
var1 ^ var2
|
位或
var1 | var2

最基本的操作包括获取位、设置位和清除位。获取位可以利用&1：&(0x1 << pos) ；设置位可以利用|1: | (0x1 << pos) ；清除位可以利用&0: &(~(0x1 << pos))。判断某位是否相同用：(A & (0x1 << pos)) ^ (B & (0x1 << pos))。
```c
int updateBit(int num, int i, boolean bitIs1){
    int value = bitIs1 ? 1 : 0;
    int mask = ~(1 << i);
    return (num & mask) | (value << i);
}
```

**面向对象设计**

我们先来看看系统设计的面试流程:
题目描述 
往往非常简单，如：设计一个XX系统。或者：你有没有用过XXX，给你看一下它的界面和功能，你来设计一个。
阐述题意 
面试者需向面试官询问系统的具体要求。如，需要什么功能，需要承受的流量大小，是否需要考虑可靠性，容错性等等。
面试者提供一个初步的系统设计
面试官这对初步的系统中提出一些后续的问题：如果要加某个功能怎么办，如果流量大了怎么办，如何考虑一致性，如果机器挂了怎么办。
面试者根据面试官的后续问题逐步完善系统设计
完成面试
总体特点是以交流为主，画图和代码为辅。
根据我们面试别人和参与面试的经验，先从面试官的角度给出一些考量标准：
适应变化的需求(Adapt to the changing requirements )
设计干净，优美，考虑周到的系统(Produce a system that is clean, elegant, well thought )
解释为何这么实现(Explain why you choose this implementation )
对自己的能力水平很熟练(Be familiar with your experience level to make decisions )
在一些高层结构和复杂性方面有设计(Answer in high level of scale and complexity )


解题策略
Abstractions, Object and Decoupling
通常，关于OOP，面试官会让面试者设计一个程序框架，该程序能够实现一些特定的功能。比如，如何实现一个音乐播放器，如何设计一个车库管理程序等等。对于此类问题，设计的关键过程一般包括抽象(abstraction)，设计对象(object)和设计合理的层次／接口(decoupling)。这里，我们举一个例子简单说明这些过程分别需要做些什么，在“模式识别”给出更为具体和完整的实例。
继承/组合/参数化类型
在面向对象中最常用的两种代码复用技术就是继承和组合。在设计对象的时候，“Is-A”表示一种继承关系。比如，班长“Is-A”学生，那么，学生就是基类，班长就是派生类。在确定了派生关系之后，我们需要分析什么是基类变量(base class variables)什么是子类变量(sub class variables)，并由此确定基类和派生类之间的联系。而“Has-A”表示一种从属关系，这就是组合。比如，班长“Has-A”眼镜，那就可以解释为班长实例中拥有一个眼镜实例变量(instance variable)。在具体实现的时候，班长类中定义一个眼镜的基类指针。“在生成班长实例的时候，同时生成一个眼镜实例，利用眼镜的基类指针指向这个实例。任何关于眼镜的操作函数都可以利用这个基类指针实现多态(polymorphism)。注意，多态是OOP相关的一个重要概念，也是面试常考的概念之一。关于多态的解释请见“工具箱”。
在通常情况下，我们更偏向于“Has-A”的设计模式。因为该模式减少了两个实例之间的相关性。对于继承的使用，通常情况下我们会定义一个虚基类，由此派生出多个不同的实例类。在业界的程序开发中，多重继承并不常见，Java甚至不允许从多个父类同时继承，产生一个子类。
此外，我们还要提及参数化类型。参数化类型，或者说模版类也是一种有效的代码复用技术。在C++的标准模版库中大量应用了这种方式。例如，在定义一个List的变量时，List被另一个类型String所参数化。
设计模式着重于代码的复用，所以在选择复用技术上，有必要看看上述三种复用技术优劣。
继承
通过继承方式，子类能够非常方便地改写父类方法，同时
保留部分父类方法，可以说是能够最快速地达到代码复用。
继承是在静态编译时候就定义了，所以无法再运行时刻改写父类方法。
因为子类没有改写父类方法的话，就相当于依赖了父类这个方法的实现细节,被认为破坏封装性。
并且如果父类接口定义需要更改时，子类也需要提更改响应接口。
组合
对象组合通过获得其他对象引用而在运行时刻动态定义的。
组合要求对象遵守彼此约定，进而要求更仔细地定义接口，而这些接口并不妨碍你将一个对象和另外一个对象一起使用。
对象只能够通过接口来访问，所以我们并没有破坏封装性。
而且只要抽象类型一致，对象是可以被替换的。
使用组合方式，我们可以将类层次限制在比较小的范围内，不容易产生类的爆炸。
相对于继承来说,组合可能需要编写“更多的代码。
参数化类型
参数化类型方式是基于接口的编程，在一定程度上消除了类型给程序设计语言带来的限制。
相对于组合方式来说，缺少的是动态修改能力。
因为参数化类型本身就不是面向对象语言的一个特征，所以在面向对象的设计模式里面，没有一种模式是于参数化类型相关的。
实践上我们方面是可以使用参数化类型来编写某种模式的。
总结
对象组合技术允许你在运行时刻改变被组合的行为，但是它存在间接性，相对来说比较低效。
继承允许你提供操作的缺省实现，通过子类来重定义这些操作，但是不能够在运行时改变。
参数化允许你改变所使用的类型，同样不能够在运行时改变。


**设计模式**
所谓的设计模式是指人们在开发软件的过程中，对于一些普适需求而总结的设计模版。根据模式目的可以分为三类：
创建型(Creational).创建型模式与对象的创建相关。
结构型(Structural).结构型模式处理类或者是对象的组合。
行为型(Behavioral).行为型模式对类或者是对象怎样交互和怎样分配职责进行描述。
下面我们对每种类型进行介绍。具体的模式请见“工具箱”。值得提醒的是，在面试或工作中不可盲目相信设计模式。设计模式更多地只是提供一些思路，能够直接套用设计模式的情况并不多，更多的时候是对现成设计模式的改进和组合。所以对于设计模式的学习更多应该着眼于模式的意图，而不是模式的具体实现方法。

创建型
一个类的创建型模式使用继承改变被实例化的类，而一个对象的创建型模式将实例化委托给另外一个对象。 在这些模式中有两种不断出现的主旋律：
将该系统使用哪些具体的类封装起来
隐藏了实例是如何被创建和存储的
总而言之，效果就是用户创建对象的结果是得到一个基类指针，用户通过基类指针调用继承类的方法。用户不需要知道在使用哪些继承类。

单例模式
意图：单例模式(Singleton Pattern)是一种常见的设计模式。其目的在于保证一个类仅仅有一个实例并且提供一个访问它的全局访问点。
这个模式主要的对比对象就是全局变量。相对于全局变量，单例有下面这些好处：
全局变量不能够保证只有一个实例。
某些情况下面，我们需要稍微计算才能够初始化这个单例。全局变量也行但是不自然。
C++下面没有保证全局变量的初始化顺序.
比如，在我们之前说的音乐播放器设计中，我们引入了歌曲管理器实现数据的存储。歌曲管理器在整个程序中应当实例化一次，其他所有关于数据的操作都应该在这个实例上进行。所以，歌曲管理器应该应用单例模式。实现单例模式的关键在于利用静态变量(static variable)，通过判断静态变量是否已经初始化判断该类是否已经实例化。此外，还需要把构造函数设为私有函数，通过公共接口getSharedInstance进行调用

工厂模式
意图：抽象类需要创建一个对象时，让子类决定实例化哪一个类
所谓的工厂模式(Factory Pattern)，就是指定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类。通常，接口提供传入参数，用以决定实例化什么类。工厂模式常见于工具包和框架中，当需要生成一系列类似的子类时，可以考虑使用工厂模式。举例如下：

结构型
类的结构型模式采用继承机制来组合接口。对象的结构型模式不是对接口进行组合， 而是描述如何对一些对象进行组合，从而实现新功能。
适配器
意图：适配器(Adapter)将一个类的接口转化成为客户希望的另外一个接口。
假设A实现了Foo()接口，但是B希望A同样实现一个Bar()接口，事实上Foo()基本实现了Bar()接口功能。 Adapter模式就是设计一个新类C，C提供Bar()接口，但实现的方式是内部调用 A的Foo()。
在实现层面上可以通过继承和组合两种方式达到目的：C可以继承A，或者C把A作为自己的成员变量。两者孰优孰劣需要视情况而定。
行为型
行为型涉及到算法和对象之间职责的分配。行为模式不仅描述对象或者类的功能行为，还描述它们之间的通信模式。 这些模式刻画了在运行时难以追踪的控制流，它们将你的注意从控制流转移到对象之间的联系上来。
观察者
意图：观察者模式(observer)定义对象之间的依赖关系，当一个对象“状态发生改变的话，所有依赖这个对象的对象都会被通知并且进行更新。
被观察的对象需要能够动态地增删观察者对象，这就要求观察者提供一个公共接口比如Update()。然后每个观察者实例注册到被观察对象里面去，在被观察对象状态更新时候能够遍历所有注册观察者并且调用Update()。
至于观察者和被观察之间是采用push还是pull模式完全取决于应用。对于观察这件事情来说的话， 我们还可以引入方面(Aspect)这样一个概念，在注册观察者的时候不仅仅只是一个观察者对象， 还包括一个Aspect参数，可以以此告诉被观察者仅在发生某些变化时通过调用Update()通知我。
状态
意图：状态模式(state)允许一个对象在其内部状态改变时改变它的行为。
这里状态模式意图是，对于实例A，当A的状态改变时，将A可能改变的行为封装成为一个类S(有多少种可能的状态就有多少个S的子类,比如S1,S2,S3等)。当A的状态转换时，在A内部切换S的实例。从A的用户角度来看，A的接口不变，但A的行为因A的状态改变而改变，这是因为行为的具体实现由S完成。

有限状态机
创建型设计模式补充
Builder
意图：将一个复杂对象构建过程和元素表示分离。
假设我们需要创建一个复杂对象，而这个复杂对象是由很多元素构成的。这些元素的组合逻辑可能非常复杂， 但是逻辑组合和创建这些元素是无关的，独立于这些元素本身的。
那么我们可以将元素的组合逻辑以及元素构建分离，元素构建我们单独放在Builder这样一个类里面，而元素的组合逻辑通过Director来指导，Director内部包含Builder对象。创建对象是通过Director来负责组合逻辑部分的， Director内部调用Builder来创建元素并且组装起来。最终通过Builder的GetResult来获得最终复杂对象。
结构型设计模式补充
Bridge
意图：将抽象部分和具体实现相分离，使得它们之间可以独立变化。
一个很简单的例子就是类Shape,有个方法Draw[抽象]和DrawLine[具体]和DrawText[具体],而Square和SquareText 继承于Shape实现Draw()这个方法，Square调用DrawLine()，而SquareText调用DrawLine()+DrawText()。而且假设DrawLine和DrawText分别有LinuxDrawLine,LinuxDrawText和Win32DrawLine和Win32DrawText。如“果我们简单地 使用子类来实现的话，比如构造LinuxSquare,LinuxSquareText,Win32Square和Win32SquareText，那么很快就会类爆炸。
事实上我们没有必要在Shape这个类层面跟进变化，即通过继承Shape类实现跨平台，而只需要在实现底层跟进变化。为此我们就定义一套接口，如例子中的DrawLine和DrawText，然后在Linux和Win32下实现一个这样接口实例(比如称为跨平台GDI)，最终 Shape内部持有这个GDI对象，Shape的DrawLine和DrawText只是调用GDI的接口而已。这样，我们把Shape及其子类的DrawLine和DrawText功能Bridge到GDI，GDI可以通过工厂模式在不同平台下实现不同的实例。
例子中Shape成为了完全抽象的部分，具体实现完全交给GDI类，若以后需要增加更多的平台支持，开发者也不需要添加更多的Shape子类，只需要扩展GDI即可。总之，抽象部分是和具体实现部分需要独立开来的时候，就可以使用Bridge模式。
Composite
意图：将对象组合成为树形以表示层级结构，对于叶子和非叶子节点对象使用需要有一致性。
Composite模式强调在这种层级结构下，叶子和非叶子节点需要一致对待，所以关键是需要定义一个抽象类，作为叶节点的子节点。 然后对于叶子节点操作没有特殊之处，而对于非叶子节点操作不仅仅需要操作自身，还要操作所管理的子节点。 至于遍历子节点和处理顺序是由应用决定的，在Composite模式里面并不做具体规定。
Decorator
意图：动态地给对象添加一些额外职责，通过组合而非继承方式完成。
给对象添加一些额外职责，例如增加新的方法，很容易会考虑使用子类方式来实现。使用子类方式实现很快但是却不通用，考虑一个抽象类X，子类有SubX1,SubX2等。现在需要为X提供一个附加方法echo，如果用继承的方式添加，那么需要为每个子类都实现echo方法，并且代码往往是重复的。我们可以考虑Decorator模式，定义一个新类，使其持有持有指向X基类的指针，并且新类只需要单独实现echo方法，而其他方法直接利用X基类指针通过多态调用即可。
值得注意的是，装饰出来的对象必须包含被装饰对象的所有接口。所以很明显这里存在一个问题， 那就是X一定不能够有过多的方法，不然Echo类里面需要把X方法全部转发一次(理论上说Echo类可以仅转发X的部分方法，但Decorator默认需要转发被装饰类的全部方法)。
Façade
意图：为子系统的一组接口提供一个一致的界面。
编译器是一个非常好的的例子。对于编译器来说，有非常多的子系统包括词法语法解析，语义检查,中间代码生成，代码优化，以及代码生成这些逻辑部件。但是对于大多数用户来说，不关心这些子系统，而只是关心编译这一个过程。
所以我们可以提供Compiler的类，里面只有很简单的方法比如Compile()，让用户直接使用Compile()这个接口。 一方面用户使用起来简单，另外一方面子系统和用户界面耦合性也降低了。
Facade模式对于大部分用户都是满足需求的。对于少部分不能够满足需求的用户，可以让他们绕过Facade模式提供的界面， 直接控制子系统即可。就好比GCC提供了很多特殊优化选项来让高级用户来指定，而不是仅仅指定-O2这样的选项。
Proxy
意图：为其他对象提供一种代理以控制对这个对象的访问。
通常使用Proxy模式是想针对原本要访问的对象做一些手脚，以达到一定的目的，包括访问权限设置，访问速度优化，或者是加入一些自己特有的逻辑。至于实现方式上，不管是继承还是组合都行，可能代价稍微有些不同，视情况而定。但是偏向组合方式，因为对于Proxy而言，完全可以定义一套新的访问接口。
Adapter,Decorator以及Proxy之间比较相近，虽然说意图上差别很大，但是对于实践中， 三者都是通过引用对象来增加一个新类来完成的，但是这个新类在生成接口方面有点差别：
Adapter模式的接口一定要和对接的接口相同。
Decorator模式的接口一定要包含原有接口，通常来说还要添加新接口。
Proxy模式完全可以重新定义一套新的接口
行为型设计模式补充
Chain of Responsibility
意图：将对象连成一条链并沿着链传递某个请求，直到有某个对象处理它为止。
大部分情况下连接起来的对象本身就存在一定的层次结构关系，少数情况下面这些连接起来的对象是内部构造的。 职责链通常与Composite模式一起使用，一个构件的父构件可以作为它的后继结点。许多类库使用职责链模式来处理事件， 比如在UI部分的话View本来就是相互嵌套的，一个View对象可能存在Parent View对象。如果某个UI不能够处理事件的话， 那么完全可以交给Parent View来完成事件处理以此类推。 
Command
意图：将一个请求封装成为一个对象。
Command模式可以说是回调机制(Callback)的一个面向对象的替代品。对于回调函数来说需要传递一个上下文参数(context)， 同时内部附带一些逻辑。将上下文参数以及逻辑包装起来的话那么就是一个Command对象。 Command对象接口可以非常简单只有Execute/UnExecute，但是使用Command对象来管理请求之后， 就可以非常方便地实现命令的复用，排队，重做，撤销，事务等。
Iterator
意图：提供一种方法顺序访问一个聚合对象中各个元素，但是又不需要暴露该对象内部表示。
将遍历机制与聚合对象表示分离，使得我们可以定义不同的迭代器来实现不同的迭代策略，而无需在聚合对象接口上面列举他们。 一个健壮的迭代器,应该保证在聚合对象上面插入和删除操作不会干扰遍历，“同时不需要copy这个聚合对象。 一种实现方式就是在聚合对象上面注册某个迭代器，一旦聚合对象发生改变的话，需要调整迭代器内部的状态。
Template Method
意图：定义一个操作里面算法的骨架，而将一些步骤延迟到子类。
假设父类A里面有抽象方法Step1(),Step2(),默认方法Step3()。并且A提供一个操作X()，分别依次使用Step1(),Step2(),Step3()。对于A的子类，通过实现自己的Step1(),Step2() (选择性地实现Step3())，提供属于子类的X具体操作。 这里操作X()就是算法的骨架，子类需要复写其中部分step，但不改变X的执行流程。
很重要的一点是模板方法必须指明哪些操作是钩子操作(可以被重定义的，比如Step3),以及哪些操作是抽象操作“(必须被重定义，比如Step1和Step2)。要有效地重用一个抽象类，子类编写者必须明确了解哪些操作是设计为有待重定义的。

面向对象的三个基本特征是：封装、继承、多态
封装 
封装最好理解了。封装是面向对象的特征之一，是对象和类概念的主要特性。封装，也就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。
继承 
继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。通过继承创建的新类称为“子类”或“派生类”，被继承的类称为“基类”、“父类”或“超类”。
要实现继承，可以通过“继承”（Inheritance）和“组合”（Composition）来实现。
多态性 
多态性（polymorphisn）是允许你将父对象设置成为和一个或更多的他的子对象相等的技术，赋值之后，父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。简单的说，就是一句话：允许将子类类型的指针赋值给父类类型的指针。
实现多态，有两种方式，覆盖和重载。覆盖和重载的区别在于，覆盖在运行时决定，重载是在编译时决定。并且覆盖和重载的机制不同，例如在 Java 中，重载方法的签名必须不同于原先方法的，但对于覆盖签名必须相同

**测试**
在面试软件开发的过程中，面试官可能也会询问关于软件开发流程以及测试方法相关的问题。在大多数互联网公司，许多部门不一定配有专门的QA(Quality Assurance)，在这种情况下，程序员本身需要对自己开发的模块和系统进行测试。另一方面，程序员在开发过程中测试自己的程序也是非常好的习惯，这样可以确保开发效率。基于上述原因，面试软件开发职位但遇到测试相关的问题并不少见

**测试现实世界的物体、软件或函数**
三者并无本质的差别，问题的核心均在于：测试对象在不同的输入下，能否实现预计的功能，提供恰当的输出。 一般情况下，总是需要考虑以下几个方面，以全面测试对象对于不同类型输入的效果：
(1) 常规情况(Normal cases)
输入不同类型的合法数据，主要用以判断对象的功能性：在给定输入的情况下能否给出期望的输出，由此判断功能的实现是否正确。比如，测试银行账户的转账功能：假设账户中有1000元，可以输入100，2000等并判断余额及转出钱数是否符合期望。
(2) 极端情况(Extreme cases)
测试一些边界条件或极端情况。所谓的极端情况包括多用户或多线程情况下频繁地访问／更新数据。比如，继续测试银行账户的转账功能：假设账户中有1000元，可以测试边界条件，取出1000元等。或者测试极端情况，假设用户开了多个页面，并在每个页面上几乎同时都尝试转出1000元，或者用户通过ATM机和手机APP同时进行转账操作等。
(3) 非法情况(Invalid case)
主要测试用户输入非法数据时系统不会崩溃，并且能够给出恰当的反馈。比如，测试银行账户的转账功能：当用户输入大于账户余额的数字时，或者当接收人账户错误时，系统能否给出错误提示等。

**故障排除(Troubleshooting)**
另一大类的常见问题是给出一个有问题的测试现象，让面试者判断问题出现在哪里。对于这类问题，首先考虑测试对象由生成，到运行，到产生最终结果的完整流程，其次判断每一步执行了什么，需要依赖哪些参数，该步骤的异常是否会导致最终的测试现象，并且考虑如何验证自己的判断。 例如，测试用户无法访问你开发的网站。首先考虑主要流程，简述如下：用户连接到网络，发送HTTP请求到网站，网站发送数据包给用户，用户浏览器显示页面。在此例中，每一步都有可能导致无法访问网站的情况，具体描述如下：
(1) 用户连接到网络：这一步用户需要获得有效的IP，获取访问互联网的权限。需要依赖用户的网卡是否工作正常，是否能够被分配到有效的IP，是否能够从路由器或者服务器获得互联网访问权限等等。检验方式可以是：可以打开终端用ping命令，尝试建立与大型网站的连接。或者直接用浏览器尝试访问其他大型网站。如果不能建立与其他网站的连接，则网络接入有问题。
(2) 发送HTTP请求到网站：用户首先会通过DNS获取服务器地址，然后发送HTTP请求到对应的IP。需要依赖用户能否正确获取网站IP地址。检验方式可以是：在用户端利用抓包软件，例如WireShark，tcpdump等，观察是否有HTTP请求发送到网站服务器。如果没有发送HTTP请求或目的地IP有问题，则DNS可能有错。
(3) 网站发送数据包给用户：这一步需要网站接收到HTTP请求，并且将对应数据传回给用户。需要依赖网站能否收到HTTP请求以及对于HTTP请求的处理是否正确。检验方式可以是：在服务器端通过log判断是否有新用户接入，接入请求的处理是否正确，以及发送给用户的数据是什么。如果网站没有收到请求，则服务器端的网络可能有问题。如果服务器无法处理HTTP请求或抛出异常，则服务器的实现可能有问题。
(4) 用户浏览器显示页面： 这一步需要用户接收到网站发回的数据，浏览器解析数据并显示页面。需要依赖于用户能否收到数据，以及收到的数据是否能够被浏览器正确解析及显示。检验方式可以是：在用户端利用抓包软件，观察是否有来自服务器的数据。一般来说，如果用户用的是商用浏览器，即能够正确解析数据。故如果能收到服务器数据但是不能正常显示，我们可以认为服务器的数据有问题。

GNU调试器命令
Compile with GDB support: gcc -g prog.c -o prog.x;
Start debugging: gdb prog.x , (gdb) run;
Handle breakpoints: (gdb) break prog.c: 6 or (gdb) break my_func; if, continue, step, next; delete;
Watch variable: (gdb) print my_var, (gdb) watch my_var, (gdb) x (address of var);
Other utilities: (gdb) backtrace, (gdb) finish.

AB Testing
AB测试是一种对比测试方案。测试人员对于不同用户随机生成两种方案，例如，某些用户看到的网页按钮是圆形的，其他用户看到的网页按钮是方形的。通过用户对于不同测试方案的反应，来决定最终部署哪种方案。具体请参考：

Black Box Testing
黑箱测试主要用于测试程序的功能，而不是内部结构或运作。测试者秩序知道输入以及对应的输出，就可以生成测试数据。黑箱测试的目的在于快速检测程序的功能性。特别地，黑箱测试还应该包括非法的输入数据，以确保程序不会崩溃。
White Box Testing
与黑箱测试相对，白箱测试主要用于测试程序的内部结构或运作。测试人员需要从程序设计的角度生成测试案例：输入测试数据并验证程序按照既定的流程执行。

Unit Test
优良的软件设计强调模块化，即模块之间通过API进行交互，每个模块负责实现相对独立的功能。单元测试的目的在于对于每个模块设计相应的测试数据，用以检验模块的功能。通常，单元测试采用黑箱测试，通过运行脚本完成。测试人员将测试数据输入脚本，将输出结果与期望的输出数据进行比较。单元测试不仅仅可以用于新模块的开发，还可以用于对于已有模块的更新，维护。对于模块的每次更改都应该运行相应的单元测试以确保功能的完整性。
Alpha Test
Alpha测试通常是阶段性开发完成后开始进行。主要是面向内部开发人员，在模拟环境中输入模拟的数据进行测试，以验证系统符合使用者以及设计者的需求。
Beta Test
当Alpha阶段完成后，可以进入由公众参与的beta测试阶段。Beta测试通常使用真实的运行环境，并且使用实际数据进行测试，以确认系统效率。测试的主要目的在于进一步测试及完善功能。


解答：互斥条件(Mutual exclusion)：
资源不能被共享，只能由一个进程使用。
请求与保持条件(Hold and wait)：已经得到资源的进程可以再次申请新的资源。
非剥夺条件(No pre-emption)：已经分配的资源不能从相应的进程中被强制地剥夺。
循环等待条件(Circular wait)：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源。
如何处理死锁问题：
忽略该问题。例如鸵鸟算法，该算法可以应用在极少发生死锁的的情况下。为什么叫鸵鸟算法呢，因为传说中鸵鸟看到危险就把头埋在地底下，可能鸵鸟觉得看不到危险也就没危险了吧。跟掩耳盗铃有点像。
检测死锁并且恢复。
仔细地对资源进行动态分配，以避免死锁。
通过破除死锁四个必要条件之一，来防止死锁产生。

实时 vs.分时操作系统
操作系统可以分为实时操作系统(Real-time system)，和分时操作系统(Sharing time system)。通常计算机采用的是sharing time，即多个进程／用户之间共享CPU，从形势上实现多任务。各个用户／进程之间的调度并非精准度特别高，如果一个进程被锁住，可以给它分配更多的时间。而实时操作系统则不同，软件和硬件必须遵从严格的deadline，超过时限的进程可能直接被终止。在这样的操作系统中，每次加锁都需要仔细考虑。

文件系统
Unix风格的文件系统利用树形结构管理文件。每个节点有多个指针，指向下一层节点或者文件的磁盘存储位置。文件节点还附有文件的操作信息(metadata)，包括修改时间，访问权限等等。
用户的访问权限通过访问控制表(Access Control List)和能力表(Capability List)实现。前者从文件角度出发，标注了每个用户可以对该文件进行何种操作。后者从用户角度出发，标注了某用户可以以什么权限操作哪些文件。
Unix的文件权限分为读、写和执行，用户组分为文件拥有者，组和所有用户。可以通过命令对三组用户分别设置权限。

逻辑地址/物理地址/虚拟内存
所谓的逻辑地址，是指计算机用户(例如程序开发者)，看到的地址。例如，当创建一个长度为100的整型数组时，操作系统返回一个逻辑上的连续空间：指针指向数组第一个元素的内存地址。由于整型元素的大小为4个字节，故第二个元素的地址时起始地址加4，以此类推。事实上，逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址(在内存条中所处的位置)，并非是连续的，只是操作系统通过地址映射，将逻辑地址映射成连续的，这样更符合人们的直观思维。
另一个重要概念是虚拟内存。操作系统读写内存的速度可以比读写磁盘的速度快几个量级。但是，内存价格也相对较高，不能大规模扩展。于是，操作系统可以通过将部分不太常用的数据移出内存，“存放到价格相对较低的磁盘缓存，以实现内存扩展。操作系统还可以通过算法预测哪部分存储到磁盘缓存的数据需要进行读写，提前把这部分数据读回内存。虚拟内存空间相对磁盘而言要小很多，因此，即使搜索虚拟内存空间也比直接搜索磁盘要快。唯一慢于磁盘的可能是，内存、虚拟内存中都没有所需要的数据，最终还需要从硬盘中直接读取。这就是为什么内存和虚拟内存中需要存储会被重复读写的数据，否则就失去了缓存的意义。
现代计算机中有一个专门的转译缓冲区(Translation Lookaside Buffer，TLB)，用来实现虚拟地址到物理地址的快速转换。
与内存／虚拟内存相关的还有如下两个概念：
1) Resident Set
当一个进程在运行的时候，操作系统不会一次性加载进程的所有数据到内存，只会加载一部分正在用，以及预期要用的数据。其他数据可能存储在虚拟内存，交换区和硬盘文件系统上。被加载到内存的部分就是resident set。
2) Thrashing
由于resident set包含预期要用的数据，理想情况下，进程运行过程中用到的数据都会逐步加载进resident set。但事实往往并非如此：每当需要的内存页面(page)不在resident set中时，操作系统必须从虚拟内存或硬盘中读数据，这个过程被称为内存页面错误(page faults)。当操作系统需要花费大量时间去处理页面错误的情况就是thrashing。


进程的基本状态
等待态：等待某个事件的完成；
就绪态：等待系统分配处理器以便运行；
运行态：占有处理器正在运行。
运行态→等待态 往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。
等待态→就绪态 则是等待的条件已满足，只需分配到处理器后就能运行。
运行态→就绪态 不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。
就绪态→运行态 系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态

调度种类
高级、中级和低级调度作业从提交开始直到完成，往往要经历下述三级调度：
高级调度：(High-Level Scheduling)又称为作业调度，它决定把后备作业调入内存运行；
低级调度：(Low-Level Scheduling)又称为进程调度，它决定把就绪队列的某进程获得CPU；
中级调度：(Intermediate-Level Scheduling)又称为在虚拟存储器中引入，在内、外存对换区进行进程对换。

非抢占式调度与抢占式调度
非抢占式 
分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程。
抢占式 
操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式。

调度策略的设计
响应时间: 从用户输入到产生反应的时间
周转时间: 从任务开始到任务结束的时间
CPU任务可以分为交互式任务和批处理任务，调度最终的目标是合理的使用CPU，使得交互式任务的响应时间尽可能短，用户不至于感到延迟，同时使得批处理任务的周转时间尽可能短，减少用户等待的时间。

调度算法
FIFO或First Come, First Served (FCFS) 
调度的顺序就是任务到达就绪队列的顺序。
公平、简单(FIFO队列)、非抢占、不适合交互式。未考虑任务特性，平均等待时间可以缩短
Shortest Job First (SJF) 
最短的作业(CPU区间长度最小)最先调度。
可以证明，SJF可以保证最小的平均等待时间。
Shortest Remaining Job First (SRJF)
SJF的可抢占版本，比SJF更有优势。
SJF(SRJF): 如何知道下一CPU区间大小？根据历史进行预测: 指数平均法。
优先权调度 
每个任务关联一个优先权，调度优先权最高的任务。
注意：优先权太低的任务一直就绪，得不到运行，出现“饥饿”现象。
FCFS是RR的特例，SJF是优先权调度的特例。这些调度算法都不适合于交互式系统。
Round-Robin(RR) 
设置一个时间片，按时间片来轮转调度（“轮叫”算法）
优点: 定时有响应，等待时间较短；缺点: 上下文切换次数较多；
如何确定时间片？
时间片太大，响应时间太长；吞吐量变小，周转时间变长；当时间片过长时，退化为FCFS。
多级队列调度 
按照一定的规则建立多个进程队列
不同的队列有固定的优先级（高优先级有抢占权）
不同的队列可以给不同的时间片和采用不同的调度方法
存在问题1：没法区分I/O bound和CPU bound；
存在问题2：也存在一定程度的“饥饿”现象；
多级反馈队列 
在多级队列的基础上，任务可以在队列之间移动，更细致的区分任务。
可以根据“享用”CPU时间多少来移动队列，阻止“饥饿”。
最通用的调度算法，多数OS都使用该方法或其变形，如UNIX、Windows等。

进程同步
临界资源与临界区
在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。
对于临界资源的访问，必须是互斥进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。
对于临界区的访问过程分为四个部分：
进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞
临界区:在临界区做操作
退出区:清除临界区被占用的标志
剩余区：进程与临界区不相关部分的代码
解决临界区问题可能的方法：
一般软件方法
关中断方法
硬件原子指令方法
信号量方法

信号量
信号量是一个确定的二元组（s，q），其中s是一个具有非负初值的整形变量，q是一个初始状态为空的队列，整形变量s表示系统中某类资源的数目：
当其值 ≥ 0 时，表示系统中当前可用资源的数目
当其值 ＜ 0 时，其绝对值表示系统中因请求该类资源而被阻塞的进程数目
除信号量的初值外，信号量的值仅能由P操作和V操作更改，操作系统利用它的状态对进程和资源进行管理
P操作
P 操作记为P(s)，其中s为一信号量，它执行时主要完成以下动作：
s.value = s.value - 1；  /*可理解为占用1个资源，若原来就没有则记帐“欠”1个*/
若s.value ≥ 0，则进程继续执行，否则（即s.value < 0），则进程被阻塞，并将该进程插入到信号量s的等待队列s.queue中
说明：实际上，P操作可以理解为分配资源的计数器，或是使进程处于等待状态的控制指令
V操作
V 操作记为V(s)，其中s为一信号量，它执行时，主要完成以下动作：
s.value = s.value + 1；/*可理解为归还1个资源，若原来就没有则意义是用此资源还1个欠帐*/
若s.value > 0，则进程继续执行，否则（即s.value ≤ 0）,则从信号量s的等待队s.queue中移出第一个进程，使其变为就绪状态，然后返回原进程继续执行
说明：实际上，V操作可以理解为归还资源的计数器，或是唤醒进程使其处于就绪状态的控制指令
信号量方法实现：生产者 − 消费者互斥与同步控制

磁盘调度
磁盘访问延迟 = 队列时间 + 控制器时间 + 寻道时间 + 旋转时间 + 传输时间
磁盘调度的目的是减小延迟，其中前两项可以忽略，寻道时间是主要矛盾。

磁盘调度算法
FCFS 
先进先出的调度策略，这个策略具有公平的优点，因为每个请求都会得到处理，并且是按照接收到的顺序进行处理。
SSTF(Shortest-seek-time First 最短寻道时间优先) 
选择使磁头从当前位置开始移动最少的磁盘I/O请求，所以 SSTF 总是选择导致最小寻道时间的请求。
总是选择最小寻找时间并不能保证平均寻找时间最小，但是能提供比 FCFS 算法更好的性能，会存在饥饿现象。
SCAN 
SSTF+中途不回折，每个请求都有处理机会。
SCAN 要求磁头仅仅沿一个方向移动，并在途中满足所有未完成的请求，直到它到达这个方向上的最后一个磁道，或者在这个方向上没有其他请求为止。
由于磁头移动规律与电梯运行相似，SCAN 也被称为电梯算法。
SCAN 算法对最近扫描过的区域不公平，因此，它在访问局部性方面不如 FCFS 算法和 SSTF 算法好。
C-SCAN 
SCAN+直接移到另一端，两端请求都能很快处理。
把扫描限定在一个方向，当访问到某个方向的最后一个磁道时，磁道返回磁盘相反方向磁道的末端，并再次开始扫描。
其中“C”是Circular（环）的意思。
LOOK 和 C-LOOK 
釆用SCAN算法和C-SCAN算法时磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点。这种形式的SCAN算法和C-SCAN算法称为LOOK和C-LOOK调度。这是因为它们在朝一个给定方向移动前会查看是否有请求。

分区表
MBR：支持最大卷为2 TB（Terabytes）并且每个磁盘最多有4个主分区（或3个主分区，1个扩展分区和无限制的逻辑驱动器）
GPT：支持最大卷为18EB（Exabytes）并且每磁盘的分区数没有上限，只受到操作系统限制（由于分区表本身需要占用一定空间，最初规划硬盘分区时，留给分区表的空间决定了最多可以有多少个分区，IA-64版Windows限制最多有128个分区，这也是EFI标准规定的分区表的最小尺寸。另外，GPT分区磁盘有备份分区表来提高分区数据结构的完整性。





- Q:将一个数组生成二叉排序树
  >排序，选数组中间的一个元素作为根节点，左边的元素构造左子树，右边的节点构造有子树。

- Q:查找数组中第k大的数字？
  >因为快排每次将数组划分为两组加一个枢纽元素，每一趟划分你只需要将k与枢纽元素的下标进行比较，如果比枢纽元素下标大就从右边的子数组中找，如果比枢纽元素下标小从左边的子数组中找，如果一样则就是枢纽元素，找到，如果需要从左边或者右边的子数组中再查找的话，只需要递归一边查找即可，无需像快排一样两边都需要递归，所以复杂度必然降低。
  >最差情况如下：假设快排每次都平均划分，但是都不在枢纽元素上找到第k大第一趟快排没找到，时间复杂度为O(n)，第二趟也没找到，时间复杂度为O(n/2)，第k趟找到，时间复杂度为O(n/2k)，所以总的时间复杂度为O(n(1+1/2+....+1/2k))=O(n)，明显比冒泡快，虽然递归深度是一样的，但是每一趟时间复杂度降低。

- Q:红黑树的定义和解释？B树的基本性质？
  >性质1. 节点是红色或黑色。
  >性质2. 根节点是黑色。
  >性质3. 每个叶子结点都带有两个空的黑色结点（被称为黑哨兵），如果一个结点n的只有一个左孩子，那么n的右孩子是一个黑哨兵；如果结点n只有一个右孩子，那么n的左孩子是一个黑哨兵。
  >性质4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)
  >性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。
  >B树：
  >1.所有非叶子结点至多拥有两个儿子（Left和Right）；
  >2.所有结点存储一个关键字；
  >3.非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树；

- Q: 常见的加密算法？
  >对称式加密就是加密和解密使用同一个密钥。
  >非对称式加密就是加密和解密所使用的不是同一个密钥，通常有两个密钥，称为“公钥”和“私钥”，它们两个必需配对使用。
  >DES：对称算法，数据加密标准，速度较快，适用于加密大量数据的场合；
  >MD5的典型应用是对一段Message产生fingerprint(指纹)，以防止被“篡改”。
  >RSA是第一个既能用于数据加密也能用于数字签名的算法。

- Q:简述一致性hash算法
  >首先求memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）。
  >然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
  >然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。

- Q:描述一种hash table的实现方法
  > 除法散列法: p ，令 h(k ) = k mod p ，这里， p 如果选取的是比较大的素数，效果比较好。而且此法非常容易实现，因此是最常用的方法。最直观的一种，上图使用的就是这种散列法，公式： index = value % 16，求模数其实是通过一个除法运算得到的。
  > 平方散列法 :求index频繁的操作，而乘法的运算要比除法来得省时。公式： index = (value * value) >> 28 （右移，除以2^28。记法：左移变大，是乘。右移变小，是除）
  > 数字选择法:如果关键字的位数比较多，超过长整型范围而无法直接运算，可以选择其中数字分布比较均匀的若干位，所组成的新的值作为关键字或者直接作为函数值。
  > 斐波那契（Fibonacci）散列法:平方散列法的缺点是显而易见的，通过找到一个理想的乘数index = (value * 2654435769) >> 28
  >冲突：
  >建立一个基本表和溢出区，凡是和基本元素发生冲突都填入溢出区
  >同时构造不同的哈希函数, 冲突的时候用二层哈希
  >将同样的哈希地址构造成一个同义词的链表


- Q:hash，任何一个技术面试官必问（例如为什么一般hashtable的桶数会取一个素数？如何有效避免hash结果值的碰撞）
  >不选素数的话可能会造成hash出值的范围和原定义的不一致, 散列效果好，没有多余的公因数

- Q:什么是平衡二叉树?
  >左右子树都是平衡二叉树，而且左右子树的深度差值的约对值不大于1。

- Q:数组和链表的优缺点
  >数组，在内存上给出了连续的空间。链表，内存地址上可以是不连续的，每个链表的节点包括原来的内存和下一个节点的信息(单向的一个，双向链表的话，会有两个)。

- Q:topK问题
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1

- Q:
  >1









## 分布式系统

## 数据库与中间件

# 资料预览
[牛客网C++面试题集合](https://www.nowcoder.com/ta/review-c)
[后端开发面试题](https://github.com/chankeh/cpp-backend-reference/blob/master/back-end.md)

汇编部分:


	汇编语言(masm汇编,王爽写的非常不错)


	x86从实模式到保护模式(学习kernel必备,保护模式是一大坑)


	


	c/c++部分:


	C++ Primer(入门必备(但并不是0基础可以看,0基础看C++ Primer Plus)


	Effective C++,More Effective C++(提升c++的编程技巧,面试官很多都从这书里问)


	深度探索c++对象模型(了解c++的底层实现机制,不然面试官问了多态的实现,你不会就挂了)


	


	STL部门:C++标准库(侯捷)(介绍STL六大组件的应用)


	STL源码剖析(STL的源码,不过自己只看了一半而已)


	范型编程与STL(绝版书,不过讲解traits时非常的nice)


	


	操作系统概念部分 Linux鸟哥私房菜(linux相关命令操作,不过自己推荐the linux command   line这电子书更棒)


	《轻松学用linux shell编程》(shell学习相关的)


	现代操作系统(非常经典的操作系统书,不要看国内的操作系统书)


	深入理解计算机系统(CSAPP)(豆瓣高达9.0以上的书,含金量就不多说了,其中的第7章有关elf看懂了,那就不必看那本程序员的自我修养了)


	


	操作系统内核部分:


	操作系统真象还原(教你怎么从0实现一个kernel,看完对操作系统绝对有一个飞一般的认识,另外作者钢哥非常棒


	,我经常骚扰他问内核问题,都会耐心回答)


	Linux内核源代码情景分析(毛德操所写的2.4内核源码,感觉非常有深度,自己囫囵吞枣的看完,细节部门略过了)


	Linux内核设计与实现(一本比较薄的2.6内核剖析书,很容易看懂其内幕)


	深入分析Linux内核源代码(一本绝版书,陈莉君教授所写的2.4内核源代码,配合Linux内核源代码情景分析使用,效果更佳)


	深入理解Linux虚拟内存管理(这本才刚开始看,没看多久)


	Linux环境编程:从应用到内核(一本非常棒的新书,讲解apue的api背后的内核实现,作者我也加了,内核功底非常深厚)


	


	计算机网络:


	(计算机网络:自顶向下,不过学院那本谢仁希的还凑合吧)


	tcp/ip详解卷1(腾讯课堂有明教教主讲解这本书)


	网络编程:


	Unix环境高级编程,Unix网络编程(这两本就不多说了,unix的圣经),


	linux 高性能服务器编程(国内写的一本不错的书)


	


	数据库那块自己很弱只看了mysql必知必会,redis入门实战 ~面试时也没问到数据库相关的,运气爆棚~


	


	算法与数据结构:


	自己的算法能力都很弱,这里只推荐那些算法比较弱的同学:


	数据结构与算法分析(维斯),还有剑指offer题必须刷完,leetcode,编程之美也最好刷一刷,


	,那算法那块就没问题了,当然这里指的是普通的开发岗位,而非算法岗


	


	


	设计模式:


	《设计模式：可复用面向对象软件的基础》,还有博览网上面的c++设计模式视频
# 面试过程
## 公司面经
- 腾讯HR面
知道是深圳岗吧，地点没问题吧 
哪里人，是独生子吗，有女朋友吗 
平时喜欢干什么 
对于公司有什么要求 
说一说未来三到五年的规划 

- 京东HR面试
自我介绍
家庭情况
感情状态
爱好
最受挫的事
实习合作的生活
未来的规划

## 实战经验

### 深圳腾讯(搜索引擎C++后台开发)
- HR提前安排通知以及邮件，三天后面试。
- 迅速准备，在牛客网搜索了面经，过了一边《剑指OFFER》
- 开始背诵常见面试题
- 然后去光大WE谷上车去的龙岗，走完辞职流程。
- 迅速到达腾讯大厦之后在公园手抄部分算法
- 面试过程中，第一轮就是笔试，
- 有少量的题是原题，其余的不太会
- 聚焦在C++内存分配上，常有的关键词，然后是时间复杂度分析
- 排列组合的题目没做出来，心态略崩，没有体现出活力。
- 面试官回答的时候，分布式我没有涉及过，可以谈一谈一致性的。

### 上海雅捷信息技术股份有限公司(C++软件开发)

**岗位职责/工作内容/岗位要求**

>1.负责linux和windows平台上设计软件的后端开发
>2.负责软件中的bug修复
>3.负责编写相关测试案例
>4.负责编写软件说明文档。

任职要求：

1. 大学本科及以上学历，计算机、通信、电子、自动化及相关专业毕业；985，211，一本以上优秀应届生可放宽条件
2. 2年以上C/C++开发经验，具有多线程开发的经验；
3. 同时精通linux/windows 开发环境；
4. 熟悉网络协议（TCP/IP）, 熟悉HTTP协议的开发；
5. 具有独立承担一个模块开发的能力，能够独立解决问题；
6. 较强的系统分析和设计能力，技术钻研能力强；
7. 有过编译器开发经验/熟悉分布式编程模型/熟悉docker应用者优先。

---
- 买好车票和行程，5-4日下午五点到东莞东出发，那就是说3点动身从松山湖北到东莞东
- 准备公司背景和入职要求
- 首先肯定是笔试，考察C++的算法能力。
- 然后就是博客里的步骤重新分析。
- 预订的学习准备步骤
- 操作系统对进程的调度
- CPP编译过程
- 写一个多线程输出字符
- 


## 技术面试感悟
缘起
去年确定要回国之后，基本已经停止了投简历和刷题。这两天完成了（可能是）最后一次 onsite 面试，连续飞来飞去，身心俱疲，但是能免费出去玩，见见朋友聊聊天，还是值得去感受下的。
从去年九月开始，到现在也算是找了小半年工作了，除了一开始什么都不懂有些迷茫之外，整个过程基本处于可控的状态，从前期的找节奏热身，到后面针对性去考察不同公司，可以说还都是比较顺利的。因为我的动机和大部分人不一样，所以这里谈及的所有，很可能对另一个人没有任何可操作性，当然，如果你对一个『奇葩』的思路和做法感兴趣，请继续。
借用知乎体，问为什么之前先要问是什么，于是问题来了：什么是面试？什么是找工作？
狭义来说，找工作面试类似于从学生到社会人身份转换的认证考试，考试成绩可能和工资公司职位有关。但一切认证考试背后的目的是对应的能力，比方说考驾照，背后对应的是驾驶车辆，判断路况以及做出最佳选择的能力。那么在找工作面试这件事儿上，所需的能力是什么呢？
简单来说八个字：观察、思考、沟通、行动。
观察不只是看题，更是审时度势说什么不说什么；思考不只是算法，更是逻辑和知识框架的建立；沟通不只是套近乎，更是因势利导去了解对方的思维模式；行动不只是刷题，更是通过试错和改进让自己更快完成身份转换。
当然，刷题也没什么错，但是不要用战术上的勤奋掩饰战略上的懒惰，道理都懂，我不多说。不过如果连我前面在说什么都看不懂的话，还是老老实实刷题吧。
我还记得小时候刚开始学英语的时候，面对一个一个不知所云的单词时的无助（当然 GRE 考试我也有这个感觉）。但是这些跟找工作相比（其实具体指对应的能力），就太九牛一毛了。那些可以量化的指标往往都是清晰的，难易暂且不说，但是至少我们有终点，也有起点。
可是对于那些直觉类的能力，由于悟道时间的不确定，我们唯一能做的就是不断坚持修炼直到开化的那天。
从这个角度来说，面试就是一个学习的过程，一个公司专门找五六个人陪你聊天帮你成长，不但不收钱还报销一切费用，难道还有更好的事情嘛？就用这么好的机会来刷刷题，难道不觉得很浪费嘛？
对于半只脚踏入社会的毕业生来说，重要的是尽一切可能去汲取那些在学校里无法获取的知识和经验，当然，结果也重要，不过如果你能在这个过程中学到足够多的东西，结果反而是水到渠成的事情，不必过多担心。
武器
就我的感觉来看，简历在没被刷掉之后，作用就基本等于零了。除非参与过一些举世闻名的项目，或者刚好和面试官的领域吻合，不然说真的没人在意。假如硬要说面试官会在面试的时候看，这都面对面了，直接跟他介绍自己不就得了嘛。
当然这不是说简历不重要，简历重要性在于做简历。要知道每往上面加哪怕一条记录，都需要大量的努力，这些背后的一点一滴，才是简历的价值，然后价值决定价格，价格会浮动，不要因为一点浮动就恐慌性抛售，沉住气，闷声发大财。
整个找工作过程中，一定要慢慢形成适合自己的合理的思维模式。在学校里，只要足够努力，很多时候都能取得比较好的成绩，但是在步入社会的过程中，或多或少会有迷茫无助的时刻，感觉自己已经刷了很多题目，很认真准备了简历，为什么还是屡战屡败。
但反过来看，这其实是一个很好的强迫自己去审视自己的机会，看看自己那一步出了问题，然后对应去调整，再根据新的反馈来继续调整，这其实就是面对没有标准解答的问题的时候的最佳实践。就好像机器学习里，有正样本，也有负样本，只有综合考虑运用，才能得到最佳的学校效果。
一旦有了这种思维，那么飞花落叶皆可伤人，比方说刷题，其实意义很大吗？不大，但是如果接着找工作的压力，检查去做，并从中验证和改进自己的学习和理解能力，那意义就大了。所谓努力，不应该只是战术上的，更应该是战略上的，而时不时停下来，审视自己之前的工作和方向，并根据观察和反馈设定下一阶段的目标，则是很重要的战略努力。
就像大侠最重要的不是武器，而是『勇气、侠义、爱与宽容』一样（古龙先生语），学习最重要的不是知识点，而是『学会学习与学会解决问题』。仔细想想，如果感觉自己因为所谓的『目标』而跑偏的话，那么现在回头，还是来得及的。
招式
不同公司的文化不同，风格不同，技术倾向不同，人员组成不同，千奇百怪组合起来，就像武林中的各个门派一样。江湖中有通用的功夫吗？并没有！所以见招拆招就很重要了。当然，有些门派就是天生不适合，那也不必强求，要知道，那些想一统武林的人，通常都没有什么好下场。
不过门派虽多，还是有规律可寻。招式的变化终究是有穷尽的，兵器的变化其实也不多，本来想多实地考察几个公司学百晓生写个兵器谱，但是东岸西岸飞一次要老命，前两天的红眼航班让我彻底放弃了这个念头，于是这个部分就随心写一下。
总体来说，无论大公司小公司，算法题基本就是主要沟通方式了，毕竟其他也没有什么好说的，毕竟面得多，可能一开始比较有激情，后面对着面试者，面试官更多就是打个卡了。
大公司制度严明，一开始就会告诉你所有的安排，接下来就是按部就班完成；小公司比较随意，谁有空谁来面，每次面多久也基本没有稳定值，最近去湾区一家小公司一口气面了 7 轮，真是『想要逃』，想大喊一声『老子就这么屌我们不要废话了爱要要不要拉倒』，恩我也就是想想而已。
打戏，要拍得好看，一定要有来有往，面试也一样，不能因为是求职的一方，就先自降一等，不卑不亢，该说什么说什么，为了一份工作，真不值得放弃更重要的东西。
偷懒地说，面试官有两种，大部分都是第一种，只有很少是第二种。第一种就是心中有题目也有答案，你没说出他想要的答案，那就是不行。第二种是心中有题目，但没有答案，会和你一起『努力』去解决一个问题。
第一种算是比较没有诚意的（当然还可以更没有诚意，这里就不提了），在网上找个题目看看答案然后心里只有标准答案，这样真的有很大意义吗？我觉得稍微学过一点计算机的，都可以做到，当然，毕竟有一定的工作经验，但是就这样似乎『事不关己』等待面试者给出正确答案，可能给出的评价也没有多少参考价值吧。遇到第二种面试官，整个面试过程变成了一个完美的大型互动教学活动，只能说好好珍惜，能学到很多有用的东西。
什么才是好的面试题目呢？当然是根据自己平时工作的场景，抽象成比较简单的设计+编码题，不需要太难，但是可以综合考察到面试者思考问题的角度以及对计算机学科的理解，最后的编码可以了解算法能力。最好可以带一点新概念，这样还能考察面试者的快速学习和理解能力。当然还有很多值得考察的角度，不过都比较花心思，估计大部分打卡型面试官，是不会这样的，所以大家还是可以放心刷题。
秘笈
写到这我有点累了。但是还是要厕所里挂钟——有始有终。
如何看人还是要向老祖宗取经，这里推荐一本书《冰鉴》，不要看译注版本（里面举得例子很多比较牵强）。
试探的话有以下方法，这里就不展开了：
故意写错比较关键但是不大容易发现的小失误，看面试官能否及时指出
故意写错比较关键的地方，但是精心设计几个看似合理但其实是『陷阱测试用例』，看看面试官能不能自己绕出逻辑陷阱（递归中这个方法很好用）
摸清楚面试官擅长的领域，然后开始扯他不熟悉的领域，看他的表现（比如说扯一点汇编，扯一点硬件）
写完一个解法之后问问面试官有没有什么优化的方法，如果他说有，问他怎么有，如果他说没有，你就给出一个优化的方法
其他很多…自行发挥创意
当然这些慎用，装逼有风险，起手需谨慎。
金盆
总结一下就是，还是要把时间用在更有意义的地方。

## 工作软实力
开始之前，一定要先摆正心态，之所以把这一点特别拿出来说明，因为我深知我们的文化中包含着的对『野路子草根逆袭』的『倾向』（比如说，对太平天国的『评价』）。但是至少在找工作这件事情上，有没有受过培训，有没有去刻意练习，身经百战的面试官肯定是能一眼看出来的。这里说的培训，主要指的是，在从学校过渡到社会的过程中，有没有针对性去进行职业态度的培训。从衣着仪态，到礼节谈吐，最后到对自己的认知，都是题中之义。当然，不可否认有些人天赋异禀，不需要太多训练就可以自然切换到『职业』模式，但是对于更多的人来说，参加不同的研讨班，有针对性地打磨自己的各项『软实力』，从依赖直觉（可能是天赋，也可能是幻想出来的）逐渐变成依赖技能，才是稳扎稳打的选择。
美国的学生从高中起就会开始做性格评估以寻找自己可能适合的工作，并且在找工作找实习的时候会花大量的时间上培训班，进行刻意练习。我们作为『外国人』，本身在语言和文化适应性上就差了一截，更应该花时间去认真打造自己的软实力，善于利用各种专业资源（研讨班，职业发展中心等等）来快速提高自己。闭门造车后『一鸣惊人』需要的天资和努力远超大部分人想象，还是不断在实践中提高自己比较靠谱（或者直接可以说，软实力闭门造车没用，因为最终还是需要根据实际来调整）。
另外，其实不存在某个『准备好了』的时间点，做任何事情（不只是找工作），我们都应该好好评估自己之前的经验，试着让下一次比上一次更好，用发展的眼光看问题，也许才是找到最终答案的『捷径』。
举个例子，CMU 定期有各种各样的培训班，细致到找工作的每一个环节，比如：
推荐信是什么，应该怎么写
面试应该穿什么
面试过程中的仪态应该怎么样
作为打开话题的 Small Talk 应该怎么说
怎么样自我介绍
在边吃饭边面试的场景中，应该如何表现
如何利用所谓的『关系』
如何回答某些『常规』问题
这些东西如果要自己模式，恐怕要花费大量的时间和精力，为什么不利用好学校的资源，去『武装』一下自己呢？（很多同学眼里只有刷题却不去准备自己的软实力，就属于看起来感动自己的勤奋却没多少功效的战术勤奋战略偷懒）
虽然很多东西无法『训练』出来，毕竟江山易改本性难移，但是我们至少可以变得更有『职业素养』一些。
问问自己
What expectations/concerns do you have about job interviewing in the US?
Think about the kind of job you might look for. Be specific: job title, company, location, type, etc
Highlight your skills in relation to the job listed above
What are your strengths in relation to this job
What are your weaknesses
What are your short-term career goals
What are your long-term career goals
这些问题其实一点都不好回答，无论是『找到自己』还是『认识自己』都是非常艰难的，但是不去找，就肯定找不到。
不过还是可以给出一点我自己的经验，多去试试，不知道自己想要什么，那么就不如排除法，看看自己不喜欢什么（这个一般比较容易感觉出来），慢慢就能找到方向了。
软实力要点
Highlight your skills and experience (not the time to be modest - you have to “sell yourself”)
Demonstrate cultrually appropriate trait, e.g. assertiveness, awareness of strengths and goals
Use “small talk” to show your social and cultural expertise
Communicate with non-verbal aspects of the interview: dress, handshakes, eye-contact, posture
Make use of the “networking” connections that are acceptable in the United States
Respond to the kinds of questions asked in US interviews
下面是具体的要点叙述，篇幅所限不展开了（硬广：如果需要具体情况具体分析，欢迎来请我吃饭）
Self Promotion
Assertiveness
Confidence in openly discussing goals and accomplishments
Follow-up(thank you notes, phone inquiries)
Appropriate dress
不止要说自己的优点，还要用具体的事例证明，学会讲故事（不会讲故事的创业公司都死了）
如果可能，thank you note，一是表示态度，二是补充信息，充分展示自己
Directness in Communication
Open and direct responses to questions
Eye contact, relaxed posture and appropirate non-verbal behavior
有啥说啥，明确说出来，比方说口音，或者语速，直接自己听不清楚，请求说清晰一点或慢一点
Self-Disclosure
Personal descriptions of experiences, hobbies, strengths and weaknesses
Related answer to personality (e.g., leadership style, problem solving abilities)
可以说兴趣爱好，但是要说明这些兴趣爱好给你带来了什么，对具体的工作有什么帮助。
想想产品发布会时候的用词和感觉。
是否了解自己，通过缺点和优点两个不同的视角来观察。
Career goals
Demonstrating knowledge of self, career goals, and how they relate to this job
Discussion of long-range career plans
什么都想做，就什么都做不好。
真的需要好好想这个问题
Informality of Interview Process
Congenial interviewing environment that encorages openness, some joking and exchange of information
具体的语境切换，俗称『阅读空气』
Individual Equality
Race, sex, age should not affect relationship
我的建议是，最好彼此都抽离成一个无性别无年龄无人种的『综合个体』来进行交流
Preparation about Organization
Obtain as much information as possible about job and organization
Demonstrate awareness in letters and in interview
看起来要专业，形式影响心态，不要太随便，心态上认真。比如说即使是电话面试，事先准备好仪容仪表也是一个很好的热身。
常见问题及解答
下面是面试中经常会出现的问题，准备好对应的故事来『证明』自己，尤其是后面几条 yes/no 的问题，千万不能说个答案（虽然通常肯定要答 yes）然后开始『谜之沉默』，要抓住机会展示自己。
留意下面问题中面试官可能想要听到的你的特质：
Tell me about yourself
What are your major strengths
What are your major weakness
What are your short-range objectives
What are your career objectives
What was the last book you read?
If you could start again, what would you do differently? (Note: you cannot say “nothing”)
What interests you most about the position we have? What interests you least?
Why weren’t your grades better? or why haven’t you obtained a job so far? (Note: do not be defensive; this may be a test of your ability to handle pressure or to analyze your own situation)
What if you were in charge of this (company, research group, department)? Why should we hire you?
注意拓展这些 yes/no 问题：
Can you work under pressure
Are you a leader
Are you creative
Can you work as a member of a team
所有的问题，可以记住关键词，但是整个叙述过程一定要自然，不要背课文。这里举一个例子，比如说面试官问 “Can you work under pressure?”，可以这么回答：
我可以承受压力，你知道在 CMU 期末考试压力非常大（可以具体渲染下如何压力大），但是我还是分配好了时间并得到高分，我觉得这是一个能抗压的表现。
其他的都可以按照这个思路回答。
Small Talk
就是日常开启话题的闲聊，展示基本的社交能力，要注意像乒乓球，有来有回，不要出现『这话我没法接』的情况，具体怎么聊天，又是另一个话题，有空我再说。
随口吹水的话题
天气、居住城市、墙上的作品或者照片、共同兴趣、体育、旅行
绝对不要提的话题
年龄、宗教、政治、钱、婚姻状况
最后说两句
其实上面任何一个小点都可以展开成一个很大的话题，这里简单举几个例子：
仪容仪表
男生，领带最好不要是红色(aggressive)，蓝色是比较安全的选择（体现团队合作）
女生，千万不要喷香水
穿正装不要穿白袜子
具体可以看看最近美国大选不同竞选人是怎么穿着，以及如何搭配他们对应的竞选风格的
一本书《Dress for Success》
握手要坚定用点力，不过目的不是捏爆别人的手
上面提到的要求很多是有文化冲突的，也就是在美国大家习惯这样，可能在中国是另一套；我们需要意识到这种差别，但是千万不要矫枉过正，尽可能还是要按照自己舒服的方式来表现
守时！有些同学迟到半个小时，老师直接跟他们说 “too late to join”，我觉得这种惩罚方式很好，既然约定好了，就不要浪费大家的时间，或者把自己的话当放屁
最后祝愿大家都能找到心仪的工作，贴一段我之前周记里写的话作为结束：
找工作与其说是找一份工作，不如说是找到自己适合什么工作，化简一下就是找到自己。在不断的测试中了解自己擅长什么，喜欢什么，想要什么，这个很关键。具体到刷题之类的东西，其实是个人努力，有一个基准线在那里，过了就好。我想做什么工作，你能提供什么职位，这两个有多匹配，能不能接受，能接受咱们继续，不行就好聚好散。选择工作就是选择环境，不要被各种乱七八糟的光环亮瞎了双眼，还是那句话，要有自己的判断和选择，不能『随大流』。


## 版本控制

| Version | Action                   | Time       |
| ------- | ------------------------ | ---------- |
| 1.0     | Init                     | 2019-04-29T06:19:10-07:00|
