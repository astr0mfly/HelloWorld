---
date: "2019-05-02T05:16:29-07:00"
draft: true
title: "Computer-Csapp"
tags: []
series: []
categories: []
toc: true
---
# 计算机系统导论
## 进程与线程 

进程（抽象1）和线程（抽象2）都是抽象。以五种抽象作为展开的脉络

- 单处理器调度（长期、中期、短期）
- 多处理器调度（粒度、设计问题、进程调度、县城调度）
- 并行处理（进程创建、竞争条件、信号量）
- 进程控制（执行模式、进程创建、进程切换）
- 进程和线程（多线程、线程特性）
- 并发原理（竞争条件、进程交互、互斥要求）
- 互斥（硬件支持、中断禁用、专用机器指令）
- 信号量（互斥、生产者/消费者问题、信号量的实现）
- 消息传递（同步、寻址、消息格式、排队原则、互斥）
- 读者-写者问题
- 死锁原理（可重用资源、可消耗资源、死锁条件）
- 死锁预防（互斥、占有且等待、不可抢占、循环等待）
- 哲学家就餐（信号量解决）
- UNIX 的并发机制（管道、消息、共享内存、信号量信号）
- Linux 内核并发机制（原子操作、自旋锁、信号量、屏障）
- Windows 并发机制（等待函数、分派器对象、临界区、轻量级读写锁和条件变量）

操作系统是控制程序在处理器上执行和管理该处理器资源的软件。操作系统具有许多功能，包括进程调度和存储管理，但这些功能的实现离不开处理器硬件的支持。事实上，所有处理器都或多或少具备这种能力，如虚拟存储器管理硬件和进程管理硬件。这些硬件包括专用寄存器、缓冲器以及完成基础资源管理任务的电路。

操作系统最重要的功能之一是**进程或任务的调度**，操作系统决定在给定时间内运行哪个进程。一般情况下，硬件不断中断运行进程，使操作系统做出新的调度裁决，从而使处理器时间被几个进程公平分配。

操作系统的另一个重要功能是**存储管理**。大多数当代操作系统都包含虚拟存储器的功能，虚拟存储器有两个优点：

- 1）进程在主存中运行时不需要将程序的全部指令和数据一次性地装入主存；
- 2）程序可用的总存储空间可以大大超过系统的实际主存容量。虽然存储管理是用软件完成的，但操作系统依赖于处理器中的硬件支持，包括分页管理硬件和分段管理硬件。


我们可以把操作系统看成是用于说明指令系统层没有的体系结构特性的解释器。其主要部分有虚拟内存、虚拟输入/输出指令和用于并行处理的一些工具。

虚拟内存是一种体系结构特性，它的目的是为了允许程序使用比计算机的物理内存更多的地址空间，或者是提供一个一致的和灵活的内存保护及共享机制。虚拟内存的实现方式有页式、段式和段页式。在页式虚拟内存中，地址空间被分成大小相等的虚拟页。其中的某些页被映射到物理页帧，其他的页则不映射。对映射页的访问将由 MMU 转换到正确的物理地址。引用一个没有映射的页将产生一个缺页。

在操作系统曾，最重要的输入 / 输出抽象是文件。文件由一系列的字节活着逻辑记录组成，读写文件时并不需要知道磁盘、磁带和其他输入/输出设备是如何工作的。文件可以顺序访问，也可以通过记录号或者主键进行随机访问。目录可以用来把文件分成组。文件可以保存在连续的扇区中或者零散地分布在磁盘上。在后一种情况下（这种情况在硬盘上经常发生），需要使用数据结构来定位文件的块。系统可以通过使用链表活着位图来掌握空闲的磁盘存储区的情况。

并行处理通常采用多个进程分时使用一个 CPU 的方式来模拟和实现。如果不对进程间通信加以控制，将会导致竞争条件。为了解决这一问题，引入了同步原语，信号量就是同步原语的一个简单的例子。使用信号量，可以很容易并且很完美地解决生产者-消费者问题。

UNIX 和 XP 是复杂操作系统的两个例子。它们都支持分页和内存映射文件。它们也都支持层次型的文件系统，其中文件都是由字节序列组成的。最后一点，UNIX 和 XP 都支持进程和线程以及用于进程和线程的同步机制

### 进程
是一个系统抽象，给应用程序一个假象，好像它是系统中唯一的 job

机制：创造，销毁，挂起，上下文切换，发送信号，IPC 等等

如何在多个进程间共享系统资源？

进程管理：
- 进程创建/销毁
  - 在遇到错误的时候，Linux 系统级函数通常会返回 -1 并且设置 errno 这个全局变量- 来表示错误的原因。使用的时候记住两个规则：
  - 对于每个系统调用都应该检查返回值
    当然有一些系统调用的返回值为 void，在这里就不适用
  - 进程会被终止：接收到一个终止信号/返回到 main/调用了 exit 函数(exit 函数会被调用一次，但从不返回)
  - 调用 fork 来创造新进程。但是会返回两次，对于子进程，返回 0， 对于父进程，返回子进程的 PID。（write on copy, 共享映射，如果修改值才分离成两个空间）
- 进程状态
  - pid_t getpid(void) - 返回当前进程的 PID
  - pid_t getppid(void) - 返回当前进程的父进程的 PID
  - 运行 Running、停止 Stopped、终止 Terminated、新建(new)和就绪(ready)
- PCB
- 竞争条件
- 进程同步
- 子进程
  - 即使主进程已经终止，子进程也还在消耗系统资源，我们称之为『僵尸』。为了『打僵尸』，就可以采用『收割』(Reaping) 的方法。父进程利用 wait 或 waitpid 回收已终止的子进程，然后给系统提供相关信息，kernel 就会把 zombie child process 给删除。
  - 如果父进程不回收子进程的话，通常来说会被 init 进程(pid == 1)回收，所以一般不必显式回收。但是在长期运行的进程中，就需要显式回收（例如 shell 和 server）。
  - 如果想在子进程载入其他的程序，就需要使用 execve 函数，具体可以查看对应的 man page，这里不再深入。
- 非本地跳转
  - 所谓的本地跳转，指的是在一个程序中通过 goto 语句进行流程跳转，尽管不推荐使用goto语句，但在嵌入式系统中为了提高程序的效率，goto语句还是可以使用的
  - setjmp 保存当前程序的堆栈上下文环境(stack context)，注意，这个保存的堆栈上下文环境仅在调用 setjmp 的函数内有效，如果调用 setjmp 的函数返回了，这个保存的堆栈上下文环境就失效了。调用 setjmp 的直接返回值为 0。
  - longjmp 将会恢复由 setjmp 保存的程序堆栈上下文，即程序从调用 setjmp 处重新开始执行，不过此时的 setjmp 的返回值将是由 longjmp 指定的值。注意longjmp 不能指定0为返回值，即使指定了 0，longjmp 也会使 setjmp 返回 1。
- 进程组
  - 每个进程都只属于一个进程组{getpgrp() - 返回当前进程的进程组 setpgid() - 设置一个进程的进程组}
- 进程调度

### 线程
线程是一个处理器抽象，假装每个执行的上下文都有一个处理器。
Process is the unit of resource ownership, while Thread is the unit of instruction execution
如何在不同进程的线程中共享 cpu？
如何在相同进程的线程的共享 cpu？

用户线程 VS 内核线程

### 协程

正如面向对象的语言是围绕面向对象的开发理念设计一样，命令式编程语言是围绕自顶向下(top-down)的开发理念设计的。其后的结构化编程(Structural Programming) 思想，更是进一步强化了“子过程调用作为唯一控制结构”的基本假设。在这样的指导思想下，协程一直没有成为当时编程语言的一等公民。

许多协同式多任务操作系统，也可以看成协程运行系统。说到协同式多任务系统，一个常见的误区是认为协同式调度比抢占式调度“低级”，因为我们所熟悉的桌面操作系统，都是从协同式调度（如 Windows 3.2， Mac OS 9 等）过渡到抢占式多任务系统的。实际上，调度方式并无高下，完全取决于应用场景。抢占式系统允许操作系统剥夺进程执行权限，抢占控制流，因而天然适合服务器和图形操作系统，因为调度器可以优先保证对用户交互和网络事件的快速响应。当年 Windows 95 刚刚推出的时候，抢占式多任务就被作为一大买点大加宣传。协同式调度则等到进程时间片用完或系统调用时转移执行权限，因此适合实时或分时等等对运行时间有保障的系统。

抢占式系统依赖于 CPU 的硬件支持。 因为调度器需要“剥夺”进程的执行权，就意味着调度器需要运行在比普通进程高的权限上，否则任何“流氓（rogue）”进程都可以去剥夺其他进程了。只有 CPU 支持了执行权限后，抢占式调度才成为可能。

在这些系统中，程序均以协程的方式运行。调度器负责控制流的让出和恢复。通过协程的模型，无需硬件支持，我们就可以在一个“简陋”的处理器上实现一个多任务的系统。我们见到的许多智能设备，如运动手环，基于硬件限制，都是采用协同调度的架构。

协程的思想本质上就是控制流的主动让出和恢复机制。在现代语言里，可以实现协程思想的方法很多，这些实现间并无高下之分，所区别的就是是否适合应用场景。理解这一点，我们对于各种协程的分类，如半对称/对称协程，有栈与无栈协程等具体实现就能提纲挈领，无需在实现细节上纠结。

总的来说，协程为协同任务提供了一种运行时抽象。这种抽象非常适合于协同多任务调度和数据流处理。在现代操作系统和编程语言中，因为用户态线程切换代价比内核态线程小，协程成为了一种轻量级的多任务模型。我们无法预测未来，但是可以看到，协程已经成为许多擅长数据处理的语言的一级对象。随着计算机并行性能的提升，用户态任务调度已经成为一种标准的多任务模型。在这样的大趋势下，协程这个简单且有效的模型就显得更加引人注目。

### 异常
从开机到关机，处理器做的工作其实很简单，就是不断读取并执行指令，每次执行一条，整个指令执行的序列，称为处理器的控制流。到目前为止，我们已经学过了两种改变控制流的方式：

- 跳转和分支
- 调用和返回
这两个操作对应于程序的改变。但是这实际上仅仅局限于程序本身的控制，没有办法去应对更加复杂的情况。系统状态发生变化的时候，无论是跳转/分支还是调用/返回都是无能为力的，比如：

- 数据从磁盘或者网络适配器到达
- 指令除以了零
- 用户按下 ctrl+c
- 系统的计时器到时间
这时候就要轮到另一种更加复杂的机制登场了，称之为异常控制流(exceptional control flow)。首先需要注意的是，虽然名称里包含异常（实际上也用到了异常），但是跟代码中 try catch 所涉及的异常是不一样的。

异常控制流存在于系统的每个层级，最底层的机制称为异常(Exception)，用以改变控制流以响应系统事件，通常是由硬件的操作系统共同实现的。更高层次的异常控制流包括进程切换(Process Context Switch)、信号(Signal)和非本地跳转(Nonlocal Jumps)，也可以看做是一个从硬件过渡到操作系统，再从操作系统过渡到语言库的过程。进程切换是由硬件计时器和操作系统共同实现的，而信号则只是操作系统层面的概念了，到了非本地跳转就已经是在 C 运行时库中实现的了。

硬件与操作系统必须协同工作才能按照我们期望的方式处理异常。硬件一般暂停指令流中导致异常的指令，同时执行完该指令前的所有指令，清除该指令后的所有指令，并且设置一个寄存器描述异常发生的原因，保存导致异常发生的指令的地址，然后跳转到预先确定的地址开始执行。操作系统则查看异常发生的原因并才去相应的操作。对于一个未定义指令异常、硬件错误异常或算数溢出异常，操作系统通常终止执行的程序并返回原因描述。对于 I/O 设备请求活操作系统服务调用，操作系统保存程序的当前状态，执行期望的任务，然后重新载入程序继续运行。在 I/O 设备请求的情况下，我们可能需要在继续执行发出 I/O 设备请求的任务前先运行另一个任务，因为该任务一般在 I/O 完成之后才能继续执行。这就是保存和恢复任务状态如此重要的原因。一个最重要且频繁出现的异常是页缺失与 TLB 异常。

在操作系统开始进行异常处理和保存处理器所有状态位的时候，操作系统特别脆弱。例如，如果在操作系统中正在处理第一个异常时，另一个异常又发生了，控制单元将重写异常程序计数器，就不能返回引起缺页的那条指令。我们可以通过提供禁止异常 disable exception 和使能异常 exception enable 来避免这种错误的发生。当异常第一次发生时，处理器设置一个位，禁止其他异常的发生；这可以与处理器设置管理态位同时进行。随后操作系统保存足够的状态，如果有另一个异常发生——异常程序计数器 EPC 和异常引发寄存器也能正确恢复。异常程序计数器和异常引发寄存器是协助处理异常、TLB 缺失以及缺页的两个特殊控制寄存器。而后操作系统可以重新允许异常发生。这些步骤保证了异常不会使处理器丢失任何状态，因此也就不会出现无法重新执行中断指令的情况。

#### Exception
这里的异常指的是把控制交给系统内核来响应某些事件（例如处理器状态的变化），其中内核是操作系统常驻内存的一部分，而这类事件包括除以零、数学运算溢出、页错误、I/O 请求完成或用户按下了 ctrl+c 等等系统级别的事件。

系统会通过异常表(Exception Table)来确定跳转的位置，每种事件都有对应的唯一的异常编号，发生对应异常时就会调用对应的异常处理代码

#### 中断
异步异常(Asynchronous Exception)称之为中断(Interrupt)，是由处理器外面发生的事情引起的。对于执行程序来说，这种“中断”的发生完全是异步的，因为不知道什么时候会发生。CPU对其的响应也完全是被动的，但是可以屏蔽掉[1]。这种情况下：

- 需要设置处理器的中断指针(interrupt pin)
- 处理完成后会返回之前控制流中的『下一条』指令
比较常见的中断有两种：计时器中断和 I/O 中断。计时器中断是由计时器芯片每隔几毫秒触发的，内核用计时器终端来从用户程序手上拿回控制权。I/O 中断类型比较多样，比方说键盘输入了 ctrl-c，网络中一个包接收完毕，都会触发这样的中断。

#### 同步异常
同步异常(Synchronous Exception)是因为执行某条指令所导致的事件，分为陷阱(Trap)、故障(Fault)和终止(Abort)三种情况。

|类型|原因|行为|示例|
|--|--|--|--|
|陷阱|有意的异常|返回到下一条指令|系统调用，断点|
|故障|潜在可恢复的错误|返回到当前指令|页故障(page faults)|
|终止|不可恢复的错误|终止当前程序|非法指令|

#### 系统调用示例
系统调用看起来像是函数调用，但其实是走异常控制流的，在 x86-64 系统中，每个系统调用都有一个唯一的 ID
|编号|名称|描述|
|--|--|--|
|0|read|读取文件|
|1|write|写入文件|
|2|open|打开文件|
|3|close|关闭文件|
|4|stat|获取文件信息|
|57|fork|创建进程|
|59|execve|执行一个程序|
|60|_exit|关闭进程|
|62|kill|向进程发送信号|

举个例子，假设用户调用了 open(filename, options)，系统实际上会执行 __open 函数，也就是进行系统调用 syscall 进入内核态，然后操作文件，如果返回值是负数，则是出错，
```
00000000000e5d70 <__open>:
    ...
    e5d79: b8 02 00 00 00     mov $0x2, %eax    # open 是编号 2 的系统调用
    e5d7e: 0f 05              syscall           # 调用的返回值会在 %rax 中
    e5d80: 48 3d 01 f0 ff ff  cmp $0xfffffffffffff001, %rax
    ...
    e5dfa: c3                 retq
```

#### 故障示例
这里我们以 Page Fault 为例，来说明 Fault 的机制。Page Fault 发生的条件是：
- 用户写入内存位置
- 但该位置目前还不在内存中

‵‵`cpp
int a[1000];
main()
{
    a[500] = 13;
}
```
那么系统会通过 Page Fault 把对应的部分载入到内存中，然后重新执行赋值语句：
执行用户代码后，movl进入异常page fault，走异常通道进入内核态代码，复制page后返回，重新执行movl

```cpp
int a[1000];
main()
{
    a[5000] = 13;
}
```
内核态代码转移page时发现非法地址，发送信号通知进程结束。

具体来说会像用户进程发送 SIGSEGV 信号，用户进程会以 segmentation fault 的标记退出。

### 信号
Linux 的进程树，可以通过 `pstree` 命令查看

信号是 Unix、类 Unix 以及其他 POSIX 兼容的操作系统中进程间通讯的一种有限制的方式。它是一种异步的通知机制，用来提醒进程一个事件已经发生。当一个信号发送给一个进程，操作系统中断了进程正常的控制流程，此时，任何非原子操作都将被中断。如果进程定义了信号的处理函数，那么它将被执行，否则就执行默认的处理函数。

这样看来，信号其实是类似于异常和中断的，是由内核（在其他进程的请求下）向当前进程发出的。信号的类型由 1-30 的整数定义，信号所能携带的信息极少，一是对应的编号，二就是信号到达这个事实。

内核通过给目标进程发送信号，来更新目标进程的状态，具体的场景为：
- 内核检测到了如除以零(SIGFPE)或子进程终止(SIGCHLD)的系统事件
- 另一个进程调用了 kill 指令来请求内核发送信号给指定的进程
目标进程接收到信号后，内核会强制要求进程对于信号做出响应，可以有几种不同的操作：
- 忽略这个型号
- 终止进程
- 捕获信号，执行信号处理器(signal handler)，类似于异步中断中的异常处理器(exception handler)

如果信号已被发送但是未被接收，那么处于等待状态(pending)，同类型的信号至多只会有一个待处理信号(pending signal)，一定要注意这个特性，因为内部实现机制不可能提供较复杂的数据结构，所以信号的接收并不是一个队列。比如说进程有一个 SIGCHLD 信号处于等待状态，那么之后进来的 SIGCHLD 信号都会被直接扔掉。
当然，进程也可以阻塞特定信号的接收，但信号的发送并不受控制，所以被阻塞的信号仍然可以被发送，不过直到进程取消阻塞该信号之后才会被接收。内核用等待(pending)位向量和阻塞(blocked)位向量来维护每个进程的信号相关状态。

信号处理器的设计并不简单，因为它们和主程序并行且共享相同的全局数据结构，尤其要注意因为并行访问可能导致的数据损坏的问题，这里提供一些基本的指南（后面的课程会详细介绍）
规则 1：信号处理器越简单越好
例如：设置一个全局的标记，并返回
规则 2：信号处理器中只调用异步且信号安全(async-signal-safe)的函数
诸如 printf, sprintf, malloc 和 exit 都是不安全的！
规则 3：在进入和退出的时候保存和恢复 errno
这样信号处理器就不会覆盖原有的 errno 值
规则 4：临时阻塞所有的信号以保证对于共享数据结构的访问
防止可能出现的数据损坏 
规则 5：用 volatile 关键字声明全局变量
这样编译器就不会把它们保存在寄存器中，保证一致性
规则 6：用 volatile sig_atomic_t 来声明全局标识符(flag)
这样可以防止出现访问异常
这里提到的异步信号安全(async-signal-safety)指的是如下两类函数：
所有的变量都保存在栈帧中的函数
不会被信号中断的函数

### 消息传递

所有的上下文切换都是通过调用某个异常处理器(exception handler)完成的，内核会计算对易于某个进程 p 的 pnb 值：pnb = pending & ~blocked

signal 函数可以修改默认的动作，函数原型为 handler_t *signal(int signum, handler_t *handler)

我们知道，内核会阻塞与当前在处理的信号同类型的其他正待等待的信号，也就是说，一个 SIGINT 信号处理器是不能被另一个 SIGINT 信号中断的。


## 深入理解并行

并行计算包括了很多，这一节主要介绍并行的基本原理和重要规则。后面分三节介绍三个重要分支：通用计算、分布式计算 和 云计算。

- cache 一致性和 MESI 协议（软件解决、硬件解决、MESI 协议）
- Roofline 性能模型
并行存储，并发控制，并行计算

---

计算机虽然只有一个 CPU，但操作系统能够将程序的执行单位细化，然后分开执行，从而实现伪并行执行。这种伪并行执行称为并发(concurrent)。使用多个 CPU 真的同时执行称为并行(parallel)
锁模型：如果竞争足够少，多数情况下能保持较高性能。但是，对于资源的竞争，不能忘记加锁。要做到完美无缺较难。
队列模型：在竞争少的时候，其性能比不上锁模型，但对于程序员来说，它比锁模型更容易贯彻。虽然各种处理系统的表现不尽相同，但这种方法很少会因为线程增多而带来性能低下的恶果。
Actor 是（仅）通过消息(message)进行通信的实体，向 Actor 发送消息，仅仅是发送消息而不等返回结构，是一种异步方式。Actor 由于没有消息以外的信息传递手段，所以不用担心 Actor 之间的资源竞争。发送给 Actor 的消息，都配送到各个 Actor 所拥有的邮箱里。多个消息同时到达时的竞争，已经由内嵌系统中的排除机制来处理了。
Actor 有一个很大的优点是安全，但更大的优点是易懂。Actor 根据消息进行进行处理，必要的话，会向其他 Actor 传递消息，或者向源 Actor 返回消息。
多个控制流同时运行的线程，非常简单和容易实现，如果协调和同步方面不需要花费很大成本的话，就能够得到很高的性能。

---

提高系统性能的传统方式是使用多个处理器，它们能并行执行，以支持给定的工作负载。两种最普遍的多处理器组织方式是对称多处理器（symmetric multiprocessor, SMP）和集群（cluster）。
SMP 由多个相同或相类似的处理器组成，以总线或某种开关阵列互连成一台计算机。SMP 所需解决的最重要问题是 cache 一致性。每个处理器都有自己的 cache，于是某一行数据可能出现在不止一个 cache 中，如果该行在一个 cache 中被修改，则主存和其他 cache 保存的将是此行的无效版本。cache 一致性协议设计用来解决这个问题

### 为什么需要并行
相关处理模型、异步模型、Actor Model、Communicating Sequential Processes、协程、Erlang

并行处理主要会遇到的两个问题是数据完整性的丧失和死锁。

分布式计算和集群是两个层面的东西

### 多核与多处理器
多核环境中编程的共同点在于，在传统的编程风格中，程序是顺序执行的，因此只能用到单独一个核心。而要充分发挥多核的优势，就必须通过某些方法，积极运用多个 CPU 的处理能力。包括 UNIX 进程的活用、通过异步 I/O 实现并行化、消息队列等，这些都是非常更有前途的技术

多核计算机或者多核处理器，在一个计算机芯片上有两个或多个处理器。由于硬件性能问题，使用更多单个处理器芯片已达到一个极限，包括指令层并行和功耗的限制。另一方面，多核体系结构给软件开发者探索多核上的多线程能力提出挑战。多核结构的主要变量是芯片处理器的数目、cache 存储器级数、cache 共享的程度。多核系统中另一个结构上的设计决策是单个内核是超标量或者实现并发多线程（SMT）

由于每个芯片上核心数目的增长，集群将会增长到包含数千个核心。云计算有许多附有吸引力的特性，其中之一就是从经济的角度来鼓励人们节省能源。

构建并充分有效利用并行处理器的进程是缓慢的。其原因一方面是受软件难点的限制，另一方面是为了提高可用性和效率，多处理器的体系结构在不断改进。不同并行体系结构之间往往存在巨大差异，所取得的性能提升也非常有限，而且过去许多并行体系结构的生命周期非常短暂，这些因素使得软件更加困难。

### 并行层级

#### 位级并行
位元层级平行（英语：Bit-level parallelism，缩写为BLP，又译为位级并行）， 一种平行计算的模式，可以增加处理器每次处理的字组（word）大小。从1970年代至1986年之间，以超大型集成电路（VLSI）发展出的电脑芯片制造技术，利用位元层级平行的技术，使处理器的速度增加。
当处理器需要执行的指令，超过字组大小时，指令需要被拆成数次来存取；增加字组大小，减少了处理器需要执行的指令数量，从而增加了运算效率。

#### 指令级并行
在 2000 年初，人们对开发指令级并行的关注达到顶峰。到 2005 年，Intel 和所有其他主要处理器制造商都调整了自己的方法，将重点放在多核心上。往往通过线程级并行而不是指令级并行来实现更高的性能，高效运用处理器的责任从硬件转移到软件和程序员身上。

GPU 追求更积极地使用 SIMD，用大量数据级并行来实现应用程序的极大性能优势。对于科学应用程序，这些方法可以有效替代在多核心中开发的更具一般性但效率较低的线程级并行。

许多研究人员预测 ILP 的应用会大幅减少，预计未来会是双发射超标量和更多核心的天下。但是，略高的发射率以及使用推测动态调度来处理意外事件（比如一级缓存缺失）的优势，使适度 ILP 成为多核心设计的主要构造模块。SMT 的添加及其有效性（无论是在性能方面还是在能耗效率方面）都进一步巩固了适度发射、乱序、推测方法的地位。

#### 任务级并行
在这个模型中，每一个线程执行一个分配到的任务，而这些线程则被分配（通常是操作系统内核）到该并行计算体系的各个计算节点中去。

尽管多核技术为克服能耗效率方面的问题提供了一些直接帮助，并将大部分重担移交给软件系统，但仍然存在一些难度很大的挑战和尚未解决的问题。

除了编程语言和编译器技术的重要问题之外，多核技术已经重新开放了计算机体系结构中另一个长期存在的问题：是否值得考虑异构处理器？尽管现在还没有提交这种多核处理器，而且异构多处理器仅在专用计算机或嵌入式系统中取得了有限的成功，但它在多核心环境中的可能性要高得多。和多重处理中的许多问题一样，其答案可能依赖于软件模型和编程系统。如果编译器和操作系统可以有效地使用同构处理器，它们将会变得更加主流。目前，对于许多应用程序来说，现有编译器的能力还不足以有效地应对中等数量的同构核心所带来的压力，但有一类拥有异构核心的多处理器变得越来越常见，它们在功能方面有明显不同，而且有一些用于分解应用程序的明确方法。这些多处理器包括诸如 GPU 和媒体处理器之类的专用处理单元。对能耗效率的重视还能促使多处理器中包含一些具有不同性能功率比的核心。

#### 数据级并行
如果有一种比任务级并行更简单的编程模型，而且可能具有更佳的性能效率，很容易就能预测到数据级并行在接下来十年中的复兴。事实上，我们已经看到一些产品对数据级并行的重视，GPU 和传统处理器都已经在增加 SIMD 扯到的数目，其增加速度至少与添加处理器的速度一样快。

我们看到系统处理器正在拥有更多的 GPU 特性，反之亦然。传统处理器和 GPU 的一个最大性能差别是集中-分散寻址。传统的向量体系结构说明如何向 SIMD 指令添加此类寻址，我们希望随着时间的推移，越来越多的在向量体系结构中得到证明的好思想能够添加到 SIMD 扩展中。

#### 其他
内存级并行
流水线并行
并行理论
PRAM model
Analysis of parallel algorithms
Amdahl’s law
Gustafson’s law
Cost efficiency
Karp–Flatt metric
Slowdown Speedup

### 协调调度

并行离不开调度，介绍调度的重要思路和经典问题。

对硬件设计者来说，基于消息传递的计算机比需要维持缓存一致性的共享存储计算机更加容易设计。对程序员来说，消息传递的优点是显式通信，这意味着共享存储的隐式通信相比性能提升较少；缺点是难以将一个顺序程序移植到消息传递计算机中，因为每次通信必须提前标识出来，否则程序将无法工作。缓存一致的共享存储允许硬件判断哪些数据需要通信，这使得移至相对简单。现在对于如何最快地获得高性能有不同的观点，隐式通信有有大量的支持者和反对者。

### 创建并行处理程序的难点
- 进程同步
  - 共享变量
  - 关键区域
  - 信号量
  - 锁
  - 经典问题
        生产者-消费者问题
        读者-写者问题
        线程安全
- 数据一致性
  - MESI
  - 内存一致性模型
    - 线性一致性（Linearizability）或严格一致性（Strict consistancy）：任何对一个内存位置X的读操作，将返回最近一次对该内存位置的写操作所写入的值。
    - 原子一致性(Atomic consistancy)：读操作未能立即读到此前最近一次写操作的结果，但多读几次还是获得了正确结果。所有对数据的修改操作都是原子的，不会产生竞态冲突。
    - 顺序一致性（Sequential consistency ）:（并发程序在多处理器上的）任何一次执行结果都相同，就像所有处理器的操作按照某个顺序执行，各个微处理器的操作按照其程序指定的顺序进行。换句话说，所有的处理器以相同的顺序看到所有的修改。读操作未必能及时得到此前其他处理器对同一数据的写更新。但是各处理器读到的该数据的不同值的顺序是一致的。
    - 缓存一致性（Cache Coherence）三个层级：在进行每个写入运算时都立刻采取措施保证数据一致性；每个独立的运算，假如它造成数据值的改变，所有进程都可以看到一致的改变结果；在每次运算之后，不同的进程可能会看到不同的值（这也就是没有一致性的行为）。
    - 静态一致性（Quiescent consistency）
    - 处理器一致性（Processor consistency）/PRAM一致性（PRAM consistency，P指pipeline）：在一个处理器上完成的所有写操作，将会被以它实际发生的顺序通知给所有其它的处理器；但是在不同处理器上完成的写操作也许会被其它处理器以不同于实际执行的顺序所看到。这反映了网络中不同节点的延迟可能是不相同的。对于双处理器，处理器一致性与顺序一致性是等价的。
    - 释放一致性（Release consistency ）：在对一个共享变量进行普通访问之前，进程在之前所有的获得锁而进行的操作必须成功的完成。在释放一个锁操作之前，进程之前的读和写操作必须已经完成。获得和释放锁的操作必须符合“FIFO一致性”。“释放一致性”仅仅关注被锁住的共享内存内存变量，仅仅只需要将对被锁住的共享变量的修改通知给其它的处理器。C#的VolatileWrite函数即实现了释放一致性语义。
    - 因果一致性（Causal consistency 
    - TSO一致性（Total store ordering）
    - PSO一致性（Partial store ordering）
    - 弱序一致性（Weak-ordering consistency）
  - 同步屏障
    - 同步屏障(Barrier)是并行计算中的一种同步方法。对于一群进程或线程，程序中的一个同步屏障意味着任何线程/进程执行到此后必须等待，直到所有线程/进程都到达此点才可继续执行下文。

## 虚拟内存与动态内存分配 

物理地址一般应用在简单的嵌入式微控制器中（汽车、电梯、电子相框等），因为应用的范围有严格的限制，不需要在内存管理中引入过多的复杂度。

但是对于计算机（以及其他智能设备）来说，虚拟地址则是必不可少的，通过 MMU(Memory management unit)把虚拟地址(Virtual Address, VA)转换为物理地址(Physical Address, PA)，再由此进行实际的数据传输。

使用虚拟内存主要是基于下面三个考虑：
- 可以更有效率的使用内存：使用 DRAM 当做部分的虚拟地址空间的缓存
- 简化内存管理：每个进程都有统一的线性地址空间
- 隔离地址控件：进程之间不会相互影响；用户程序不能访问内核信息和代码

### 虚拟内存的三个角色

**作为缓存工具**
虚拟内存就是存储在磁盘上的 N 个连续字节的数组。这个数组的部分内容，会缓存在 DRAM 中，在 DRAM 中的每个缓存块(cache block)就称为页(page)

就是利用 DRAM 比较快的特性，把最常用的数据换缓存起来。如果要访问磁盘的话，大约会比访问 DRAM 慢一万倍，所以我们的目标就是尽可能从 DRAM 中拿数据。为此，我们需要：
- 更大的页尺寸(page size)：通常是 4KB，有的时候可以达到 4MB
- 全相联(Fully associative)：每一个虚拟页(virual page)可以放在任意的物理页(physical page)中，没有限制。
- 映射函数非常复杂，所以没有办法用硬件实现，通常使用 Write-back 而非 Write-through 机制
    - Write-through: 命中后更新缓存，同时写入到内存中
    - Write-back: 直到这个缓存需要被置换出去，才写入到内存中（需要额外的 dirty bit 来表示缓存中的数据是否和内存中相同，因为可能在其他的时候内存中对应地址的数据已经更新，那么重复写入就会导致原有数据丢失）

具体怎么做呢？通过页表(page table)。每个页表实际上是一个数组，数组中的每个元素称为页表项(PTE, page table entry)，每个页表项负责把虚拟页映射到物理页上。

因为有一个表可以查询，就会遇到两种情况，一种是命中(Page Hit)，另一种则是未命中(Page Fault)。

不命中的时候，即访问到 page table 中灰色条目的时候，因为在 DRAM 中并没有对应的数据，所以需要执行一系列操作（从磁盘复制到 DRAM 中），具体为：

- 触发 Page fault，也就是一个异常
- Page fault handler 会选择 DRAM 中需要被置换的 page，并把数据从磁盘复制到 DRAM 中
- 重新执行访问指令，这时候就会是 page hit

复制过程中的等待时间称为 demand paging。

**作为内存管理工具**
在内存分配中没有太多限制，每个虚拟页都可以被映射到任何的物理页上。这样也带来一个好处，如果两个进程间有共享的数据，那么直接指向同一个物理页即可（也就是上图 PP 6 的状况，只读数据）

虚拟内存带来的另一个好处就是可以简化链接和载入的结构（因为有了统一的抽象，不需要纠结细节）

**作为内存保护工具**
页表中的每个条目的高位部分是表示权限的位，MMU 可以通过检查这些位来进行权限控制（读、写、执行）

### 地址翻译
具体的访问过程为：

- 通过虚拟地址找到页表(page table)中对应的条目
- 检查有效位(valid bit)，是否需要触发页错误(page fault)
- 然后根据页表中的物理页编号(physical page number)找到内存中的对应地址
- 最后把虚拟页偏移(virtual page offset)和前面的实际地址拼起来，就是最终的物理地址了
这里又分两种情况：Page Hit 和 Page Fault，

这里有 7 步，前面和 Page Hit 是一致的，先把虚拟地址发给 MMU 进行检查，然后发现没有对应的页，于是触发异常，异常处理器会负责从磁盘中找到对应页面并与缓存/内存中的页进行置换，置换完成后再访问同一地址，就可以按照 Page Hit 的方式来访问了。

虽然缓存已经很快了，但是能不能更快呢，为什么不能直接在 MMU 进行一部分的工作呢？于是就有了另外一个设计：Translation Lookaside Buffer(TLB)。TLB 实际上可以认为是页表在处理芯片上的缓存，整体的机制和前面提到的缓存很像，这里 VPN + VPO 就是虚拟地址，同样分成三部分，分别用于匹配标签、确定集合，如果 TLB 中有对应的记录，那么直接返回对应页表项(PTE)即可，如果没有的话，就要从缓存/内存中获取，并更新 TLB 的对应集合。

来看一个简单的例子，我们的内存系统设定如下：
- 14 位的虚拟地址
- 12 位的物理地址
页大小为 64 字节
TLB 的配置为：
- 能够存储 16 条记录
- 每个集合有 4 条记录
系统本身缓存（对应于物理地址）：
- 16 行，每个块 4 个字节
- 直接映射（即 16 个集合）

先看 TLB 中有没有对应的条目，所以先看虚拟地址的第 6-13 位，在前面的 TLB 表中，根据 TLBI 为 3 这个信息，去看这个 set 中有没有 tag 为 3 的项目，发现有，并且对应的 PPN 是 0x0D，所以对应到物理地址，就是 PPN 加上虚拟地址的 0-5 位，而具体的物理地址又可以在缓存中找到（利用 cache memory 的机制），就可以获取到对应的数据了。

### 动态内存分配
分配器以块为单位来维护堆，可以进行分配或释放。有两种类型的分配器：

- 显式分配器：应用分配并且回收空间（C 语言中的 malloc 和 free）
- 隐式分配器：应用只负责分配，但是不负责回收（Java 中的垃圾收集）

分配器有如下的限制：

- 不能控制已分配块的数量和大小
- 必须立即响应 malloc 请求（不能缓存或者给请求重新排序）
- 必须在未分配的内存中分配
- 不同的块需要对齐（32 位中 8 byte，64 位中 16 byte）
- 只能操作和修改未分配的内存
- 不能移动已分配的块

**性能指标**
吞吐量是在单位时间内完成的请求数量。假设在 10 秒中之内进行了 5000 次 malloc 和 5000 次 free 调用，那么吞吐量是 1000 operations/second

另外一个目标是 Peak Memory Utilization，就是最大的内存利用率。

内部碎片指的是对于给定的块，如果需要存储的数据(payload)小于块大小，就会因为对齐和维护堆所需的数据结构的缘故而出现无法利用的空间

**实现细节**
在具体实现之前，需要考虑以下问题：

- 给定一个指针，我们如何知道需要释放多少内存？
- 如何记录未分配的块？
- 实际需要的空间比未分配的空间要小的时候，剩下的空间怎么办？
- 如果有多个区域满足条件，如何选择？
- 释放空间之后如何进行记录？

具体这部分书中提到了四种方法：
- 隐式空闲列表 Implicit List
- 显式空闲列表 Explicit List
- 分离的空闲列表 Segregated Free List
- 按照大小对块进行排序 Blocks Sorted by Size

这里提一点，就是如何确定哪部分空间合适，有三种方法：
- First Fit: 每次都从头进行搜索，找到第一个合适的块，线性查找
- Next Fit: 每次从上次搜索结束的位置继续搜索，速度较快，但可能会有更多碎片
- Best Fit: 每次遍历列表，找到最合适的块，碎片较少，但是速度最慢

所谓**垃圾回收**，就是我们不再需要显式释放所申请内存空间了

**内存陷阱**
关于内存的使用需要注意避免以下问题：

- 解引用错误指针
- 读取未初始化的内存
- 覆盖内存
- 引用不存在的变量
- 多次释放同一个块
- 引用已释放的块
- 释放块失败

## 并行与同步 

### 并行方法
常见的错误有仨：竞争条件[2]、死锁[3]和活锁[4]，尤其是在现在的多核处理器架构中，更容易出现这类并行问题。

根据系统机制的层级和实现方式，有下面三大类方法：
- 基于进程
    内核自动管理多个逻辑流
    每个进程有其私有的地址空间（也就是说进程切换的时候需要保存和载入数据）
- 基于事件
    由程序员手动控制多个逻辑流
    所有的逻辑流共享同一个地址空间
    这个技术称为 I/O multiplexing
- 基于线程
    内核自动管理多个逻辑流
    每个线程共享地址空间
    属于基于进程和基于事件的混合体

**基于进程**

```cpp
void sigchld_handler(int sig){
    while (waitpid(-1, 0, WNOHANG) > 0)
        ;
    return;
    // Reap all zombie children
}

int main(int argc, char **argv) {
    int listenfd, connfd;
    socklen_t clientlen;
    struct sockaddr_storage clientaddr;
    
    Signal(SIGCHLD, sigchld_handler);
    listenfd = Open_listenfd(argv[1]);
    while (1) {
        clientlen = sizeof(struct sockaddr_storage);
        connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen);
        if (Fork() == 0) {
            Close(listenfd); // Child closes its listening socket
            echo(connfd); // Child services client
            Close(connfd); // Child closes connection with client
            exit(0); // Child exits
        }
        Close(connfd); // Parent closes connected socket (important!)
    }
}

```
整个执行模型中：

- 每个客户端由独立子进程处理
    必须回收僵尸进程，来避免严重的内存泄露
- 不同进程之间不共享数据
- 父进程和子进程都有 listenfd 和 connfd，所以在父进程中需要关闭 connfd，在子进程中需要关闭 listenfd
    内核会保存每个 socket 的引用计数，在 fork 之后 refcnt(connfd) = 2，所以在父进程需要关闭 connfd，这样在子进程结束后引用计数才会为零

基于进程的方式可以并行处理连接，除了共享已打开的 file table 外，无论是 descriptor 还是全局变量都不共享，不大容易造成同步问题，比较简单粗暴。但是带来了额外的进程管理开销，并且进程间通讯不便，需要使用 IPC (interprocess communication)。

**基于事件**

服务器会维护一个 connection 数组，包含若干 connfd，每个输入请求都被当做事件，然后每次从已有的事件中选取一个进行处理。

基于实践的好处在于只使用一个逻辑控制流和地址空间，可以利用调试器进行单步调试（其他的方法因为并行的缘故基本没办法调试），也不会有进程/线程控制的开销。但是相比之下，代码的逻辑复杂度会比较高，很难进行精细度比较高的并行，也无法发挥多核处理器的全部性能。

**基于线程**
和基于进程的方法非常相似，唯一的区别是这里用线程。进程其实是比较『重』的，一个进程包括进程上下文、代码、数据和栈。如果从线程的角度来描述，一个进程则包括线程、代码、数据和上下文。也就是说，线程作为单独可执行的部分，被抽离出来了，一个进程可以有多个线程。

每个线程有自己的线程 id，有自己的逻辑控制流，也有自己的用来保存局部变量的栈（其他线程可以修改）但是会共享所有的代码、数据以及内核上下文。

和进程不同的是，线程没有一个明确的树状结构（使用 fork 是有明确父进程子进程区分的）。和进程中『并行』的概念一样，如果两个线程的控制流在时间上有『重叠』（或者说有交叉），那么就是并行的。

进程和线程的差别已经被说了太多次，这里简单提一下。相同点在于，它们都有自己的逻辑控制流，可以并行，都需要进行上下文切换。不同点在于，线程共享代码和数据（进程通常不会），线程开销比较小（创建和回收）

**POSIX Threads**

Pthreads 是一个线程库，基本上只要是 C 程序能跑的平台，都会支持这个标准。Pthreads定义了一套C语言的类型、函数与常量，它以 pthread.h 头文件和一个线程库实现。

Pthreads API 中大致共有 100 个函数调用，全都以 pthread_ 开头，并可以分为四类：

- 线程管理，例如创建线程，等待(join)线程，查询线程状态等。
- Mutex：创建、摧毁、锁定、解锁、设置属性等操作
- 条件变量（Condition Variable）：创建、摧毁、等待、通知、设置与查询属性等操作
- 使用了读写锁的线程间的同步管理

POSIX 的 Semaphore API 可以和 Pthreads 协同工作，但这并不是 Pthreads 的标准。因而这部分API是以 sem_ 打头，而非 pthread_。
```cpp
// Thread routine
void *thread(void *vargp){
    int connf = *((int *)vargp);
    // detach 之后不用显式 join，会在执行完毕后自动回收
    Pthread_detach(pthread_self());
    Free(vargp);
    echo(connfd);
    // 一定要记得关闭！
    Close(connfd);
    return NULL;
}

int main(int argc, char **argv) {
    int listenfd, *connfdp;
    socklen_t clientlen;
    struct sockaddr_storage clientaddr;
    pthread_t tid;
    
    listenfd = Open_listenfd(argv[1]);
    while (1) {
        clientlen = sizeof(struct sockaddr_storage);
        // 这里使用新分配的 connected descriptor 来避免竞争条件
        connfdp = Malloc(sizeof(int));
        *connfdp = Accept(listenfd, (SA *) & clientaddr, &clientlen);
        Pthread_create(&tid, NULL, thread, connfdp);
    }
}

```

这里简单归纳下三种并行方法的特点：
- 基于进程
    - 难以共享资源，但同时也避免了可能带来的共享问题
    - 添加/移除进程开销较大 
- 基于事件
    - 非常底层的实现机制
    - 使用全局控制而非调度
    - 开销比较小
    - 但是无法提供精细度较高的并行
    - 无法充分利用多核处理器 
- 基于线程
    - 容易共享资源，但也容易出现问题
    - 开销比进程小
    - 对于具体的调度可控性较低
    - 难以调试（因为事件发生的顺序不一致）

### 共享变量

在介绍同步之前，我们需要弄清楚一个定义，什么是 Shared variable（共享变量）？
    >A variable x is shared if and only if multiple threads reference some instance of x

另外一个需要注意的是线程的内存模型，因为概念上的模型和实际的模型有一些差异，非常容易导致错误。
在概念上的模型中：
- 多个线程在一个单独进程的上下文中运行
- 每个线程有单独的线程上下文（线程 ID，栈，栈指针，PC，条件码，GP 寄存器）
- 所有的线程共享剩下的进程上下文
    - Code, data, heap, and shared library segments of the process virtual address space
    - Open files and installed handlers
在实际的模型中，寄存器的值虽然是隔离且被保护的，但是在栈中的值并不是这样的（其他线程也可以访问）。

- 全局变量：在函数外声明的变量
    - 虚拟内存中有全局唯一的一份实例
- 局部变量：在函数内声明，且没有用 static 关键字
    - 每个线程的栈中都保存着对应线程的局部变量
- 局部静态变量：在函数内用 static 关键字声明的变量
    - 虚拟内存中有全局唯一的一份实例

具体来分析下，一个变量只有在被多个线程引用的时候才算是共享，在这个例子中，共享变量有 ptr, cnt 和 msgs；非共享变量有 i 和 myid。

### 关键区域 Critical Section
```cpp
// 全局共享变量
volatile long cnt = 0; // 计数器

int main(int argc, char **argv)
{
    long niters;
    pthread_t tid1, tid2;
    
    niter2 = atoi(argv[1]);
    Pthread_create(&tid1, NULL, thread, &niters);
    Pthread_create(&tid2, NULL, thread, &niters);
    Pthread_join(tid1, NULL);
    Pthread_join(tid2, NULL);
    
    // 检查结果
    if (cnt != (2 * niters))
        printf("Wrong! cnt=%ld\n", cnt);
    else
        printf("Correct! cnt=%ld\n", cnt);
    exit(0);
}
```
cnt 使用了 volatile 关键字声明，意思是不要在寄存器中保存值，无论是读取还是写入，都要对内存操作（还记得 write-through 吗？）。这里把具体的步骤分成 5 步：HLUST，尤其要注意 LUS 这三个操作，这三个操作必须在一次执行中完成，一旦次序打乱，就会出现问题，不同线程拿到的值就不一定是最新的。

### 信号量
运作方式：
- 初始化，给与它一个非负数的整数值。
- 运行 P，信号量 S 的值将被减少。企图进入临界区块的进程，需要先运行 P。当信号量 S 减为负值时，进程会被挡住，不能继续；当信号量S不为负值时，进程可以获准进入临界区块。
- 运行 V，信号量 S 的值会被增加。结束离开临界区块的进程，将会运行 V。当信号量 S 不为负值时，先前被挡住的其他进程，将可获准进入临界区块
```cpp
// 先定义信号量
volatile long cnt = 0;
sem_t mutex;

Sem_init(&mutex, 0, 1);


// 在线程中用 P 和 V 包围关键操作
for (i = 0; i < niters; i++)
{
    P(&mutex);
    cnt++;
    V(&mutex);
}

```

### 生产者-消费者问题
具体的同步模型为：

- 生产者等待空的 slot，把 item 存储到 buffer，并通知消费者
- 消费整等待 item，从 buffer 中移除 item，并通知生产者

应用：
- 多媒体处理
    生产者生成 MPEG 视频帧，消费者进行渲染
- 事件驱动的图形用户界面
    生产者检测到鼠标点击、移动和键盘输入，并把对应的事件插入到 buffer 中
    消费者从 buffer 中获取事件，并绘制到到屏幕上

```cpp
// 头文件 sbuf.h
/*
productor --> biff --> consumer

mutex: 用来保证对 buffer 的互斥访问
slots: 统计 buffer 中可用的 slot 数目
items: 统计 buffer 中可用的 item 数目
*/
// 包括几个基本操作
#include "csapp.h"

typedef struct {
    int *buf;    // Buffer array
    int n;       // Maximum number of slots
    int front;   // buf[(front+1)%n] is first item
    int rear;    // buf[rear%n] is the last item
    sem_t mutex; // Protects accesses to buf
    sem_t slots; // Counts available slots
    sem_t items; // Counts available items
} sbuf_t;

// sbuf.c

// Create an empty, bounded, shared FIFO buffer with n slots
void sbuf_init(sbuf_t *sp, int n) {
    sp->buf = Calloc(n, sizeof(int));
    sp->n = n;                  // Buffer holds max of n items
    sp->front = sp->rear = 0;   // Empty buffer iff front == rear
    Sem_init(&sp->mutex, 0, 1); // Binary semaphore for locking
    Sem_init(&sp->slots, 0, n); // Initially, buf has n empty slots
    Sem_init(&sp->items, 0, 0); // Initially, buf has 0 items
}

// Clean up buffer sp
void sbuf_deinit(sbuf_t *sp){
    Free(sp->buf);
}

// Insert item onto the rear of shared buffer sp
void sbuf_insert(sbuf_t *sp, int item) {
    P(&sp->slots);                        // Wait for available slot

    P(&sp->mutex);                        // Lock the buffer
    sp->buf[(++sp->rear)%(sp->n)] = item; // Insert the item
    V(&sp->mutex);                        // Unlock the buffer
    
    V(&sp->items);                        // Announce available item
}

// Remove and return the first tiem from the buffer sp
int sbuf_remove(sbuf_f *sp) {
    int item;
    P(&sp->items);                         // Wait for available item
    
    P(&sp->mutex);                         // Lock the buffer
    item = sp->buf[(++sp->front)%(sp->n)]; // Remove the item
    V(&sp->mutex);                         // Unlock the buffer
    
    V(&sp->slots);                         // Announce available slot
    return item;
}

```

### 读者-写者问题

是互斥问题的通用描述，具体为：

- 读者线程只读取对象
- 写者线程修改对象
- 写者对于对象的访问是互斥的
- 多个读者可以同时读取对象

常见的应用场景是：

- 在线订票系统
- 多线程缓存 web 代理

第一类读者写者问题（读者优先）

- 如果写者没有获取到使用对象的权限，不应该让读者等待
- 在等待的写者之后到来的读者应该在写者之前处理
- 也就是说，只有没有读者的情况下，写者才能工作

第二类读者写者问题（写者优先）

- 一旦写者可以处理的时候，就不应该进行等待
- 在等待的写者之后到来的读者应该在写者之后处理

```cpp
sbuf_t sbuf; // Shared buffer of connected descriptors

static int byte_cnt;  // Byte counter
static sem_t mutex;   // and the mutex that protects it

void echo_cnt(int connfd){
    int n;
    char buf[MAXLINE];
    rio_t rio;
    static pthread_once_t once = PTHREAD_ONCE_INIT;
    
    Pthread_once(&once, init_echo_cnt);
    Rio_readinitb(&rio, connfd);
    while ((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) {
        P(&mutex);
        byte_cnt += n;
        printf("thread %d received %d (%d total) bytes on fd %d\n",
                    (int) pthread_self(), n, byte_cnt, connfd);
        V(&mutex);
        Rio_writen(connfd, buf, n);
    }
}

static void init_echo_cnt(void){
    Sem_init(&mutex, 0, 1);
    byte_cnt = 0;
}

void *thread(void *vargp){
    Pthread_detach(pthread_self());
    while (1) {
        int connfd = sbuf_remove(&sbuf); // Remove connfd from buf
        echo_cnt(connfd);                // Service client
        Close(connfd);
    }
}

int main(int argc, char **argv) {
    int i, listenfd, connfd;
    socklen_t clientlen;
    struct sockaddr_storage clientaddr;
    pthread_t tid;
    
    listenfd = Open_listenfd(argv[1]);
    sbuf_init(&sbuf, SBUFSIZE);
    for (i = 0; i < NTHREADS; i++) // Create worker threads
        Pthread_create(&tid, NULL, thread, NULL);
    while (1) {
        clientlen = sizeof(struct sockaddr_storage);
        connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen);
        sbuf_insert(&sbuf, connfd); // Insert connfd in buffer
    }
}

```

### 线程安全

A function is thread-safe iff it will always produce correct results when called repeatedly from multiple concurrent threads

主要有 4 类线程不安全的函数

1. 不保护共享变量的函数
    - 解决办法：使用 P 和 V semaphore 操作
    - 问题：同步操作会影响性能
2. 在多次调用间保存状态的函数
    - 解决办法：把状态当做传入参数
3. 返回指向静态变量的指针的函数
    - 解决办法1：重写函数，传地址用以保存
    - 解决办法2：上锁，并且进行复制
4. 调用线程不安全函数的函数
    - 解决办法：只调用线程安全的函数

A function is reentrant iff it accesses no shared variables when called by multiple threads

Reentrant Functions 是线程安全函数非常重要的子集，不需要同步操作，对于第二类的函数来说（上面提到的），唯一的办法就是把他们修改成 reentrant 的。

总结来看，并行编程需要注意的是：
- 要有并行策略，可以把一个大任务分成若干个独立的子任务，或者用分而治之的方式来解决
- 内循环最好不要有任何同步机制
- 注意 Amdahl’s Law
- 一致性是个大问题，无论是计算一致性还是存储一致性，都需要仔细考虑

### 超线程
我们之前是如何处理 I/O 的延迟的呢？

一个办法是每个客户端都由一个线程来处理，这样就不需要互相等待。现在的多核/超线程处理器提供了另外一种可能。我们不但可以并行执行多个线程，更好的是这些都是自动进行的，当然，我们也可以通过把大任务分成小任务来加速运算。



## 版本控制

| Version | Action                   | Time       |
| ------- | ------------------------ | ---------- |
| 1.0     | Init                     | 2019-05-02T05:16:29-07:00|
